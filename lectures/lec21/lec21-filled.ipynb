{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e4849e",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from lec_utils import *\n",
    "import lec21_util as util"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526bc00d",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-info\" markdown=\"1\">\n",
    "\n",
    "#### Lecture 21\n",
    "\n",
    "# Introduction to Classification\n",
    "\n",
    "### EECS 398: Practical Data Science, Winter 2025\n",
    "\n",
    "<small><a style=\"text-decoration: none\" href=\"https://practicaldsc.org\">practicaldsc.org</a> ‚Ä¢ <a style=\"text-decoration: none\" href=\"https://github.com/practicaldsc/wn25\">github.com/practicaldsc/wn25</a> ‚Ä¢ üì£ See latest announcements [**here on Ed**](https://edstem.org/us/courses/69737/discussion/5943734) </small>\n",
    "    \n",
    "</div>\n",
    "\n",
    "<script type=\"text/x-mathjax-config\">\n",
    " MathJax.Hub.Config({\n",
    "   TeX: {\n",
    "     extensions: [\"color.js\"],\n",
    "     packages: {\"[+]\": [\"color\"]},\n",
    "   }\n",
    " });\n",
    " </script>\n",
    " <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS_HTML\"></script>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a205c2eb",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Agenda üìÜ\n",
    "\n",
    "- Classification overview.\n",
    "- Survey of classification methods.\n",
    "    - $k$-nearest neighbors üè°üè†.\n",
    "    - Decision trees üéÑ.\n",
    "- Evaluating classifiers.\n",
    "- Multiclass classification üêß."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bb776c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h3>Question ü§î (Answer at <a style=\"text-decoration: none; color: #0066cc\" href=\"https://docs.google.com/forms/d/e/1FAIpQLSd4oliiZYeNh76jWy-arfEtoAkCrVSsobZxPwxifWggo3EO0Q/viewform\">practicaldsc.org/q</a>)</h3>\n",
    "    \n",
    "Remember that you can always ask questions anonymously at the link above!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5e4851",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Classification overview\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07be1b2",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The taxonomy of machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040bdb78",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- So far, we've focused on building **regression** models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9950da0b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Regression is a form of **supervised learning**, in which the target variable (i.e., the $y$-values we're trying to predict) is **numerical**.<br><small>For example, a predicted commute time could technically be any real number.</small>\n",
    "\n",
    "<center><img src=\"imgs/taxonomy.svg\" width=500></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5002d6",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Next, we'll focus on **classification**, a form of supervised learning in which the target variable is **categorical**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa97069",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example classification problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8e78e8",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Does this person have diabetes?<br><small>This is an example of **binary classification** ‚Äì there are only two possible classes, or categories. In binary classification, the two classes are typically **1** (yes) and **0** (no).</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8aa81be",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Is this digit a 0, 1, 2, 3, 4, 5, 6, 7, 8, or 9?<br><small>This is an example of multi-class classification, where there are multiple possible classes.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31053d89",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Is this picture of a dog, cat, zebra, or hamster?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f30e14",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The plan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e8e506",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- When we introduced regression, we **started** by understanding the theoretical foundations on paper, and then learned how to build models in `sklearn`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b41831",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- This time, we'll do the reverse: we'll start by learning how to use classifiers in `sklearn`, and then over the next few lectures, we'll dive deeper into the internals of a few.\n",
    "    - Today: $k$-nearest neighbors and decision trees.\n",
    "    - Lectures 22-23: Logistic regression (and, potentially, Na√Øve Bayes)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4f5594",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Loading the data üè•"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d6fc34",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Our first classification example will involve predicting whether or not a patient has diabetes, given other information about their health."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216c3acb",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "diabetes = pd.read_csv('data/diabetes.csv')\n",
    "display_df(diabetes, cols=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ac94af",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# 0 means no diabetes, 1 means yes diabetes.\n",
    "diabetes['Outcome'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f30a6f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- `'Glucose'` is measured in mg/dL (milligrams per deciliter); `'BMI'` is calculated as $\\text{BMI} = \\frac{\\text{weight (kg)}}{\\left[ \\text{height (m)} \\right]^2}$.<br>Let's start by using these two features to predict whether or not a patient has diabetes (`'Outcome'`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88600e7e",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- But first, a train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c35b639",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = (\n",
    "    train_test_split(diabetes[['Glucose', 'BMI']], diabetes['Outcome'], random_state=1)\n",
    ")\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70eaefa2",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Visualizing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9454a7bc",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Let's visualize the relationship between `X_train` and `y_train`. There are three numeric variables at play here ‚Äì `'Glucose'`, `'BMI'`, and `'Outcome'` ‚Äì so we can use a 3D scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59787b49",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "px.scatter_3d(X_train.assign(Outcome=y_train), \n",
    "              x='Glucose', y='BMI', z='Outcome', \n",
    "              title='Relationship between Glucose, BMI, and Diabetes',\n",
    "              width=800, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38adc22b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Since there are only two possible `'Outcome'`s, we can draw a 2D scatter plot of `'BMI'` vs. `'Glucose'` and color each point by `'Outcome'`. Below, <span style='color: orange'><b>class 0 (orange) is \"no diabetes\"</b></span> and <span style='color: blue'><b>class 1 (blue) is \"diabetes\"</b></span>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c30ac4",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fig = util.create_base_scatter(X_train, y_train)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c70269",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Using this dataset, how can we classify whether someone new (not already in the dataset) has diabetes, given their `'Glucose'` and `'BMI'`?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cc98f7",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Intuition**: If a new person's feature vector is <b><span style=\"color:blue\">close to the blue points</span></b>, we'll predict <b><span style=\"color:blue\">blue (diabetes)</span></b>; if they're <b><span style=\"color:orange\">close to the orange points</span></b>, we'll predict <b><span style=\"color:orange\">orange (no diabetes)</span></b>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1547041",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Classifier 1: $k$-nearest neighbors  üè°üè†\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305b19d7",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### $k$-nearest neighbors üè°üè†"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0240aab",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Suppose we're given a new individual, $\\vec{x}_\\text{new} = \\begin{bmatrix} \\text{Glucose}_\\text{new} \\\\ \\text{BMI}_\\text{new} \\end{bmatrix}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c89fa3",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The $k$-nearest neighbors classifier ($k$-NN for short) classifies $\\vec{x}_\\text{new}$ by:\n",
    "    1. Finding the $k$ **closest points** in the training set to $\\vec{x}_\\text{new}$.\n",
    "    1. Predicting that $\\vec{x}_\\text{new}$ belongs to the **most common class** among those $k$ closest points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d1e894",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07147dd0",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Example: Suppose $k = 6$. If, among the 6 closest points to $\\vec{x}_\\text{new}$, there are <b><span style=\"color:blue\">4 blue</span></b> and <b><span style=\"color:orange\">2 orange</span></b> points, we'd predict <b><span style=\"color:blue\">blue (diabetes)</span></b>.\n",
    "<br><small>What if there are ties? Read [here](https://stats.stackexchange.com/questions/144718/how-does-scikit-learn-resolve-ties-in-the-knn-classification).</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6168cde0",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- $k$ is a hyperparameter that should be chosen through cross-validation.<br><small>As we've seen in Homework 8 and 9, in the context of $k$-NN regression, smaller values of $k$ tend to overfit significantly.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff42aaf1",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `KNeighborsClassifier` in `sklearn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1648d0d",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8bf1d0",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Let's fit a `KNeighborsClassifier` by using cross-validation to choose a value of $k$ from 1 through 50.<br><small>Note that `KNeighborsClassifier`s have several other hyperparameters. One of them is the metric used to measure distances; the default is the standard Euclidean ($L_2$) distance, e.g. $\\text{dist}(\\vec u, \\vec v) = \\sqrt{(u_1 - v_1)^2 + (u_2 - v_2)^2 + ... + (u_d - v_d)^2}$.</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118c6cf4",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model_knn = GridSearchCV(\n",
    "    KNeighborsClassifier(),\n",
    "    param_grid = {'n_neighbors': range(1, 51)}\n",
    ")\n",
    "model_knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5324d7f2",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model_knn.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1476b2d2",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Cross-validation chose $k = 28$. With the resulting model, we can make predictions using the `predict` method, just like with regressors.<br><small>Note that all of the work in making the prediction ‚Äì finding the 28 nearest neighbors, for instance ‚Äì is done when we call `predict`. \"Training\" does very little.</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4984ce3e",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# To know what reasonable values for 'Glucose' and 'BMI' might be, let's look at the plot again.\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62617b86",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model_knn.predict(pd.DataFrame([{\n",
    "    'Glucose': 125,\n",
    "    'BMI': 40\n",
    "}]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff437f2",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- What does the resulting model **look like** üëÄ? Can we visualize it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04acf2a2",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Decision boundaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032edfa6",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The **decision boundaries** of a classifier visualize the regions in the feature space that separate different predicted classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf359467",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The decision boundaries for `model_knn` are visualized below.<br><small>If a new person's feature vector lies in the <b><span style=\"color:blue\">blue region</span></b>, we'd predict they <b><span style=\"color:blue\">do have diabetes</span></b>, <b><span style=\"color:orange\">otherwise</span></b>, we'd predict <b><span style=\"color:orange\">they don't</span></b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c36ec0",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "util.visualize_k(28, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18e5e5e",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What would the decision boundaries look like if $k$ increased or decreased?<br><small>Play with the slider below to find out!</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3a9ae0",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "util.show_slider()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851bc693",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What if $k = n$, the number of points in the training set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec5fcb9",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "util.visualize_k(576, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de09b43b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Quantifying the performance of a classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006727f9",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- For regression models, our default evaluation metric was **mean squared error**.<br><small>Error is bad, so **lower** values indicate **better** model performance.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75137742",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The most common evaluation metric in classification is **accuracy**:\n",
    "\n",
    "    $$\\text{accuracy} = \\frac{\\text{# points classified correctly}}{\\text{# points}}$$\n",
    "    \n",
    "    Accuracy ranges from 0 to 1, i.e. 0% to 100%. **Higher** values indicate **better** model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b523b56c",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Equivalent to 75%.\n",
    "(model_knn.predict(X_test) == y_test).mean() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e9be0f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- This is the default metric that the `score` method of a classifier computes, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42e2236",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model_knn.score(X_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f8867a",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# For future reference.\n",
    "test_scores = pd.Series()\n",
    "test_scores['knn with k = 28'] = model_knn.score(X_test, y_test) \n",
    "test_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927baaa5",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Accuracy is **not** the only metric we care about, and can sometimes be misleading. More on this soon!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bafd15",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "### Activity\n",
    "    \n",
    "It seems that a $k$-NN classifier that uses $k = 1$ should achieve 100% training accuracy. Why **doesn't** the model defined below have 100% training accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead69a1d",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800f2836",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model_k1 = KNeighborsClassifier(n_neighbors=1)\n",
    "model_k1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b436d06",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Training accuracy ‚Äì high, but not 100%.\n",
    "model_k1.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93205fdf",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Accuracy on test set is lower than when k = 28!\n",
    "model_k1.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8524f8e",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_scores['knn with k = 1'] = model_k1.score(X_test, y_test)\n",
    "test_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbae7289",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "### Discussion\n",
    "    \n",
    "Why should we generally **standardize** features before using a $k$-NN classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824db124",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "util.create_scaled_version(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bdffe6",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d16e9a1",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Parametric vs. non-parametric models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e062b81c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The $k$-nearest neighbors classifier is an example of a **non-parametric** machine learning method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef78527",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Linear regression, on the other hand, is **parametric**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f433ee89",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- One intuitive difference:\n",
    "    - Once we train a linear regression model, we don't need to look at the training set to make predictions ‚Äì we just use the optimal parameters $w_0^*, w_1^*, ..., w_d^*$ we found.\n",
    "    - Once we train a $k$-NN model, we still need to look at the training set each time we want to make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bbca51",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Other differences between parametric and non-parametric models:\n",
    "\n",
    "| Parametric | Non-Parametric |\n",
    "| --- | --- |\n",
    "| There's a fixed set of parameters (weights/coefficients), $w_0^*, w_1^*, ..., w_d^*$ that we'll use for making predictions, and the number of parameters is independent of the training set size. | No fixed set of parameters; model complexity increases as the training set size increases. |\n",
    "| Parametric methods make assumptions about the shape of the data and/or its underlying probability distribution.<br><small>For instance, linear models assume a linear relationship between the features $X$ and target $\\vec{y}$.<br>There's a connection between the squared loss function and maximum likelihood estimation, too.</small> | Non-parametric methods make no assumptions about the shape of the data. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f976d13",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Classifier 2: Decision trees üéÑ\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a310f80",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Decision trees üéÑ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b53266",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Suppose we're given a new individual, $\\vec{x}_\\text{new} = \\begin{bmatrix} \\text{Glucose}_\\text{new} \\\\ \\text{BMI}_\\text{new} \\end{bmatrix}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bec15dd",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The decision tree classifier classifies $\\vec{x}_\\text{new}$ by:\n",
    "    1. Asking a series of yes/no questions about $\\text{Glucose}_\\text{new}$ and $\\text{BMI}_\\text{new}$, e.g.:\n",
    "    <br>\n",
    "    <center>Is $\\text{Glucose}_\\text{new} \\leq 129.5$?<br>If so, is $\\text{BMI}_\\text{new} \\leq 26.3$?\n",
    "    <br>If not, is $\\text{BMI}_\\text{new} \\leq 29.95$?<br>$\\vdots$</center>\n",
    "    2. Once it runs out of questions to ask, it predicts that $\\vec{x}_\\text{new}$ belongs to the **most common class** among training set points that had the same answers as $\\vec{x}_\\text{new}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c409c91d",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Visually, a fit decision tree may look like:\n",
    "\n",
    "<center><img src=\"imgs/example-dt.png\" width=500</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26aa6187",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Decision trees are also **non-parametric**!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ae41af",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `DecisionTreeClassifier` in `sklearn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c53590",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119c8a8e",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Let's fit a `DecisionTreeClassifier`.<br><small>One of the main hyperparameters is `max_depth`, the number of questions to ask before making a prediction. Typically, we fit this with cross-validation, but for now we'll hard-code it.</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ba2172",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model_tree = DecisionTreeClassifier(max_depth=3)\n",
    "model_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20f8d4b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The decision tree achieves a slightly higher test set accuracy than the cross-validated $k$-NN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313cfd51",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model_tree.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9850714c",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_scores['decision tree with depth = 3'] = model_tree.score(X_test, y_test)\n",
    "test_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dd9406",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- But what does it **look like**?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4981cb0f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Decision boundaries for a decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0851614b",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "util.show_decision_boundary(model_tree, X_train, y_train, title='Decision Boundary for a Tree of Depth 3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd81ca2",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Observe that the decision boundaries ‚Äì at least when we set `max_depth` to 3 ‚Äì look less \"jagged\" than with the $k$-NN classifier.<br><small>Decision trees partition the feature space into rectangles.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c0017c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Visualizing decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778cea74",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Our fit decision tree is like a \"flowchart\", made up of a series of questions.<br><small>It turns out `sklearn` provides us with a convenient way of visualizing this flowchart.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b9d346",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- As before, <span style='color: orange'><b>orange is \"no diabetes\"</b></span> and <span style='color: blue'><b>blue  is \"diabetes\"</b></span>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64cfd0d",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "util.show_diabetes_decision_tree(model_tree, X_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab689933",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- To **classify a new data point**, we start at the top and answer the first question (i.e. \"Glucose <= 129.5\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e70490",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If the answer is \"**Yes**\", we move to the **left** branch, otherwise we move to the right branch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3147e5f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We repeat this process until we end up at a leaf node, at which point we predict the most common class in that node.<br><small>Note that each node has a `value` attribute, which describes the number of **training** individuals of each class that fell in that node.</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59080a9c",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_train[X_train[X_train['Glucose'] <= 129.5].index].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db41dcfa",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Increasing tree depth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75aa4971",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- One of the many hyperparameters we can tune is tree depth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c55ffa9",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- What happens to the decision boundary of the resulting classifier if we increase `max_depth`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202c0520",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "interact(lambda depth: util.visualize_depth(depth, X_train, y_train), depth=(1, 51));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1315ed00",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- What happens to the flowchart representation of the resulting classifier if we increase `max_depth`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f140a0af",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# By default, there is pre-specified maximum depth.\n",
    "# The training algorithm keeps \n",
    "model_tree_no_max = DecisionTreeClassifier()\n",
    "model_tree_no_max.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483762ea",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "util.show_diabetes_decision_tree(model_tree_no_max, X_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcd97ee",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The tree is **extremely overfit** to the training set, and very deep!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c72443c",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Training accuracy. This number should look familiar!\n",
    "model_tree_no_max.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1d1087",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model_tree_no_max.tree_.max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239e71ee",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Worse test set performance than when we used max_depth = 3!\n",
    "test_scores['decision tree with no specified max depth'] = model_tree_no_max.score(X_test, y_test)\n",
    "test_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733d7160",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "### Activity\n",
    "    \n",
    "<br>\n",
    "    \n",
    "<center><img src=\"imgs/chicken-class.png\" width=1200></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a280ad",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Classifier evaluation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7058bf",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Outcomes in binary classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e272816",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- When performing **binary** classification, there are four possible outcomes.<br><small>Note: A \"positive prediction\" is a prediction of 1, and a \"negative prediction\" is a prediction of 0.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a50eea2",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "|Outcome of Prediction|Definition|True Class|\n",
    "|---|---|---|\n",
    "|**True** positive (TP) ‚úÖ|The predictor **correctly** predicts the positive class.|P|\n",
    "|False negative (FN) ‚ùå|The predictor incorrectly predicts the negative class.|P|\n",
    "|**True** negative (TN) ‚úÖ|The predictor **correctly** predicts the negative class.|N|\n",
    "|False positive (FP) ‚ùå|The predictor incorrectly predicts the positive class.|N|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7861d6",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We typically organize the four quantities above into a **confusion matrix**.\n",
    "\n",
    "| | Predicted Negative | Predicted Positive |\n",
    "| --- | --- | --- |\n",
    "| **Actually Negative** | TN ‚úÖ | FP ‚ùå |\n",
    "| **Actually Positive** | FN ‚ùå | TP ‚úÖ |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd343ab",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Note that in the four acronyms ‚Äì TP, FN, TN, FP ‚Äì the **first letter** is whether the prediction is correct, and the **second letter** is what the prediction is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57887921",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Depending on the situation, false negatives may be worse than false positives (or vice versa!).**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b51f763",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Accuracy of COVID tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13610897",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The results of 100 Michigan Medicine COVID tests are given below.\n",
    "\n",
    "| | Predicted Negative | Predicted Positive |\n",
    "| --- | --- | --- |\n",
    "| **Actually Negative** | TN = 90 ‚úÖ | FP = 1 ‚ùå |\n",
    "| **Actually Positive** | FN = 8 ‚ùå | TP = 1 ‚úÖ |\n",
    "<center><i><small>Michigan Medicine test results</small></i></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e3da18",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- ü§î **Question:** What is the accuracy of the test?\n",
    "\n",
    "$$\n",
    "\\text{accuracy} = \\frac{\\text{# points classified correctly}}{\\text{# points}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292dc573",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **üôã Answer:** $$\\text{accuracy} = \\frac{TP + TN}{TP + FP + FN + TN} = \\frac{1 + 90}{100} = 0.91$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8436e82f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Followup:** At first, the test seems good. But, suppose we build a classifier that predicts that **nobody has COVID**. What would its accuracy be?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba1f865",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Answer to followup:** Also 0.91! There is severe **class imbalance** in the dataset, meaning that most of the data points are in the same class (no COVID). **Accuracy doesn't tell the full story!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56518eb",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Recall\n",
    "\n",
    "| | Predicted Negative | Predicted Positive |\n",
    "| --- | --- | --- |\n",
    "| **Actually Negative** | TN = 90 ‚úÖ | FP = 1 ‚ùå |\n",
    "| <span style='color:orange'><b>Actually Positive</b></span> | <span style='color:orange'>FN = 8</span> ‚ùå | <span style='color:orange'>TP = 1</span> ‚úÖ |\n",
    "\n",
    "<center><i><small>Michigan Medicine test results</small></i></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e719e2",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- ü§î **Question:** What proportion of individuals who actually have COVID did the test **identify**?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5af516",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **üôã Answer:** $\\frac{1}{1 + 8} = \\frac{1}{9} \\approx 0.11$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d65942",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- More generally, the **recall** of a binary classifier is the proportion of <span style='color:orange'><b>actually positive instances</b></span> that are correctly classified. We'd like this number to be as close to 1 (100%) as possible.\n",
    "\n",
    "$$\\text{recall} = \\frac{TP}{\\text{# actually positive}} = \\frac{TP}{TP + FN}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134ae096",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- To compute recall, look at the <span style='color:orange'><b>bottom (positive) row</b></span> of the above confusion matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1026fa57",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Recall isn't everything, either!\n",
    "\n",
    "$$\\text{recall} = \\frac{TP}{TP + FN}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a47b56",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- ü§î **Question:** Can you design a \"COVID test\" with perfect recall?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b95ea4",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **üôã Answer:** Yes ‚Äì **just predict that everyone has COVID!**\n",
    "\n",
    "| | Predicted Negative | Predicted Positive |\n",
    "| --- | --- | --- |\n",
    "| **Actually Negative** | TN = 0 ‚úÖ | FP = 91 ‚ùå |\n",
    "| <span style='color:orange'><b>Actually Positive</b></span> | <span style='color:orange'>FN = 0</span> ‚ùå | <span style='color:orange'>TP = 9</span> ‚úÖ |\n",
    "\n",
    "<center><i><small>everyone-has-COVID classifier</small></i></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabf0cb2",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\\text{recall} = \\frac{TP}{TP + FN} = \\frac{9}{9 + 0} = 1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2393bc35",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Like accuracy, recall on its own is not a perfect metric. Even though the classifier we just created has perfect recall, it has 91 false positives!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e348fbf",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Precision\n",
    "\n",
    "| | Predicted Negative | <span style='color:orange'>Predicted Positive</span> |\n",
    "| --- | --- | --- |\n",
    "| **Actually Negative** | TN = 0 ‚úÖ | <span style='color:orange'>FP = 91</span> ‚ùå |\n",
    "| **Actually Positive** | FN = 0 ‚ùå | <span style='color:orange'>TP = 9</span> ‚úÖ |\n",
    "\n",
    "<center><i><small>everyone-has-COVID classifier</small></i></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44888dd3",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The **precision** of a binary classifier is the proportion of <span style='color:orange'><b>predicted positive instances</b></span> that are correctly classified. We'd like this number to be as close to 1 (100%) as possible.\n",
    "\n",
    "$$\\text{precision} = \\frac{TP}{\\text{# predicted positive}} = \\frac{TP}{TP + FP}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8c9c2f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- To compute precision, look at the <span style='color:orange'><b>right (positive) column</b></span> of the above confusion matrix.<br><small>**Tip:** A good way to remember the difference between precision and recall is that in the denominator for üÖøÔ∏èrecision, both terms have üÖøÔ∏è in them (TP and FP).</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3031fdd7",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Note that the \"everyone-has-COVID\" classifier has perfect recall, but a precision of $\\frac{9}{9 + 91} = 0.09$, which is quite low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca46547",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- üö® **Key idea:** There is a \"tradeoff\" between precision and recall. Ideally, you want both to be high. For a particular prediction task, one may be important than the other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89031ebc",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Precision and recall\n",
    "\n",
    "<center><img src=\"imgs/Precisionrecall.svg.png\" width=30%></center>\n",
    "\n",
    "<center>(<a href=\"https://en.wikipedia.org/wiki/Precision_and_recall\">source</a>)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c99eb0",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "### Discussion\n",
    "    \n",
    "$$\\text{precision} = \\frac{TP}{TP + FP} \\: \\: \\: \\:  \\: \\: \\: \\: \\text{recall} = \\frac{TP}{TP + FN}$$\n",
    "    \n",
    "- When might high **precision** be more important than high recall?\n",
    "- When might high **recall** be more important than high precision?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6991e919",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <h3>Activity</h3>\n",
    "\n",
    "\n",
    "Consider the confusion matrix shown below.\n",
    "\n",
    "| | Predicted Negative | Predicted Positive |\n",
    "| --- | --- | --- |\n",
    "| **Actually Negative** | TN = 22 ‚úÖ | FP = 2 ‚ùå |\n",
    "| **Actually Positive** | FN = 23 ‚ùå | TP = 18 ‚úÖ |\n",
    "\n",
    "What is the accuracy of the above classifier? The precision? The recall?\n",
    "\n",
    "<br>\n",
    "\n",
    "After calculating all three on your own, click below to see the answers.\n",
    "\n",
    "<details>\n",
    "    <summary><b>üëâ Accuracy</b></summary>\n",
    "    (22 + 18) / (22 + 2 + 23 + 18) = 40 / 65\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "    <summary><b>üëâ Precision</b></summary>\n",
    "    18 / (18 + 2) = 9 / 10\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "    <summary><b>üëâ Recall</b></summary>\n",
    "    18 / (18 + 23) = 18 / 41\n",
    "</details>    \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a19ab65",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    \n",
    "#### Reference Slide\n",
    "\n",
    "### Combining precision and recall\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1364def",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "- If we care equally about a model's precision $PR$ and recall $RE$, we can combine the two using a single metric called the **F1-score**:\n",
    "\n",
    "$$\\text{F1-score} = \\text{harmonic mean}(PR, RE) = 2\\frac{PR \\cdot RE}{PR + RE}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047dd0b7",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "- Both F1-score and accuracy are overall measures of a binary classifier's performance. But remember, accuracy is misleading in the presence of class imbalance, and doesn't take into account the kinds of errors the classifier makes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f088437",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    \n",
    "#### Reference Slide\n",
    "\n",
    "### Other evaluation metrics for binary classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e557cc35",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "- We just scratched the surface! This [excellent table from Wikipedia](https://en.wikipedia.org/wiki/Template:Diagnostic_testing_diagram) summarizes the many other metrics that exist.\n",
    "\n",
    "<center><img src='imgs/wiki-table.png' width=75%></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac034fb5",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "- If you're interested in exploring further, a good next metric to look at is **true negative rate (i.e. specificity)**, which is the analogue of recall for true negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021d529b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Multiclass classification üêß\n",
    "\n",
    "<center><img src=\"imgs/lter_penguins.png\" width=800>\n",
    "<i><a href=\"https://github.com/allisonhorst/palmerpenguins/blob/main/README.md\">Artwork by @allison_horst</a></i>\n",
    "\n",
    "</center>\n",
    "\n",
    "---\n",
    "\n",
    "To illustrate multiclass classification, we'll revisit the Palmer Penguins dataset we saw earlier in the semester."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724f9f9e",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### From binary to multiclass classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e1a0bc",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In binary classification, there are only two possible classes, typically either 0 or 1.\n",
    "\n",
    "$$y_i \\in \\{0, 1\\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8d5a62",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In multiclass classification, there can be any finite number of classes, or **labels**. They need not be numbers, either.\n",
    "\n",
    "$$y_i \\in \\{ \\text{Adelie}, \\text{Chinstrap}, \\text{Gentoo} \\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbfa4ff",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Loading the data üêß"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63d18d4",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "penguins = sns.load_dataset('penguins').dropna().reset_index(drop=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(penguins[['bill_length_mm', 'body_mass_g', 'bill_depth_mm']], \n",
    "                                                    penguins['species'], \n",
    "                                                    random_state=26)\n",
    "display(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a09097",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Here, each row corresponds to a single penguin."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0927855",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- There are three `'species'` of penguin: Adelie, Chinstrap, and Gentoo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2688a4d7",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fff7959",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Question**: Suppose our goal is to predict the `'species'` of a penguin, given other information.<br> What accuracy would the best \"constant\" classifier achieve on this data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba2d79a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Visualizing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b831dd1",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Visually, it seems that the `'species'` are penguins are well separated based on their physical characteristics (`'bill_depth_mm'`, `'bill_length_mm'`, and `'body_mass_g'`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4592d7d1",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "util.penguin_scatter_3d(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cebfef",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- For simplicity, we'll work with just two features: `'bill_length_mm'` and `'body_mass_g'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a7a5e6",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "util.penguin_scatter_2d(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71e70f9",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Classifier 1: $k$-nearest neighbors üè°üè†"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911ee03c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Let's use the default of $k = 5$.<br><small>Of course, in practice, we _should_ cross-validate.</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6ffd03",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model_knn = KNeighborsClassifier(n_neighbors=5)\n",
    "model_knn.fit(X_train.iloc[:, :-1], y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a3a8f5",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- There are now three colors in the decision boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862acc9a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "util.penguin_decision_boundary(model_knn, X_train, y_train, title=\"k-NN Decision Boundary when k = 5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f40837",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Classifier 2: Decision trees üéÑ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c01eb87",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Let's fix `max_depth=3` so that we can visualize the resulting tree.<br><small>Again, in practice, we _should_ cross-validate.</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aada922",
   "metadata": {
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_tree = DecisionTreeClassifier(max_depth=2)\n",
    "model_tree.fit(X_train.iloc[:, :-1], y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db8e748",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Note that colors below don't directly match the colors in the scatter plot earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537e640a",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "util.penguin_decision_boundary(model_tree, X_train.iloc[:, :-1], y_train, title=\"Decision Boundary for a Decision Tree of Depth 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053a6392",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "util.show_penguin_decision_tree(model_tree, X_train);"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "None",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "livereveal": {
   "scroll": true
  },
  "rise": {
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
