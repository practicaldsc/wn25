{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26dd74a3",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from lec_utils import *\n",
    "import lec24_util as util"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52f592f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-info\" markdown=\"1\">\n",
    "\n",
    "#### Lecture 24\n",
    "\n",
    "# Clustering\n",
    "\n",
    "### EECS 398: Practical Data Science, Winter 2025\n",
    "\n",
    "<small><a style=\"text-decoration: none\" href=\"https://practicaldsc.org\">practicaldsc.org</a> ‚Ä¢ <a style=\"text-decoration: none\" href=\"https://github.com/practicaldsc/wn25\">github.com/practicaldsc/wn25</a> ‚Ä¢ üì£ See latest announcements [**here on Ed**](https://edstem.org/us/courses/69737/discussion/5943734) </small>\n",
    "    \n",
    "</div>\n",
    "\n",
    "<script type=\"text/x-mathjax-config\">\n",
    " MathJax.Hub.Config({\n",
    "   TeX: {\n",
    "     extensions: [\"color.js\"],\n",
    "     packages: {\"[+]\": [\"color\"]},\n",
    "   }\n",
    " });\n",
    " </script>\n",
    " <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS_HTML\"></script>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a987a2",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Please give us feedback! üôè"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7de48f8",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- We're looking for your feedback to help improve the course for future offerings and decide where it sits in the overall EECS/DS curriculum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2010eec6",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- If **at least 85% of the class** fills out **both**:\n",
    "    - This [**internal End-of-Semester Survey**](https://forms.gle/TLomgG6rB3BcLa9s6), **and**\n",
    "    - the [**Official Campus Evaluations**](https://umich.bluera.com/umich/),<br>\n",
    "    \n",
    "    then we will add 1% of extra credit to everyone's overall grade."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd796eb",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- The deadline to fill out both is on **Wednesday, April 23rd at 11:59PM**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f38529",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Agenda üìÜ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12632ee4",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- Today's focus is on **clustering**, an **unsupervised learning** method. We'll focus on $k$-means clustering, the most popular clustering technique, but discuss another clustering technique (agglomerative clustering) as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a60fd52",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- In our final lecture on Monday, we'll more examples of other techniques in machine learning that are small extensions to what we've covered so far."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d2b78f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h3>Question ü§î (Answer at <a style=\"text-decoration: none; color: #0066cc\" href=\"https://docs.google.com/forms/d/e/1FAIpQLSd4oliiZYeNh76jWy-arfEtoAkCrVSsobZxPwxifWggo3EO0Q/viewform\">practicaldsc.org/q</a>)</h3>\n",
    "    \n",
    "Remember that you can always ask questions anonymously at the link above!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d9e10e",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Clustering\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004c965d",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The taxonomy of machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd43f33c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"imgs/taxonomy.svg\" width=600></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bebe30e",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In Lectures 11-19, we focused on building models for **regression**.<br><small>In regression, we predict a **continuous** target variable, $y$, using some features, $X$.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490fcfe1",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In the past few lectures, we switched our focus to building models for **classification**.<br><small>In classification, we predict a **categorical** target variable, $y$, using some features, $X$.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d63d57",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Both regression and classification are **supervised learning** methods.<br><small>In both regression and classification, our goal is to predict $y$ from $X$. The datasets we've used already had a $y$ variable.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614b219f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- What might an **unsupervised learning** problem look like?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d25a99",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: TV show ratings üì∫"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9dc515",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Suppose we have the ratings that several customers of a streaming service gave to two popular TV shows: _Modern Family_ and _Stranger Things_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879b6b0d",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "util.show_ratings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a87225",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The data naturally falls into three groups, or **clusters**, based on users with similar preferences.<br><small>All we're given are the ratings each customer gave to the two shows; the customers aren't already part of any group.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fbfc3a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If we ran the streaming service and could \"identify\" the three clusters, it could help inform us on who to make recommendations to.<br><small>For example, if someone in the bottom-right cluster likes _How I Met Your Mother_, we might recommend it to other members of the bottom-right cluster since they have similar tastes.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527ef82f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **How do we algorithmically determine these clusters**, especially when there are too many dimensions to visualize?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d3efe9",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a4824e",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Goal**: Given a set of $n$ data points stored as vectors in $\\mathbb{R}^d$, $\\vec x_1, \\vec x_2, ..., \\vec x_n$, and a positive integer $k$, **place the data points into $k$ clusters of nearby points**.<br><small>In the scatter plot below, $n = 9$ and $d = 2$.</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d21d08",
   "metadata": {
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "util.show_ratings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9491b0",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Think of clusters as **colors**; in other words, the goal of clustering is to assign each point a color, such that points of the same color are similar to one another."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a556de83",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Note, unlike with regression or classification, there is no \"right answer\" that we're trying to predict ‚Äì there is no $y$! This is what makes clustering **unsupervised**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7a563e",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7b4bba",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Idea: Points in a cluster should be close to the center of the cluster.<br><small>The clustering method we're developing relies on this assumption.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79bd973",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **One** technique for defining clusters involves choosing $k$ cluster centers, known as **centroids**.\n",
    "\n",
    "    $$\\vec \\mu_1, \\vec \\mu_2, ..., \\vec \\mu_k \\in \\mathbb{R}^d$$\n",
    "\n",
    "    For instance, $\\vec \\mu_2$ is the center of cluster 2.<br><small>Cluster 2 might be the set of points colored **<span style=\"color:blue\">blue</span>**, for instance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201489d3",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- These $k$ centroids define the $k$ clusters; **each data point \"belongs\" to the nearest centroid to it**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8ed1e1",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Our problem reduces to finding the **best locations** for the centroids.<br><small>Over the next few slides, we'll visualize several possible sets of centroids and the clusters they define.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18ba390",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "With the following $k = 3$ centroids, the data are colored in the way that we'd expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4e9408",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "util.visualize_centroids([(2, 7), (8, 4), (8, 8)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2bba76",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "But here, even though $k = 3$, the data are not colored \"naturally\"!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c71a82",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "util.visualize_centroids([(2, 7), (8, 4), (3, 7)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ce8491",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Nothing is stopping us from setting $k = 2$, for instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1ababb",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "util.visualize_centroids([(2, 7), (8, 4)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ac0ad1",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Or $k = 5$!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1542f21a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "util.visualize_centroids([(4, 4), (5, 5), (6, 6), (7, 7), (8, 8)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6c9da6",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Reflections on choosing a centroid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa679e96",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Some values of $k$ seemed more intuitive than others; $k$ is a **hyperparameter** that we'll need to tune.<br><small>More on this later.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6305264",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- For a fixed $k$, some clusterings \"looked\" better than others; we'll need a way to quantify this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39b8ab9",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- As we did at the start of the second half of the course, we'll formulate an **objective function** to minimize. Specifically, we'll minimize **inertia**, $I$:\n",
    "\n",
    "$$I(\\vec \\mu_1, \\vec \\mu_2, ..., \\vec \\mu_k) = \\text{total squared distance} \\\\ \\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\: \\text{of each point } \\vec x_i \\\\ \\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\: \\text{ to its closest centroid } \\vec \\mu_j$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3c8022",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Lower values of inertia lead to better clusterings; our goal is to find the set of centroids $\\vec \\mu_1, \\vec \\mu_2, ... \\vec \\mu_k$ that **minimize inertia**, $I$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb39bf08",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "### Activity\n",
    "    \n",
    "Recall, inertia is defined as follows:\n",
    "    \n",
    "$$I(\\vec \\mu_1, \\vec \\mu_2, ..., \\vec \\mu_k) = \\text{total squared distance} \\\\ \\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\: \\text{of each point } \\vec x_i \\\\ \\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\: \\text{ to its closest centroid } \\vec \\mu_j$$\n",
    "    \n",
    "<br>\n",
    "    \n",
    "Suppose we arrange the dataset below into $k = 2$ clusters. What is the **minimum possible inertia**?\n",
    "    \n",
    "<center><img src=\"imgs/example-q.png\" width=500></center>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1fa779",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## $k$-means clustering\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce7ca84",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Minimizing inertia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cb3469",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Goal**: Find the centroids $\\vec \\mu_1, \\vec \\mu_2, ..., \\vec \\mu_k$ that minimize inertia:\n",
    "\n",
    "$$I(\\vec \\mu_1, \\vec \\mu_2, ..., \\vec \\mu_k) = \\text{total squared distance} \\\\ \\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\: \\text{of each point } \\vec x_i \\\\ \\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\: \\text{ to its closest centroid } \\vec \\mu_j$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c47056",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Issue**: There is no efficient way to find the centroids that minimize inertia!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06be3d3",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- There are $k^n$ possible assignments of points to clusters; it would be computationally infeasible to try them all.<br><small>It can be shown that finding the optimal centroid locations is NP-hard.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49c1c13",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We can't use calculus to minimize $I$, either ‚Äì we use calculus to minimize continuous functions, but the assignment of a point $\\vec x_i$ to a centroid $\\vec \\mu_j$ is a discrete operation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1476596",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### $k$-means clustering (i.e. Lloyd's algorithm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646f0955",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Fortunately, there's an efficient algorithm that (tries to) find the centroid locations that minimize inertia. The resulting clustering technique is called **$k$-means clustering**.<br><small>Note that this has no relation to $k$-nearest neighbors, which we used for both regression and classification. Remember that clustering is an unsupervised technique!</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5372b7e",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "0. **Randomly** initialize $k$ centroids.<br><small>There are other ways of initializing the centroids as well.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c5b411",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. Assign each point to the nearest centroid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dccf346",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "2. Move each centroid to the **center** of its group.<br><small>We compute the center of a group by taking the mean of the group's coordinates.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8297ce",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "3. **Repeat** steps 1 and 2 until the centroids stop changing!<br><small>This is an iterative algorithm!</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a8f0fd",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Let's visualize a few iterations ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffd111a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "util.visualize_centroids([(2, 5), (8, 10)], show_color=False, title='Step 0: Random Initialization<br>Red:(2, 5), Blue: (8, 10)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b975ee",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "util.visualize_centroids([(2, 5), (8, 10)], title='Iteration 1, Step 1: Assign each point to the nearest centroid<br>Red:(2, 5), Blue: (8, 10)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e5e0cd",
   "metadata": {
    "deletable": true,
    "editable": true,
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "util.visualize_centroids([(2, 5), (8, 10)], lines=True, title='Iteration 1, Step 1: Assign each point to the nearest centroid<br>Red:(2, 5), Blue: (8, 10); <b>Inertia = Sum(squared distances) = 156.25</b>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4f10dc",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "util.visualize_centroids([(3.6, 6.8), (9.5, 7.125)], lines=True, assignments=[0] * 5 + [1] * 4, title='Iteration 1, Step 2: Move each centroid to the center of its group<br>Red:(3.6, 6.8), Blue: (9.5, 7.125); <b>Inertia = 85.1875</b>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec7b49d",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "util.visualize_centroids([(3.6, 6.8), (9.5, 7.125)], assignments=[0] * 5 + [1] * 4, title='Iteration 1, Step 2: Move each centroid to the center of its group<br>Red:(3.6, 6.8), Blue: (9.5, 7.125); <b>Inertia = 85.1875</b>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81a4615",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "util.visualize_centroids([(3.6, 6.8), (9.5, 7.125)], title='Iteration 2, Step 1: Assign each point to the nearest centroid<br>Red:(3.6, 6.8), Blue: (9.5, 7.125); <b>Inertia = 70.653125</b>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c85d83",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "util.visualize_centroids([(2.5, 7.75), (9.2, 6.3)], title='Iteration 2, Step 2: Move each centroid to the center of its group<br>Red:(2.5, 7.75), Blue: (9.2, 6.3); <b>Inertia = 58.35</b>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c007d6c7",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "util.visualize_centroids([(2.5, 7.75), (9.2, 6.3)], title='Iteration 3, Step 1: Assign each point to the nearest centroid<br>No change, so algorithm terminates!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e4bca8",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Why does $k$-means work?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d98225e",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- On each iteration, **inertia can only stay the same or decrease** ‚Äì it cannot increase.\n",
    "\n",
    "$$I(\\vec \\mu_1, \\vec \\mu_2, ..., \\vec \\mu_k) = \\text{total squared distance} \\\\ \\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\: \\text{of each point } \\vec x_i \\\\ \\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\: \\text{ to its closest centroid } \\vec \\mu_j$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481f95a1",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Why? Step 2 and step 3 **alternate** minimizing inertia in different ways:\n",
    "    - In Step 2, we assign each point to the nearest centroid; this reduces the squared distance of each point to its closest centroid.\n",
    "    - In Step 3, we move the centroids to the **center (mean position)** of their groups; this reduces the total **squared** distance from a centroid to the points assigned to it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5035cee",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Since there are only finitely many possible assignments of points to clusters, eventually the algorithm will terminate at some **potentially local** minimum.<br><small>Read more on the theory [**here**](https://www.cs.toronto.edu/~rgrosse/courses/csc311_f21/lectures/lec11.pdf).</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec57fe6",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Let's experiment!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9379a7f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Let's visualize more runs of the algorithm [**here**](https://www.naftaliharris.com/blog/visualizing-k-means-clustering).\n",
    "\n",
    "<center><img src=\"imgs/smiley.png\" width=500></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a636a4",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- To replicate the picture above, select \"I'll Choose\" and \"Smiley Face.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b2eeb2",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### In what sense is $k$-means _optimal_?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5431385c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The algorithm discussed **isn't guaranteed** to find the centroids that minimize inertia; depending on the initially-chosen centroids, it may converge at a local minimum.<br><small>One solution is $k$-means++, which picks one centroid randomly and chooses the others in a way that maximizes distance from existing centroids. Read more [here](https://en.wikipedia.org/wiki/K-means%2B%2B).</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706957a5",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Even if $k$-means \"works\", the resulting clustering might not look \"right\" to humans. That is, the clustering that minimizes inertia doesn't necessarily look correct to us.<br><small>Remember, the core assumption in $k$-means is that **points in a cluster should be close to the center of the cluster**. This assumption isn't always true!</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b110acc",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Choosing the number of clusters\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd56276",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Choosing $k$ in $k$-means clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace8d12a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Given a dataset, how do we choose $k$, the number of clusters to use?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1361d9",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The larger the value of $k$, the smaller inertia is.\n",
    "\n",
    "$$I(\\vec \\mu_1, \\vec \\mu_2, ..., \\vec \\mu_k) = \\text{total squared distance} \\\\ \\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\: \\text{of each point } \\vec x_i \\\\ \\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\: \\text{ to its closest centroid } \\vec \\mu_j$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68794a3a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If $k = n$, then each point is a centroid, and inertia is 0!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8186a3",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- But, the goal of clustering is to put the data into groups, so a large number of groups may not be meaningful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8153f8",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "util.show_ratings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6124978f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The elbow method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb13e43e",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- For several different values of $k$, let's compute the inertia of the resulting clustering, using the scatter plot from the previous slide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618cb830",
   "metadata": {
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "util.show_elbow()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6aae72",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The **elbow method** says to choose the $k$ that appears at the elbow of the plot of inertia vs. $k$, since there are diminishing returns for using more than $k$ clusters.<br><small>Above, we see an elbow at $k = 3$, which gives us the $k$ that matches our natural intuition in this example.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c50251c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In practice, the data may not have natural clusters, so the choice of $k$ may not be so obvious.<br><small>And, there may be other business reasons to choose a specific value of $k$, e.g. if you're told to categorize customers of a clothing item into 5 groups: XS, small, medium, large, XL.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4a16c5",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h3>Question ü§î (Answer at <a style=\"text-decoration: none; color: #0066cc\" href=\"https://docs.google.com/forms/d/e/1FAIpQLSd4oliiZYeNh76jWy-arfEtoAkCrVSsobZxPwxifWggo3EO0Q/viewform\">practicaldsc.org/q</a>)</h3>\n",
    "    \n",
    "Remember that you can always ask questions anonymously at the link above!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9c6a76",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: World Bank data üåé\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faee4c15",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d822c075",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Below, we load in a dataset containing hundreds of attributes per country, taken from the [World Bank](https://databank.worldbank.org/source/world-development-indicators#)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb06a46",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "world_bank = pd.read_csv('data/world_bank_data.csv').set_index('country').fillna(0)\n",
    "world_bank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e77e95",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- There are $d = 209$ features, far too many to visualize before clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51f52b8",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "world_bank.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edf53af",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Dimensionality reduction** is another form of unsupervised learning that would help us visualize the data; we'll explore it briefly next class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f98927f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The elbow method, revisited"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6831b96c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- How many clusters should we use? We'll need to resort to the elbow method, since we can't visualize the data to see how many \"natural\" clusters there are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886d20f5",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "util.show_elbow_world_bank(world_bank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b4a0c7",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The choice is a bit more ambiguous than before; here, we'll use $k = 6$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25938c4",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Clustering in `sklearn`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427054c0",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- To create our clusters, we'll use `KMeans` in `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ed20aa",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9db5e8",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Like other models we've used in `sklearn`, we need to instantiate and fit a `KMeans` object. The difference is that the `fit` method only takes in a single `X`, not an `X` and `y`.<br><small>$k$-means is an unsupervised method, so there is no `y`.</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6032311b",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# The default value of k is 8; we should generally specify another value.\n",
    "# We fix a random_state for reproducibility; remember the centroids are generally initialized randomly.    \n",
    "model = KMeans(n_clusters=6, random_state=15)\n",
    "model.fit(world_bank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb43da26",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- A fit `KMeans` instance has a `predict` method. It outputs the cluster whose centroid the data point is closest to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39d319a",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model.predict(world_bank.loc[['United States']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6a1571",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# It seems that the US and Canada are assigned to different clusters!\n",
    "model.predict(world_bank.loc[['Canada']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65689451",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Inspecting clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558e6e76",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We can view the countries assigned to each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dddbe7e",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "countries_and_clusters = pd.Series(model.labels_, index=world_bank.index)\n",
    "util.list_countries_by_cluster(countries_and_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03441743",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- It seems that the vast majority of countries are assigned to the same cluster!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118b5b59",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Visualizing clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9cde3f",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "util.country_choropleth(countries_and_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c3044b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Standardize before clustering!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f583561",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Clustering, like $k$-nearest neighbors and regularization, is a **distance-based method**, meaning that it **depends on the scale of the data**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff11347e",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In `world_bank`, some features are in the millions or billions, while some are in the single digits. The larger features will influence cluster membership more than the smaller features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180ddaca",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "world_bank.iloc[[1], -9:-5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a766633e",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Solution**: Standardize before clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1930554",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f288a21",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model_std = make_pipeline(StandardScaler(), KMeans(n_clusters=6, random_state=15)) # We fix a random state for reproducibility.\n",
    "model_std.fit(world_bank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91a513b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Once we standarize, the sizes of the clusters seem to be a bit more evenly distributed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7faff9",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "countries_and_clusters_std = pd.Series(model_std[-1].labels_, index=world_bank.index)\n",
    "util.list_countries_by_cluster(countries_and_clusters_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9dfc9c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Visualizing clusters after standardizing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853713af",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Note that the colors themselves are arbitrary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57aaab88",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "util.country_choropleth(countries_and_clusters_std, title='after Standardizing')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62680ce",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Agglomerative clustering\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd9da55",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Overview of clustering methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0255f7c9",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- `sklearn` supports many different clustering methods! Read about them all [**here**](https://scikit-learn.org/1.5/modules/clustering.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a55bd91",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"imgs/clustering-methods.png\" width=800></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ee7315",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Remember the \"no free lunch theorem\" ‚Äì there isn't a clustering method that is **always** better than all other clustering methods. It depends on the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279538b9",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Agglomerative clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a14e25",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Let's revisit the ratings dataset from earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca20d59",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "util.show_ratings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb98954",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Agglomerative clustering**, a form of **hierarchical clustering**, creates clusters by:\n",
    "    1. Starting with each point as its own cluster.\n",
    "    2. Repeatedly **combining the two closest clusters** until there are only $k$ clusters remaining."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d6f9c1",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Let's visualize it in the context of this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201fbd1c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "util.color_ratings(title='Iteration 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bff00d",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The two closest clusters are <b><span style=\"color:brown\">cluster 7</span></b> and <b><span style=\"color:navy\">cluster 8</span></b>, so we merge them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e830e8f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "util.color_ratings(title='Iteration 1', labels=[0, 1, 2, 3, 4, 5, 6, 7, 7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d4cfe6",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Now, the two closest clusters are <b><span style=\"color:cyan\">cluster 5</span></b> and <b><span style=\"color:magenta\">cluster 6</span></b>, so we merge them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390feed6",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "util.color_ratings(title='Iteration 2', labels=[0, 1, 2, 3, 4, 5, 5, 7, 7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2140d5",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- It's not clear what the next merge should be ‚Äì should <b><span style=\"color:orange\">cluster 4</span></b> merge with <b><span style=\"color:cyan\">cluster 5</span></b> or should <b><span style=\"color:green\">cluster 2</span></b> merge with <b><span style=\"color:purple\">cluster 3</span></b>?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c65790",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Linkage criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1c9a99",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We need a way to measure the distance between two clusters.<br><small>For example, what is the \"distance\" between <b><span style=\"color:orange\">cluster 4</span></b> and <b><span style=\"color:cyan\">cluster 5</span></b> below?</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adec2678",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "util.color_ratings(title='Iteration 2', labels=[0, 1, 2, 3, 4, 5, 5, 7, 7], width=500, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0b7574",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The **linkage criteria** determines how to compute the distance between  two clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00883db",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Some examples:\n",
    "    - Average linkage: The average distance between points in both clusters.\n",
    "    - Single linkage: The minimum distance between points in both clusters.\n",
    "    - Complete linkage: The maximum distance between points in both clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089cf86c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "util.color_ratings(title='Iteration 2', show_distances=[(1, 3), (0, 2), (0, 1), (2, 3), (4, 5)], labels=[0, 1, 2, 3, 4, 5, 5, 7, 7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05176dd3",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We'll use single linkage, i.e.:\n",
    "\n",
    "$$\\text{distance(cluster $A$, cluster $B$)} = \\text{minimum distance between} \\\\ \\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\: \\text{any point in $A$ and any point in $B$}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8fde5c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Here, there are lots of ties; we'll arbitrarily choose to merge <b><span style=\"color:orange\">cluster 4</span></b> and <b><span style=\"color:cyan\">cluster 5</span></b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902c6f93",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "util.color_ratings(title='Iteration 3', show_distances=[(0, 2), (2, 3)], labels=[0, 1, 2, 3, 5, 5, 5, 7, 7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f40c64",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Again, there's a tie; we'll arbitrarily choose to merge <b><span style=\"color:green\">cluster 2</span></b> and <b><span style=\"color:purple\">cluster 3</span></b>.<br><small>We could have also merged <b><span style=\"color:green\">cluster 2</span></b> and <b><span style=\"color:red\">cluster 0</span></b>, since their minimum distance is also the same.</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85bb3f0",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "util.color_ratings(title='Iteration 4', show_distances=[(0, 2), (1, 2)], labels=[0, 1, 2, 2, 5, 5, 5, 7, 7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82641239",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Next, we merge <b><span style=\"color:green\">cluster 2</span></b> and <b><span style=\"color:red\">cluster 0</span></b>.<br><small>Why? Because the minimum distance between <b><span style=\"color:red\">cluster 0</span></b> and <b><span style=\"color:green\">cluster 2</span></b> is less than the minimum distance between <b><span style=\"color:blue\">cluster 1</span></b> and <b><span style=\"color:green\">cluster 2</span></b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab13c52",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "util.color_ratings(title='Iteration 5', labels=[2, 1, 2, 2, 5, 5, 5, 7, 7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c11373",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- And finally, we merge <b><span style=\"color:green\">cluster 2</span></b> and <b><span style=\"color:blue\">cluster 1</span></b>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9278b367",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If we just want $k = 3$ clusters, we stop here! If we wanted $k = 2$ clusters, we'd then merge the two closest clusters, based on the single linkage criterion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41f6dbe",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### $k$-means vs. agglomerative clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088b1424",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- On what sorts of datasets does agglomerative clustering perform better than $k$-means clustering?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef96399",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "util.show_scatter_comp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877a23ad",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "util.show_scatter_comp_k_means(k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0c3209",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Note that $k$-means clustering optimizes for inertia, not \"blobiness.\"<br>It doesn't work well when the natural clusters are of uneven sizes.<br><small>Read more [**here**](https://stats.stackexchange.com/questions/133656/how-to-understand-the-drawbacks-of-k-means).</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8766214",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "util.show_scatter_comp_agg(k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac570d9",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Another metric that's used to compare different clusterings is the **silhouette score**.<br><small>Read more [**here**](https://en.wikipedia.org/wiki/Silhouette_(clustering)).</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6120440",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h3>Question ü§î (Answer at <a style=\"text-decoration: none; color: #0066cc\" href=\"https://docs.google.com/forms/d/e/1FAIpQLSd4oliiZYeNh76jWy-arfEtoAkCrVSsobZxPwxifWggo3EO0Q/viewform\">practicaldsc.org/q</a>)</h3>\n",
    "    \n",
    "Remember that you can always ask questions anonymously at the link above!"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "None",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "livereveal": {
   "scroll": true
  },
  "rise": {
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
