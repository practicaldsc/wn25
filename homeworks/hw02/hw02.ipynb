{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80fdb1d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"hw02.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f06da3e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" markdown=\"1\">\n",
    "\n",
    "#### Homework 2\n",
    "\n",
    "# Arrays, Probability, and DataFrames\n",
    "\n",
    "### EECS 398: Practical Data Science, Winter 2025\n",
    "\n",
    "#### Due Tuesday, January 28th at 11:59PM\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce62537",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "Welcome to Homework 2! In this homework, you will practice with `numpy` arrays, linear algebra, and random simulations, as in Lecture 3. You'll also start to understand the connection between probability and machine learning, using your understanding of EECS 203 material. Finally, you'll start to work with real, tabular data using the `pandas` library.\n",
    "\n",
    "You are given 8 slip days throughout the semester to extend deadlines. See the [Syllabus](https://practicaldsc.org/syllabus) for more details. With the exception of using slip days, late work will not be accepted unless you have made special arrangements with your instructor.\n",
    "\n",
    "To access this notebook, you'll need to clone our [public GitHub repository](https://github.com/practicaldsc/wn25/). The [Environment Setup](https://practicaldsc.org/env-setup) page on the course website walks you through the necessary steps. Once you're done, you'll submit your completed notebook to Gradescope.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "This homework features a mix of autograded programming questions and manually-graded questions.\n",
    "\n",
    "- Questions 1.4 and 3 are **manually graded**, and say **[Written ‚úèÔ∏è]** in their titles. For this question, **do not write your answers in this notebook**! Instead, write **all** of your answers in a separate PDF. You can create this PDF either digitally, using your tablet or using [Overleaf + LaTeX](https://overleaf.com) (or some other sort of digital document), or by writing your answers on a piece of paper and scanning them in. Submit this separate PDF to the **Homework 2 (Questions 1.4, 3; written problems)** assignment on Gradescope, and **make sure to correctly select the pages associated with each question**! Make sure to show your work for all written questions, as answers without work shown may not receive full credit.\n",
    "    \n",
    "- Questions 1.1-1.3, 2, and 4-6 are **fully autograded**, and say **[Autograded üíª]** in the title. For these questions, all you need to is write your code in this notebook, run the local `grader.check` tests, and submit to the **Homework 2 (Questions 1.1-1.3, 2, 4-6; autograder problems)** assignment on Gradescope to have your code graded by the hidden autograder. Remember that the public `grader.check` tests in your notebook are not comprehensive, and that your work will also be graded on hidden test cases on Gradescope after the submission deadline.\n",
    "    \n",
    "Your Homework 2 submission time will be the **later** of your two individual submissions. Please start early and submit often. You can submit as many times as you'd like to Gradescope, and we'll take your **most recent** submission. \n",
    "</div>\n",
    "</div>\n",
    "\n",
    "This homework is worth a total of **63 points**, 49 of which come from the autograder, **and 14 of which are manually graded by us** (Questions 1.4, 3). The number of points each question is worth is listed at the start of each question. **The three parts of the assignment are independent, so feel free to move around if you get stuck**. Tip: if you're using Jupyter Lab, you can see a Table of Contents for the notebook by going to View > Table of Contents.\n",
    "\n",
    "To get started, run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498f3f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "\n",
    "# Preferred styles\n",
    "pio.templates[\"pds\"] = go.layout.Template(\n",
    "    layout=dict(\n",
    "        margin=dict(l=30, r=30, t=30, b=30),\n",
    "        autosize=True,\n",
    "        width=600,\n",
    "        height=400,\n",
    "        xaxis=dict(showgrid=True),\n",
    "        yaxis=dict(showgrid=True),\n",
    "        title=dict(x=0.5, xanchor=\"center\"),\n",
    "    )\n",
    ")\n",
    "pio.templates.default = \"simple_white+pds\"\n",
    "\n",
    "set_matplotlib_formats(\"svg\")\n",
    "sns.set_context(\"poster\")\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 5)\n",
    "\n",
    "# Use plotly as default plotting engine\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb55e84c",
   "metadata": {},
   "source": [
    "## Question 1: PageRank üîó\n",
    "\n",
    "---\n",
    "\n",
    "In this part of the homework, you'll replicate the PageRank algorithm, the algorithm that Google uses to decide how to rank search results. Along the way, you'll develop proficiency with using arrays in the context of linear algebra.\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "\n",
    "To get started, read [**this guide**](https://practicaldsc.org/guides/linear-algebra/pagerank) we've written about the PageRank algorithm. Think of it as an extension of the homework spec. It involves linear algebra but is self-contained.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf98b3c5",
   "metadata": {},
   "source": [
    "We'll start by defining a 2D array, `A`, representing the adjacency matrix defined in the guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee1dfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[0, 1 / 2, 1 / 2, 1 / 3],\n",
    "              [1, 0, 0, 1 / 3],\n",
    "              [0, 0, 0, 1 / 3],\n",
    "              [0, 1 / 2, 1 / 2, 0]])\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3385122a",
   "metadata": {},
   "source": [
    "The function below draws a network given an adjacency matrix. Run the cell below to see a visualization of `A`'s network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096a52cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_from_adjacency(adjacency_matrix, node_sizes=0.25):\n",
    "    np.random.seed(25)\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    G = nx.from_numpy_array(adjacency_matrix.T, create_using=nx.DiGraph)\n",
    "    layout = nx.spring_layout(G)\n",
    "    labels_dict={i: i+1 for i in range(adjacency_matrix.shape[0])}\n",
    "    nx.draw(G, layout, \n",
    "            node_size=15000 * node_sizes, labels=labels_dict, with_labels=True, font_color='white', font_weight='bold', font_size=15, \n",
    "            connectionstyle='arc3, rad = 0.1')\n",
    "    plt.show()\n",
    "\n",
    "plot_from_adjacency(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f8152f",
   "metadata": {},
   "source": [
    "This graph should resemble the one shown in the aforementioned guide, but was generated using code. Cool!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11face6c",
   "metadata": {},
   "source": [
    "### Question 1.1 [Autograded üíª] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">4 Points</div>\n",
    "\n",
    "Having to specify an adjacency matrix manually is slightly cumbersome. It is more natural and convenient for us to describe the links between webpages using a dictionary. Once such example is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de4d54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_net = {\n",
    "    1: [2],\n",
    "    2: [1, 4],\n",
    "    3: [1, 4],\n",
    "    4: [1, 2, 3]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7049231",
   "metadata": {},
   "source": [
    "In the above \"network dictionary\", we are told that:\n",
    "- Page 1 links to Page 2.\n",
    "- Page 2 links to Pages 1 and 4.\n",
    "- Page 3 links to Pages 1 and 4.\n",
    "- Page 4 links to Pages 1, 2, and 3.\n",
    "\n",
    "**Note that this dictionary describes the same network that the adjacency matrix `A` does.**\n",
    "\n",
    "Below, complete the implementation of the function `create_adjacency`, which takes in a network dictionary, `network` (formatted similarly to `example_net`) and returns the adjacency matrix that corresponds to `network`. Example behavior is given below.\n",
    "\n",
    "```python\n",
    ">>> create_adjacency(example_net)\n",
    "array([[0.        , 0.5       , 0.5       , 0.33333333],\n",
    "       [1.        , 0.        , 0.        , 0.33333333],\n",
    "       [0.        , 0.        , 0.        , 0.33333333],\n",
    "       [0.        , 0.5       , 0.5       , 0.        ]])\n",
    "```\n",
    "\n",
    "A few notes:\n",
    "- It is **not** guaranteed that there are 4 pages in the network. \n",
    "- It **is** guaranteed that all pages link to at least one page ‚Äì potentially itself ‚Äì and that there is at least one page.\n",
    "- Remember that adjacency matrices are 1-indexed, like in math, but Python is 0-indexed.\n",
    "\n",
    "Some guidance:\n",
    "- Look into `np.zeros`.\n",
    "- You can use (multiple) `for`-loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8449ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_adjacency(network):\n",
    "    ...\n",
    "\n",
    "# Feel free to change this input to make sure your function works correctly.\n",
    "create_adjacency(example_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db852b7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q01_01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a686ed",
   "metadata": {},
   "source": [
    "### Question 1.2 [Autograded üíª] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">2 Points</div>\n",
    "\n",
    "Complete the implementation of the function `compute_scores`, which takes in an adjacency matrix `matrix` of shape `(n, n)`, where `n` is a positive integer, and returns an array of length `n` containing the PageRank scores of all pages. Compute the PageRank scores using a matrix power of 100, as we did in the linked [**guide**](https://practicaldsc.org/guides/linear-algebra/pagerank). Example behavior is given below.\n",
    "\n",
    "```python\n",
    "# Remember, compute_scores should work for any adjacency matrix, not just A!\n",
    ">>> compute_scores(A)\n",
    "array([0.30769231, 0.38461538, 0.07692308, 0.23076923])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6524a17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_scores(matrix):\n",
    "    ...\n",
    "\n",
    "# Feel free to change this input to make sure your function works correctly.\n",
    "compute_scores(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfeaafe5",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q01_02\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0da686e",
   "metadata": {},
   "source": [
    "We can change the sizes of the pages in our network to be proportional to their PageRank scores. To do this, use the `node_sizes` argument in `plot_from_adjacency`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60086f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_from_adjacency(A, node_sizes=compute_scores(A))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af179b2",
   "metadata": {},
   "source": [
    "### Question 1.3 [Autograded üíª] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">2 Points</div>\n",
    "\n",
    "Complete the implementation of the function `pagerank`, which takes in an adjacency matrix `matrix` of shape `(n, n)`, where `n` is a positive integer, and returns a list containing the **numbers** of the pages in the matrix, in **decreasing** order of PageRank score as computed by `compute_scores`. If there are ties in scores, return the pages in any order. Example behavior is given below.\n",
    "\n",
    "```python\n",
    ">>> pagerank(A)\n",
    "[2, 1, 4, 3]\n",
    "```\n",
    "\n",
    "Some guidance:\n",
    "- Look into `np.argsort`.\n",
    "- This should only take 2-3 lines; do not write a `for`-loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828bd2a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pagerank(matrix):\n",
    "    ...\n",
    "\n",
    "# Feel free to change this input to make sure your function works correctly.\n",
    "pagerank(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640fcc82",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q01_03\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f01b2fc",
   "metadata": {},
   "source": [
    "Once you've completed `pagerank`, run the following cell to visualize your work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf47dee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's another example network, which you can use to test your code.\n",
    "test_net = {1: [6], 2: [1, 3, 4, 6], 3: [2, 5, 6], 4: [1], 5: [1, 2, 6], 6: [2, 4]}\n",
    "print(test_net)\n",
    "test_net_adjacency = create_adjacency(test_net)\n",
    "test_net_scores = compute_scores(test_net_adjacency)\n",
    "plot_from_adjacency(test_net_adjacency, node_sizes=test_net_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da148ba2",
   "metadata": {},
   "source": [
    "### Question 1.4: Sinkholes [Written ‚úèÔ∏è] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">3 Points</div>\n",
    "\n",
    "Let's wrap up this question with a puzzle. Consider the following network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b370af",
   "metadata": {},
   "outputs": [],
   "source": [
    "weird_net = {\n",
    "    1: [1],\n",
    "    2: [1, 3, 5],\n",
    "    3: [2, 4],\n",
    "    4: [1, 2, 3],\n",
    "    5: [3]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc66ed66",
   "metadata": {},
   "source": [
    "Note that Page 1 links to itself and to no other pages. Practically speaking, we can interpret Page 1 as being a \"dead end\" or \"sinkhole\", with no outgoing links.\n",
    "\n",
    "Run the cells below to compute the adjacency matrix and scores for the above network and to visualize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef4a111",
   "metadata": {},
   "outputs": [],
   "source": [
    "weird_matrix = create_adjacency(weird_net)\n",
    "weird_scores = compute_scores(weird_matrix)\n",
    "print(weird_scores)\n",
    "plot_from_adjacency(weird_matrix, node_sizes=weird_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa30ef7",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "It appears that Page 1's score is 1, and all of the other pages' scores are 0! (`9.6409e-10` means $9.64 \\cdot 10^{-10}$, which is a really, really small number.)\n",
    "\n",
    "In your PDF submission, write your answers to the following two manually-graded prompts:\n",
    "\n",
    "- Why do you think Page 1's score is so high, and the other pages' scores are so low? (***Hint:*** Think about how we interpret the score of a page.)\n",
    "- Read the [Damping factor](https://en.wikipedia.org/wiki/PageRank#Damping_factor) section of the Wikipedia article on PageRank. In two sentences, describe (to the best of your ability) how using damping would prevent the score of Page 1 from becoming 1. (If you read the article closely, the answer is there ‚Äì describe it in your own words.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a7ac50",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## Question 2: Euchre Returns! üÉè\n",
    "\n",
    "---\n",
    "\n",
    "In this question, we'll practice simulating various probabilities in the context of the popular card game, [Euchre](https://www.wikihow.com/Play-Euchre)!\n",
    "\n",
    "Euchre, as you may have seen in EECS 280, is a 4-player card game, in which the players are named Player 0, Player 1, Player 2, and Player 3. Euchre is played with a deck of **24 cards**. Each card has two attributes:\n",
    "- a **suit**, which is either hearts (<span style=\"color:red\">‚ù§Ô∏è</span>), diamonds (<span style=\"color:red\">‚ô¶Ô∏è</span>), clubs (‚ô£), or spades (‚ô†).\n",
    "- a **face value**, which is either 9, 10, Jack (J), Queen (Q), King (K), or Ace (A).\n",
    "\n",
    "The full deck of 24 cards is shown below.\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "<span style=\"color:red\">‚ù§Ô∏è: 9, 10, J, Q, K, A</span><br>\n",
    "<span style=\"color:red\">‚ô¶Ô∏è: 9, 10, J, Q, K, A</span><br>\n",
    "<span style=\"color:black\">‚ô£: 9, 10, J, Q, K, A</span><br>\n",
    "<span style=\"color:black\">‚ô†: 9, 10, J, Q, K, A</span><br>\n",
    "\n",
    "</center>\n",
    "\n",
    "The 24 cards are all different. The list `deck`, defined below, represents our deck of 24 cards. Each element in deck is a string representing a card, in the format `'{face} {suit}'`.\n",
    "\n",
    "Note that you don't need to know how Euchre is played, beyond what is explained above, to work on the following question. (Suraj has never taken EECS 280 or played Euchre before, either.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3430a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do NOT edit this cell! \n",
    "# In our hidden tests, we will assume deck is defined exactly as below.\n",
    "suits = ['Hearts', 'Diamonds', 'Clubs', 'Spades']\n",
    "faces = ['9', '10', 'J', 'Q', 'K', 'A']\n",
    "deck = [f'{face} {suit}' for suit in suits for face in faces]\n",
    "deck"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4148c153",
   "metadata": {},
   "source": [
    "At the start of a round of Euchre, the 24 cards are randomly distributed to the 4 players such that each player gets 5 cards, and the remaining 4 cards ($24 - 5 \\cdot 4 = 4$) are put to the side. \n",
    "\n",
    "You should use functions built into `np.random` to simulate the act of shuffling and distributing cards, but be careful about the arguments you provide to these functions and the assumptions they make. You're free to define helper functions to use throughout your work, too ‚Äì **we did this ourselves** ‚Äì and you'll need to research various string, list, array, and `np.random` functions and methods to get this all to work.\n",
    "\n",
    "Your answers will be (very) slightly different than those of your peers, and slightly different each time you run your notebook, due to randomness. This is expected, and our autograder tests will account for this. **Don't** work out the math by hand ‚Äì that isn't the point of these questions, rather the point is to build your fluency in simulating."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f85dc90",
   "metadata": {},
   "source": [
    "### Question 2.1 [Autograded üíª] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">5 Points</div>\n",
    "\n",
    "Complete the implementation of the function `prob_at_least_k_same_suit`, which takes in an integer `k` and returns a simulated estimate of the **probability that Player 0 ends up with at least $k$ cards of the same suit**. Remember, the 24 cards in the Euchre deck (`deck`) are distributed such that Player 0, Player 1, Player 2, and Player 3 each receive 5 cards, and 4 cards are put to the side.\n",
    "\n",
    "Example behavior is given below.\n",
    "\n",
    "```python\n",
    ">>> prob_at_least_k_same_suit(4)\n",
    "0.02693\n",
    "\n",
    "# Each time we call prob_at_least_k_same_suit with the same input,\n",
    "# we should see a slightly different result.\n",
    ">>> prob_at_least_k_same_suit(4)\n",
    "0.02591\n",
    "```\n",
    "\n",
    "Some extra guidance:\n",
    "- Use 100,000 repetitions in your simulation.\n",
    "- If `k` is negative or `0`, return `0`. If `k` is greater than the number of cards given to Player 0, return `0`. (Note that there are some values of `k` for which you'll always end up returning `1` ‚Äì it's useful to think about which values of `k` these are. Think back to the pigeonhole principle from EECS 203!)\n",
    "- Look at the default `replace` argument in `np.random.choice` ‚Äì you may need to set this to something else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aebb523",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prob_at_least_k_same_suit(k):\n",
    "    ...\n",
    "\n",
    "# Feel free to change this input to make sure your function works correctly.\n",
    "# Each time you run this cell, you should see a slightly different result!\n",
    "prob_at_least_k_same_suit(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc798e17",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q02_01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49dedbb6",
   "metadata": {},
   "source": [
    "### Question 2.2 [Autograded üíª] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">5 Points</div>\n",
    "\n",
    "Complete the implementation of the function `prob_all_one_jack`, which takes no arguments and returns a simulated estimate of the **probability that each player ends up with exactly one Jack (J)**.\n",
    "\n",
    "Again, use 100,000 repetitions in your simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe4e705",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prob_all_one_jack():\n",
    "    ...\n",
    "\n",
    "# Each time you run this cell, you should see a slightly different result!\n",
    "prob_all_one_jack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211bee74",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q02_02\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4fad63",
   "metadata": {},
   "source": [
    "## Question 3: Probability ü§ù Machine Learning\n",
    "\n",
    "---\n",
    "\n",
    "In this question, we'll introduce you to a key idea machine learning and statistics, called **maximum likelihood estimation**.\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "\n",
    "To get started, read [**this guide**](https://practicaldsc.org/guides/machine-learning/mle) we've written about the method of maximum likelihood estimation. Think of it as an extension of the homework spec.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d25db72",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 3.1 [Written ‚úèÔ∏è] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">2 Points</div>\n",
    "\n",
    "When you step on campus, each person you see has a $0.1$ chance of saying \"Go Blue!\" to you, independent of all other people.\n",
    "\n",
    "Tomorrow, what's the probability that the first person to say \"Go Blue!\" to you is the **6th** person you see?\n",
    "\n",
    "Leave your answer in unsimplified form. This question should not take very long; think back to the probability distributions you learned in EECS 203 (other than the binomial distribution)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb6c6ed",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 3.2 [Written ‚úèÔ∏è] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">2 Points</div>\n",
    "\n",
    "Again, assume that the probability that each person you see has a $0.1$ chance of saying \"Go Blue!\" to you, independent of all other people. \n",
    "\n",
    "What's the probability that:\n",
    "- the first person to say \"Go Blue!\" to you tomorrow is the **6th** person you see, **and**\n",
    "- the first person to say \"Go Blue!\" to you the day after tomorrow is the **10th** person you see, **and**\n",
    "- the first person to say \"Go Blue!\" to you the day after that is the **2nd** person you see?\n",
    "\n",
    "Again, leave your answer in unsimplified form. Note that we're asking for a single probability, not three separate probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e3bc9a",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 3.3 [Written ‚úèÔ∏è] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">4 Points</div>\n",
    "\n",
    "Now, suppose that the probability that each person you see says \"Go Blue!\" to you is some **unknown parameter**, $\\pi$. (That is, $0.1$ will not appear in the rest of this question.)\n",
    "\n",
    "Suppose you go to campus on $n$ straight days, and you collect a dataset $x_1, x_2, ..., x_n$, where:\n",
    "- On Day 1, the first person to say \"Go Blue!\" to you is the $x_1$th person you saw (or \"person $x_1$\"), **and**\n",
    "- On Day 2, the first person to say \"Go Blue!\" to you is person $x_2$, **and**,\n",
    "- On Day 3, the first person to say \"Go Blue!\" to you is person $x_3$, **and** so on.\n",
    "- In general, for $i = 1, 2, ..., n$, on Day $i$, the first person to say \"Go Blue!\" to you is person $x_i$.\n",
    "\n",
    "For example, the dataset $x_1 = 5, x_2 = 10, x_3 = 2$ would mean that on Day 1, person 5 was the first to say \"Go Blue!\"; on Day 2, person 10 was the first to say \"Go Blue!\"; and on Day 3, person 2 was the first to say \"Go Blue!\".\n",
    "\n",
    "Show that $\\log L(\\pi)$, the log of the likelihood function for $\\pi$, is:\n",
    "\n",
    "$$\\log L(\\pi) = \\log(1 - \\pi) \\sum_{i = 1}^n (x_i - 1) + n \\log \\pi$$\n",
    "\n",
    "Some guidance: Try and generalize the calculation you made in Question 3.2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ad1676",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 3.4 [Written ‚úèÔ∏è] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">3 Points</div>\n",
    "\n",
    "Using the result to Question 3.3, find $\\pi^*$, the maximum likelihood estimate of $\\pi$ given the dataset $x_1, x_2, ..., x_n$. Once you've done that, give a brief English explanation of why the value of $\\pi^*$ makes intuitive sense."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860129c1",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## Questions 4-6: Movies üé•\n",
    "\n",
    "---\n",
    "\n",
    "In the final three questions of the homework, we'll build our skills in working with DataFrames in `pandas`.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Questions 4-6 will rely on knowing the basics of `pandas`. As of this homework being released, we haven't yet covered `pandas`. We will cover the material necessary for these questions in Lecture 4 on Wednesday, January 22nd, which will give you enough time to complete them before the deadline of Tuesday, January 28th. If you'd like to get a head start, you can navigate to last semester's course website (see the [Archive](https://practicaldsc.org/archive) tab of the course website) to find the relevant materials.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76151ed",
   "metadata": {},
   "source": [
    "Run the cell below to load in a dataset with information about various movies from [IMDb](https://www.imdb.com/), the Internet Movie Database. (The dataset comes from [Kaggle](https://www.kaggle.com/datasets/parthdande/imdb-dataset-2024-updated))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8ad531",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb = pd.read_csv('data/imdb-2024-cleaned.csv')\n",
    "imdb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5ce764",
   "metadata": {},
   "source": [
    "As the preview above shows us, `imdb` has 255 rows, and has some brand new movies, like `'A Quiet Place: Day One'`, released earlier this year.\n",
    "\n",
    "Not sure what one of the columns means? Google it, as data scientists do ‚Äì you'll find helpful information directly on IMDb's website.\n",
    "\n",
    "In lecture, we'll learn that it's good practice to set the index of a DataFrame to a unique identifier for each row, if one exists. At first glance, it may seem like the values in the `'Title'` column are unique, but upon further investigation we see that there are actually duplicate `'Title'`s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a535910",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb['Title'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eef6922",
   "metadata": {},
   "source": [
    "There are 2 rows for `'Planet of the Apes'`, for example. We can query to see just those rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be73f29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb[imdb['Title'] == 'Planet of the Apes']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6c6ecb",
   "metadata": {},
   "source": [
    "It seems like there are indeed multiple different `'Planet of the Apes'` movies, released in different years. So, for now, we'll leave the index of `imdb` as-is.\n",
    "\n",
    "Time to get to work!\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "    \n",
    "**DO NOT** modify the `imdb` DataFrame at any point in this notebook! If you do, your code won't be graded correctly when you submit it to Gradescope.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6b457c",
   "metadata": {},
   "source": [
    "### Question 4: Exploring the Data ü§î\n",
    "\n",
    "In this question, which is made up of 7 smaller subparts, we'll ask you to answer various questions involving the `imdb` DataFrame. **Don't** hard-code your answers; use `pandas` code to find them programatically."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e63cd3",
   "metadata": {},
   "source": [
    "#### Question 4.1 [Autograded üíª] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">1 Point</div>\n",
    "\n",
    "Assign `highest_rating_ever` to the highest `'IMDb Rating'` of any movie in `imdb`. Your answer should be a float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2411e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "highest_rating_ever = ...\n",
    "highest_rating_ever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d118af1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q04_01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f6fe14",
   "metadata": {},
   "source": [
    "#### Question 4.2 [Autograded üíª] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">2 Points</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a310756d",
   "metadata": {},
   "source": [
    "Assign `movie_with_highest_rating_ever` to the `'Title'` of the movie with the highest `'IMDb Rating'` of any movie in `imdb`. Assume there are no ties. Your answer should be a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f62c4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "movie_with_highest_rating_ever = ...\n",
    "movie_with_highest_rating_ever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34973bb",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q04_02\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c69596",
   "metadata": {},
   "source": [
    "#### Question 4.3 [Autograded üíª] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">1 Point</div>\n",
    "\n",
    "Assign `num_comedy` to the number of movies in `imdb` with a `'Genre'` of `'Comedy'`. Your answer should be an integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc51def",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_comedy = ...\n",
    "num_comedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2beb9010",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q04_03\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7356b258",
   "metadata": {},
   "source": [
    "#### Question 4.4 [Autograded üíª] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">2 Points</div>\n",
    "\n",
    "Assign `most_common_genre_2024` to the name of the most common `'Genre'` among all movies in `imdb` released in 2024. Assume there are no ties. Your answer should be a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed299dff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "most_common_genre_2024 = ...\n",
    "most_common_genre_2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc7090d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q04_04\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a4109e",
   "metadata": {},
   "source": [
    "#### Question 4.5 [Autograded üíª] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">3 Points</div>\n",
    "\n",
    "Assign `prop_big_directors` to the **proportion** of movies in `imdb` directed by the top 4 `'Director'`s, when `'Director'`s are ranked by the number of movies they've directed in descending order. Assume that the top 4 `'Directors'` are unambiguous; i.e. that there isn't a 5th director that is tied with one of the top 4. Your answer should be a float between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499ada67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prop_big_directors = ...\n",
    "prop_big_directors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169d40be",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q04_05\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a305ce8",
   "metadata": {},
   "source": [
    "#### Question 4.6 [Autograded üíª] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">2 Points</div>\n",
    "\n",
    "Assign `average_harry_potter` to the mean `'IMDb Rating'` of all movies with the string `'Harry Potter'` in the `'Title'`. Your answer should be a float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea02f92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "average_harry_potter = ...\n",
    "average_harry_potter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6618b28d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q04_06\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea0935a",
   "metadata": {},
   "source": [
    "#### Question 4.7: [Autograded üíª] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">4 Points</div>\n",
    "\n",
    "Assign `num_hours_family_friendly` to the number of **hours** it would take you to watch the 10 highest-rated `'PG-13'` movies whose `'Genre'` is either `'Action'` or `'Adventure'`. By highest-rated, we're referring to movies with the highest `'IMDb Rating'`s. Assume that there are no ties in `'IMDb Rating'`s. Your answer should be a float.\n",
    "\n",
    "This is a sophisticated problem, but one that only requires knowledge from Lecture 4. Remember to break the problem into steps, and write one step/method at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67e5f86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_hours_family_friendly =  ...\n",
    "num_hours_family_friendly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111300e8",
   "metadata": {},
   "source": [
    "### Question 5: Star Struck ü§©\n",
    "\n",
    "Take a look at the `'Star Cast'` column of `imdb`, which we didn't use in Question 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad7014c",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb['Star Cast']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b16bb4",
   "metadata": {},
   "source": [
    "Right now, actors' names aren't separated by spaces. With `'Star Cast'` in this form, we can still perform _some_ queries, like looking at all of the movies Margot Robbie was in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0a9339",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb[imdb['Star Cast'].str.contains('Margot Robbie')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fc6c44",
   "metadata": {},
   "source": [
    "But we **can't** answer questions like, which actor was in the most movies? Let's change that by cleaning the data üßπ.\n",
    "\n",
    "#### Question 5.1 [Autograded üíª] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">5 Points</div>\n",
    "\n",
    "Complete the implementation of the function `extract_names`, which takes in `s`, a single string formatted like those in the `'Star Cast'` column of `imdb`, and returns a **list** of strings with the names of all of the actors in `s`. Example behavior is given below.\n",
    "\n",
    "```python\n",
    ">>> extract_names('Makoto ShinkaiClark Cheng')\n",
    "['Makoto Shinkai', 'Clark Cheng']\n",
    "\n",
    ">>> extract_names('Anya Taylor-JoyChris HemsworthTom Burke')\n",
    "['Anya Taylor-Joy', 'Chris Hemsworth', 'Tom Burke']\n",
    "\n",
    ">>> extract_names('Santa Ono')\n",
    "['Santa Ono']\n",
    "```\n",
    "\n",
    "You **must** assume that:\n",
    "- Each actor only has a single first name and a single last name.\n",
    "- Actors names are \"split\" when you see a lowercase character followed immediately by an uppercase character. For instance, in the input<br><center>\"Anya Taylor-Jo**yC**hris Hemswort**hT**om Burke\"</center><br>the only two occurrences of a lowercase character followed by an uppercase character are at the boundaries of names. You **must** split names in this way, even though it means that `extract_names` will work incorrectly for cases like the one below. (We're adding this assumption because it makes the implementation of `extract_names` simpler.)\n",
    "\n",
    "```python\n",
    ">>> extract_names('Leonardo DiCaprioJonah HillMargot Robbie')\n",
    "['Leonardo Di', 'Caprio', 'Jonah Hill', 'Margot Robbie']\n",
    "```\n",
    "\n",
    "Note that the implementation of `extract_names` doesn't involve any `pandas` methods; it's a pure Python problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0490a786",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_names(s):\n",
    "    ...\n",
    "\n",
    "# Feel free to change this input to make sure your function works correctly.\n",
    "extract_names('Makoto ShinkaiClark Cheng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad28e0a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q05_01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07616c76",
   "metadata": {},
   "source": [
    "Now, using syntax we'll see in Week 4, we've defined for you a Series, named `star_names`, containing the names of all individual actors in `'Star Cast'`. This involves using the Series `apply` method to call your `extract_names` function on every value in `imdb['Star Cast']`, and then combining the resulting lists into one massive list, and finally converting that to Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6117d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "star_names = pd.Series(imdb['Star Cast'].apply(extract_names).sum())\n",
    "star_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54992af9",
   "metadata": {},
   "source": [
    "Note that the values in `star_names` are not unique!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010bcf96",
   "metadata": {},
   "source": [
    "#### Question 5.2 [Autograded üíª] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">2 Points</div>\n",
    "\n",
    "Complete the implementation of the function `most_common`, which takes in a Series, `ser`, and returns a **list** containing the mode(s) of `ser`. The order of the elements in the returned list does not matter. Assume `ser` contains at least one element. Example behavior is given below.\n",
    "\n",
    "```python\n",
    ">>> most_common(pd.Series([1, 2, 2]))\n",
    "[2]\n",
    "\n",
    ">>> most_common(pd.Series([1, 2]))\n",
    "[1, 2]\n",
    "\n",
    "# This works strangely because of our assumptions in 5.1.\n",
    "# We're intentionally not showing you the entire output.\n",
    ">>> star_names_output = most_common(star_names)\n",
    ">>> 'Caprio' in star_names_output and 'Leonardo Di' in star_names_output\n",
    "True\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec6a7a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def most_common(ser):\n",
    "    ...\n",
    "\n",
    "# Feel free to change this input to make sure your function works correctly.\n",
    "most_common(pd.Series([1, 2, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0696c300",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q05_02\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f99ccc5",
   "metadata": {},
   "source": [
    "After you've implemented `most_common`, run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdfa18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common(star_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0372e9f0",
   "metadata": {},
   "source": [
    "You may recognize some of these names, but not others. You should explore! For instance, query `imdb` for all the movies that `'Pete Docter'` starred in. What do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625eec2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You're NOT required to do this, but you should ‚Äì it's fun!\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69f93e2",
   "metadata": {},
   "source": [
    "### Question 6: Diving Deeper ü§ø\n",
    "\n",
    "To wrap up, let's answer a few more involved questions involving the original DataFrame, `imdb`.\n",
    "\n",
    "Remember that DataFrames are **mutable**, which means that they can be modified as a side effect of calling a function. Make sure the functions you define **don't** have any side effects, i.e. they don't modify their input DataFrames directly, but rather just return the output that is asked of them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d893503c",
   "metadata": {},
   "source": [
    "#### Question 6.1 [Autograded üíª] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">3 Points</div>\n",
    "\n",
    "Complete the implementation of the function `longest_title`, which takes in a DataFrame `df` and returns the longest movie `'Title'`. Assume that `df` has the same 9 column titles as `imdb`, with the same data types, **but potentially a different number of rows in a different order, with a potentially different index**. Assume that `df` has at least one row, and assume there are no ties. Example behavior is given below.\n",
    "\n",
    "```python\n",
    "# Remember, imdb.head(5) is a DataFrame with just the first 5 rows of imdb.\n",
    ">>> longest_title(imdb.head(5))\n",
    "'10 Things I Hate About You'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc39d56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def longest_title(df):\n",
    "    ...\n",
    "\n",
    "# Feel free to change this input to make sure your function works correctly.\n",
    "longest_title(imdb.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee44c418",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q06_01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677f132b",
   "metadata": {},
   "source": [
    "Once you've implemented `longest_title`, run the cell below to see the longest movie title in `imdb` ü¶Å."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b12dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "longest_title(imdb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9053c5c5",
   "metadata": {},
   "source": [
    "#### Question 6.2 [Autograded üíª] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">3 Points</div>\n",
    "\n",
    "Typically, it seems that `'IMDb Rating'`, which are determined by user ratings, and `'MetaScore'` ratings, which are weighted averages of scores given by trusted movie critics, are correlated. That is, movies with high `'IMDb Rating'`s tend to have high `'MetaScore'` ratings, and movies with low `'IMDb Rating'`s tend to have low `'MetaScore'` ratings.\n",
    "\n",
    "We can see this trend in the following scatter plot. **Hover over points to see the names of the movies!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0808d23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb.plot(kind='scatter', \n",
    "          x='IMDb Rating', \n",
    "          y='MetaScore', \n",
    "          hover_name='Title', \n",
    "          width=800, \n",
    "          height=600,\n",
    "          title='MetaScore vs. IMDb Rating')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f04d3e9",
   "metadata": {},
   "source": [
    "As you can see, there are some outliers, i.e. movies that had relatively high `'MetaScore'`s but relatively low `'IMDb Rating'`s, or vice versa.\n",
    "\n",
    "We define the `'MetaScore'` to `'IMDb Rating'` ratio of a movie as follows:\n",
    "\n",
    "$$\\frac{\\text{Movie's MetaScore}}{\\text{Movie's IMDb Rating}}$$\n",
    "\n",
    "Complete the implementation of the function `metascore_to_rating_outlier`, which takes in a DataFrame `df` and returns the movie with the **largest** `'MetaScore'` to `'IMDb Rating'` ratio. Note that this is only one of the two types of outliers mentioned in the paragraph at the top of this cell, but use this definition in your solution.\n",
    "\n",
    "Assume that `df` has the same 9 column titles as `imdb`, with the same data types, but potentially a different number of rows in a different order, with a potentially different index. Assume that `df` has at least one row, and assume there are no ties. Example behavior is given below.\n",
    "\n",
    "\n",
    "```python\n",
    ">>> metascore_to_rating_outlier(imdb.head(5))\n",
    "'A Quiet Place'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e502e76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def metascore_to_rating_outlier(df):\n",
    "    ...\n",
    "\n",
    "# Feel free to change this input to make sure your function works correctly.\n",
    "metascore_to_rating_outlier(imdb.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f9c547",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q06_02\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779a1327",
   "metadata": {},
   "source": [
    "#### Question 6.3 [Autograded üíª] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">3 Points</div>\n",
    "\n",
    "And finally, now that you're almost done Homework 2, it's time to find new movies in your favorite genre that the data thinks you might like.\n",
    "\n",
    "Complete the implementation of the function `genre_specific`, which takes in a DataFrame `df` and a string, `genre`, corresponding to a `'Genre'` in `imdb`. `genre_specific(df, genre)` should return a DataFrame that:\n",
    "- Contains all of the movies in `df` of `'Genre'` `genre` **released in 2024**. Assume `genre` is a valid value in `df['Genre']`.\n",
    "- Is sorted in descending order of `'IMDb Rating'`, with ties broken by `'MetaScore'` in descending order. Assume no two movies have both the same `'IMDb Rating'` and the same `'MetaScore'`. (There are a few cases where this happens, but you won't be tested on them in the hidden test cases.)\n",
    "- Is indexed by `'Title'`, and only has two columns: `'IMDb Rating'` and `'MetaScore'`.\n",
    "\n",
    "Example behavior is given below.\n",
    "\n",
    "```python\n",
    ">>> genre_specific(imdb, 'Horror')\n",
    "```\n",
    "\n",
    "<div style=\"text-align: left;\">\n",
    "  <table border=\"1\" class=\"dataframe\">\n",
    "    <thead>\n",
    "      <tr>\n",
    "        <th style=\"text-align: left;\"></th>\n",
    "        <th style=\"text-align: left;\">IMDb Rating</th>\n",
    "        <th style=\"text-align: left;\">MetaScore</th>\n",
    "      </tr>\n",
    "      <tr>\n",
    "        <th>Title</th>\n",
    "        <th></th>\n",
    "        <th></th>\n",
    "      </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "      <tr>\n",
    "        <th>Alien: Romulus</th>\n",
    "        <td>7.1</td>\n",
    "        <td>66.9</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "        <th>Exhuma</th>\n",
    "        <td>7.0</td>\n",
    "        <td>66.9</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "        <th>The First Omen</th>\n",
    "        <td>6.7</td>\n",
    "        <td>65.0</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "        <th>Abigail</th>\n",
    "        <td>6.7</td>\n",
    "        <td>62.0</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "        <th>Immaculate</th>\n",
    "        <td>5.8</td>\n",
    "        <td>57.0</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "        <th>Sting</th>\n",
    "        <td>5.7</td>\n",
    "        <td>57.0</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "        <th>The Strangers: Chapter 1</th>\n",
    "        <td>5.0</td>\n",
    "        <td>43.0</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "        <th>Tarot</th>\n",
    "        <td>4.9</td>\n",
    "        <td>36.0</td>\n",
    "      </tr>\n",
    "    </tbody>\n",
    "  </table>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39df071",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def genre_specific(df, genre):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d28d5af",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q06_03\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24064781",
   "metadata": {},
   "source": [
    "## Finish Line üèÅ\n",
    "\n",
    "Congratulations! You're ready to submit Homework 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6da8598",
   "metadata": {},
   "source": [
    "You need to submit Homework 2 twice:\n",
    "\n",
    "### To submit the manually graded problems (Questions 1.4, 3; marked [Written ‚úèÔ∏è])\n",
    "\n",
    "- Make sure your answers **are not** in this notebook, but rather in a separate PDF.\n",
    "    - You can create this PDF either digitally, using your tablet or using [Overleaf + LaTeX](https://overleaf.com) (or some other sort of digital document), or by writing your answers on a piece of paper and scanning them in.\n",
    "- Submit this separate PDF to the **Homework 2 (Questions 1.4, 3; written problems)** assignment on Gradescope, and **make sure to correctly select the pages associated with each question**!\n",
    "\n",
    "### To submit the autograded problems (Questions 1.1-1.3, 2, 4-6; marked [Autograded üíª])\n",
    "\n",
    "1. Select `Kernel -> Restart & Run All` to ensure that you have executed all cells, including the test cells.\n",
    "2. Read through the notebook to make sure everything is fine and all tests passed.\n",
    "3. Run the cell below to run all tests, and make sure that they all pass.\n",
    "4. Download your notebook using `File -> Download as -> Notebook (.ipynb)`, then upload your notebook to Gradescope under **Homework 2 (Questions 1.1-1.3, 2, 4-6; autograded problems)**.\n",
    "5. Stick around while the Gradescope autograder grades your work.\n",
    "6. Check that you have a confirmation email from Gradescope and save it as proof of your submission.\n",
    "\n",
    "Your Homework 2 submission time will be the **later** of your two individual submissions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "otter": {
   "tests": {
    "q01_01": {
     "name": "q01_01",
     "points": 4,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> callable(create_adjacency) and isinstance(create_adjacency(example_net), np.ndarray)\nTrue",
         "failure_message": "create_adjacency should return a numpy array.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> example_net_output = create_adjacency(example_net)\n>>> example_net_output.shape == (4, 4) and np.allclose(example_net_output, A)\nTrue",
         "failure_message": "Incorrect size for adjacency matrix and/or incorrect values for input example_net.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> public_test_net = {1: [2, 3], 2: [1, 3], 3: [1, 2]}\n>>> public_test_net_output = create_adjacency(public_test_net)\n>>> public_test_net_output.shape == (3, 3) and np.allclose(public_test_net_output, np.array([[0, 0.5, 0.5], [0.5, 0, 0.5], [0.5, 0.5, 0]]))\nTrue",
         "failure_message": "Incorrect size and/or values for input (see test).",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> big_test_net = {1: [6], 2: [1, 3, 4, 6], 3: [2, 5, 6], 4: [1], 5: [1, 2, 6], 6: [2, 4]}\n>>> big_test_net_output = create_adjacency(big_test_net)\n>>> big_test_net_expected_output = np.load('data/real_adjacency.npy')\n>>> big_test_net_output.shape == big_test_net_expected_output.shape and np.allclose(big_test_net_output, big_test_net_expected_output)\nTrue",
         "failure_message": "Incorrect size and/or values for input (see test).",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q01_02": {
     "name": "q01_02",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> callable(compute_scores) and isinstance(compute_scores(A), np.ndarray)\nTrue",
         "failure_message": "compute_scores should return a numpy array.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.allclose(compute_scores(A), np.array([0.30769231, 0.38461538, 0.07692308, 0.23076923]))\nTrue",
         "failure_message": "Incorrect PageRank scores for input A.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> big_test_net = {1: [6], 2: [1, 3, 4, 6], 3: [2, 5, 6], 4: [1], 5: [1, 2, 6], 6: [2, 4]} # Doesn't do anything, just here for clarity.\n>>> big_test_net_expected_output = np.load('data/real_adjacency.npy')\n>>> big_test_net_scores = compute_scores(big_test_net_expected_output) # So that errors don't cascade, we load in the correct adjacency matrix.\n>>> np.allclose(big_test_net_scores, np.array([0.25      , 0.17647059, 0.04411765, 0.20098039, 0.01470588, 0.31372549]))\nTrue",
         "failure_message": "Incorrect PageRank scores for medium-sized test net. Make sure scores add to 1.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q01_03": {
     "name": "q01_03",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> callable(pagerank) and isinstance(pagerank(A), list)\nTrue",
         "failure_message": "pagerank should return a list, not an array.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.allclose(pagerank(A), [2, 1, 4, 3])\nTrue",
         "failure_message": "Incorrect output for input A.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> big_test_net = {1: [6], 2: [1, 3, 4, 6], 3: [2, 5, 6], 4: [1], 5: [1, 2, 6], 6: [2, 4]} # Doesn't do anything, just here for clarity.\n>>> big_test_net_expected_output = np.load('data/real_adjacency.npy')\n>>> big_test_net_rankings = pagerank(big_test_net_expected_output) # So that errors don't cascade, we load in the correct adjacency matrix.\n>>> np.allclose(big_test_net_rankings, [6, 1, 4, 2, 3, 5])\nTrue",
         "failure_message": "Incorrect output for medium-sized test net. Make sure you're returning the pages in descending order of scores!",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q02_01": {
     "name": "q02_01",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> callable(prob_at_least_k_same_suit) and isinstance(prob_at_least_k_same_suit(4), float)\nTrue",
         "failure_message": "prob_at_least_k_same_suit should return a float.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> call_one = prob_at_least_k_same_suit(4)\n>>> call_two = prob_at_least_k_same_suit(4)\n>>> call_one != call_two\nTrue",
         "failure_message": "prob_at_least_k_same_suit shouldn't return the same value every time!",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> 0.022 <= prob_at_least_k_same_suit(4) <= 0.029\nTrue",
         "failure_message": "Failing this but think you did your simulation correctly? Check your replacement strategy.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> prob_at_least_k_same_suit(15) == 0\nTrue",
         "failure_message": "Make sure to consider the value of the input (k) before calculating the probability of getting 'k' cards of the same suit!",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q02_02": {
     "name": "q02_02",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> callable(prob_all_one_jack) and isinstance(prob_all_one_jack(), float) and 0 <= prob_all_one_jack() <= 1\nTrue",
         "failure_message": "prob_all_one_jack should return a float.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> call_one = prob_all_one_jack()\n>>> call_two = prob_all_one_jack()\n>>> call_one != call_two\nTrue",
         "failure_message": "prob_all_one_jack shouldn't return the same value every time!",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q04_01": {
     "name": "q04_01",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> (isinstance(highest_rating_ever, float) or isinstance(highest_rating_ever, np.float64)) and highest_rating_ever in list(imdb['IMDb Rating'])\nTrue",
         "failure_message": "highest_rating_ever should be an element in the 'IMDb Rating' column of the DataFrame.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q04_02": {
     "name": "q04_02",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(movie_with_highest_rating_ever, str) and movie_with_highest_rating_ever in list(imdb['Title'])\nTrue",
         "failure_message": "movie_with_highest_rating_ever should be an element in the 'Title' column of the DataFrame.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q04_03": {
     "name": "q04_03",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> (isinstance(num_comedy, int) or isinstance(num_comedy, np.int64)) and num_comedy < imdb.shape[0]\nTrue",
         "failure_message": "num_comedy should be an integer less than 255 (the number of movies).",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q04_04": {
     "name": "q04_04",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(most_common_genre_2024, str) and most_common_genre_2024 in list(imdb['Genre'])\nTrue",
         "failure_message": "most_common_genre_2024 should be an element in the 'Genre' column of the DataFrame.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q04_05": {
     "name": "q04_05",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> (isinstance(prop_big_directors, float) or isinstance(prop_big_directors, np.float64)) and 0 < prop_big_directors < 1\nTrue",
         "failure_message": "prop_big_directors should be a float between 0 and 1.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q04_06": {
     "name": "q04_06",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> (isinstance(average_harry_potter, float) or isinstance(average_harry_potter, np.float64)) and 3.9 < average_harry_potter < 9.2\nTrue",
         "failure_message": "average_harry_potter should be a float.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q04_07": {
     "name": "q04_07",
     "points": 4,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q05_01": {
     "name": "q05_01",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> callable(extract_names) and isinstance(extract_names('Makoto ShinkaiClark Cheng'), list)\nTrue",
         "failure_message": "extract_names should return a list.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> extract_names('Makoto ShinkaiClark Cheng') == ['Makoto Shinkai', 'Clark Cheng']\nTrue",
         "failure_message": "Incorrect output for input 'Makoto ShinkaiClark Cheng'.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> extract_names('Anya Taylor-JoyChris HemsworthTom Burke') == ['Anya Taylor-Joy', 'Chris Hemsworth', 'Tom Burke']\nTrue",
         "failure_message": "Incorrect output for input 'Anya Taylor-JoyChris HemsworthTom Burke'.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q05_02": {
     "name": "q05_02",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> callable(most_common) and isinstance(most_common(pd.Series([1, 2, 2])), list)\nTrue",
         "failure_message": "most_common should return a list.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> most_common(pd.Series([1, 2, 2])) == [2]\nTrue",
         "failure_message": "Incorrect output for input pd.Series([1, 2, 2]).",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> most_common(pd.Series([1, 2])) == [1, 2] or most_common(pd.Series([1, 2])) == [2, 1]\nTrue",
         "failure_message": "Incorrect output for input pd.Series([1, 2]).",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> set(most_common(star_names)) == {'Caprio', 'Daniel Radcliffe', 'Rupert Grint', 'Emma Watson', 'Leonardo Di', 'Pete Docter'}\nTrue",
         "failure_message": "Failing this test? Try using the value_counts method.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q06_01": {
     "name": "q06_01",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> callable(longest_title) and isinstance(longest_title(imdb.head(5)), str)\nTrue",
         "failure_message": "longest_title should return a string.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> longest_title(imdb.head(5)) == '10 Things I Hate About You'\nTrue",
         "failure_message": "Incorrect output for input imdb.head(5).",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> longest_title(imdb.tail(5).sample(frac=1)) == \"You Can't Run Forever\"\nTrue",
         "failure_message": "Incorrect output for input imdb.tail(5).sample(frac=1), which is a shuffled version of imdb.tail(5).",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q06_02": {
     "name": "q06_02",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> callable(metascore_to_rating_outlier) and isinstance(metascore_to_rating_outlier(imdb.head(5)), str)\nTrue",
         "failure_message": "metascore_to_rating_outlier should return a string.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> metascore_to_rating_outlier(imdb.head(5)) == 'A Quiet Place'\nTrue",
         "failure_message": "Incorrect output for input imdb.head(5).",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> metascore_to_rating_outlier(imdb.iloc[15:25]) == 'Barbie'\nTrue",
         "failure_message": "Incorrect output for input imdb.iloc[15:25].",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q06_03": {
     "name": "q06_03",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> callable(genre_specific) and isinstance(genre_specific(imdb, 'Horror'), pd.DataFrame)\nTrue",
         "failure_message": "genre_specific should return a DataFrame.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> horror_output = genre_specific(imdb, 'Horror')\n>>> horror_output.shape == (8, 2)\nTrue",
         "failure_message": "genre_specific(imdb, 'Horror') should have 8 movies with 2 columns.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> horror_output = genre_specific(imdb, 'Horror')\n>>> np.all(horror_output.index == ['Alien: Romulus', 'Exhuma', 'The First Omen', 'Abigail', 'Immaculate', 'Sting', 'The Strangers: Chapter 1', 'Tarot'])\nTrue",
         "failure_message": "genre_specific(imdb, 'Horror') has the wrong 8 movies in its index.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
