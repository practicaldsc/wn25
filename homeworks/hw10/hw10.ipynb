{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bddd4c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"hw10.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c299e310",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" markdown=\"1\">\n",
    "\n",
    "#### Homework 10\n",
    "\n",
    "# Gradient Descent and Classification\n",
    "\n",
    "### EECS 398: Practical Data Science, Winter 2025\n",
    "\n",
    "#### Due Friday, April 11th at 11:59PM (note the later than usual deadline)\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba24a7c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Instructions\n",
    "\n",
    "Welcome to Homework 10, and thanks for your patience! In this homework, you'll get your hands dirty and implement gradient descent from scratch, and gain familiarity with various classification algorithms and their behaviors. This homework touches on ideas from Lectures 20 and 21.\n",
    "\n",
    "You are given **eight** slip days throughout the semester to extend deadlines. See the [Syllabus](https://practicaldsc.org/syllabus) for more details. With the exception of using slip days, late work will not be accepted unless you have made special arrangements with your instructor.\n",
    "\n",
    "To access this notebook, you'll need to clone our [public GitHub repository](https://github.com/practicaldsc/wn25/). The [Environment Setup](https://practicaldsc.org/env-setup) page on the course website walks you through the necessary steps.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "This homework is **fully autograded, and has no hidden tests**. All you need to do is write your code in this notebook, run the local `grader.check` tests, and submit to the **Homework 10** assignment on Gradescope to make sure your final score matches the test cases in this notebook.\n",
    "</div>\n",
    "\n",
    "This homework is worth a total of **39 points**, all of which come from the autograder. The number of points each question is worth is listed at the start of each question. **All questions in the assignment are independent, so feel free to move around if you get stuck**. Tip: if you're using Jupyter Lab, you can see a Table of Contents for the notebook by going to View > Table of Contents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1e34fb",
   "metadata": {},
   "source": [
    "To get started, run the cell below, plus the cell at the top of the notebook that imports and initializes `otter`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00448271",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hw10_util as util\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "\n",
    "# Preferred styles\n",
    "pio.templates[\"pds\"] = go.layout.Template(\n",
    "    layout=dict(\n",
    "        margin=dict(l=30, r=30, t=30, b=30),\n",
    "        autosize=True,\n",
    "        width=600,\n",
    "        height=400,\n",
    "        xaxis=dict(showgrid=True),\n",
    "        yaxis=dict(showgrid=True),\n",
    "        title=dict(x=0.5, xanchor=\"center\"),\n",
    "    )\n",
    ")\n",
    "pio.templates.default = \"simple_white+pds\"\n",
    "\n",
    "# Use plotly as default plotting engine\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "\n",
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d6c09b",
   "metadata": {},
   "source": [
    "## Question 1: Spam or Ham üçî\n",
    "\n",
    "---\n",
    "\n",
    "Whenever you receive an email at your @umich.edu account, Gmail's spam filter predicts whether the email is **spam** or **ham** (not spam). In other words, they're performing binary classification! **In this question, we'll build our own spam classifiers using techniques from class.**\n",
    "\n",
    "Run the cell below to load in a dataset of emails, all labeled as either `'spam'` or `'ham'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ffaead",
   "metadata": {},
   "outputs": [],
   "source": [
    "emails = pd.read_csv('data/spam_ham_dataset.csv')\n",
    "emails.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ecd14f",
   "metadata": {},
   "source": [
    "In keeping consistent with what we've seen in class, **we'll convert `'spam'` to 1 and `'ham'` to 0**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a674306",
   "metadata": {},
   "outputs": [],
   "source": [
    "emails['label'] = (emails['label'] == 'spam').astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5729b2",
   "metadata": {},
   "source": [
    "Before we do any analysis, we'll perform a train-test split, as usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ae182b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(emails[['text']], emails['label'], random_state=98)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8264631a",
   "metadata": {},
   "source": [
    "In the training set, about 30% of emails are spam (1) and about 70% are not spam (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862501ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455fb4e5",
   "metadata": {},
   "source": [
    "Right now, **none of our features are numeric**, so we'll need to engineer numeric features out of the `'text'` column. Fortunately, we learned how to create text features out of documents in [Lecture 10](https://practicaldsc.org/resources/lectures/lec10/lec10-filled.html), when we learned about the bag of words model and TF-IDF!\n",
    "\n",
    "Each value in `'text'` clearly starts with a subject (from `'Subject:'` to `'\\r\\n'`), which is separate from the body of the email (everything after the first `'\\r\\n'`). For simplicity's sake, we'll treat all words in `'text'` as being equivalent and **not** distinguish between email subjects and bodies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef88c61f",
   "metadata": {},
   "source": [
    "### Question 1.1 [Autograded üíª] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">2 Points</div>\n",
    "\n",
    "To start, you'll build a `sklearn` Pipeline that does the following to predict the `'label'` of an email:\n",
    "- Uses `sklearn`'s `TfidfVectorizer` to turn all emails in the `'text'` column into TF-IDF features. `TfidfVectorizer` **automatically** creates a \"TF-IDF matrix\" as seen in Lecture 10, with one row per document (email) and one column per unique term. **It uses regular expressions and removes punctuation all for us; we fortunately don't need to think about those details.**\n",
    "- Fits a `LogisticRegression` model with the default settings. While we will only formally introduce logistic regression (which is a classification technique!) in Lecture 22, it works similarly to `KNeighborsClassifier` and `DecisionTreeClassifier` in that it can be used for binary classification. The added benefit of logistic regression is that it allows us to predict the **probability** of belonging to a class, i.e. it will allow us to predict the probability that an email is spam (class 1) or ham (class 0), given its text.\n",
    "\n",
    "Complete the implementation of the function `create_pipe_tfidf`, which takes in a DataFrame like `X_train` and a Series like `y_train` and returns a **fit** Pipeline that follows all of the steps above.\n",
    "\n",
    "Example behavior is given below.\n",
    "\n",
    "```python\n",
    ">>> pipe = create_pipe_tfidf(X_train, y_train)\n",
    "\n",
    "# As we'll see in Lecture 22, fit LogisticRegression estimators\n",
    "# have a predict_proba method, which returns the predicted probabilities of each class.\n",
    "# Here, we're seeing that this email has a 59.45% predicted probability of being ham (class 0),\n",
    "# and a 40.55% predicted probability of being spam (class 1).\n",
    ">>> pipe.predict_proba(pd.DataFrame([{\n",
    "    'text': 'hey eecs 398 students attached is where you are sitting for the exam'\n",
    "}]))\n",
    "array([[0.59450521, 0.40549479]])\n",
    "```\n",
    "\n",
    "Some guidance:\n",
    "- **Our implementation is just two lines long**, one of which is fairly long.\n",
    "- We created a Pipeline with three components, one of which is a `FunctionTransformer` instance. The `FunctionTransformer` takes in an input DataFrame with one column and returns a Series containing just that column; this is necessary because `X_train` is a DataFrame, but `TfidfVectorizer` expects a Series/1D array of documents.\n",
    "- This part has no hidden test cases, since the rest of Question 1 depends on a correct implementation of `create_pipe_tfidf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b2c2b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline, FunctionTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def create_pipe_tfidf(X_train, y_train):\n",
    "    ...\n",
    "\n",
    "emails = pd.read_csv('data/spam_ham_dataset.csv')\n",
    "X_train, X_test, y_train, y_test = train_test_split(emails[['text']], emails['label'], random_state=98)\n",
    "\n",
    "# Feel free to change these inputs to make sure your function works correctly.\n",
    "pipe = create_pipe_tfidf(X_train, y_train)\n",
    "pipe.predict_proba(pd.DataFrame([{\n",
    "    'text': 'hey eecs 398 students attached is where you are sitting for the exam'\n",
    "}]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1913f85",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q01_01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53dce567",
   "metadata": {},
   "source": [
    "We tested your code using the `predict_proba` method of your fit Pipeline. But, as we'll see in Lecture 22, the `predict` method of a fit  `LogisticRegression` model predicts the class with the larger probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068add77",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = create_pipe_tfidf(X_train, y_train)\n",
    "pipe.predict(pd.DataFrame([{\n",
    "    'text': 'hey eecs 398 students attached is where you are sitting for the exam'\n",
    "}]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7618f96a",
   "metadata": {},
   "source": [
    "Let's make a nicer UI for this! Run the cell below and play with the resulting widget. (This may not work in VSCode, in which case you can call `predict_on_new_email` directly.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53f99ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_new_email(email, pipe):\n",
    "    pred = pipe.predict(pd.DataFrame([{'text': email}]))[0]\n",
    "    pred_proba = pipe.predict_proba(pd.DataFrame([{'text': email}]))[0, 1]\n",
    "    if pred == 'spam':\n",
    "        piece = 'Spam ‚ùå'\n",
    "    else:\n",
    "        piece = 'Not Spam ‚úÖ'\n",
    "    display(Markdown(f'### Predicted {piece} \\n Spam Probability: {round(pred_proba * 100, 2)}%'))\n",
    "\n",
    "\n",
    "def email_widget(pipe):    \n",
    "    from ipywidgets import interact\n",
    "    interact(lambda email: predict_on_new_email(email, pipe=pipe), email='replace this text!');\n",
    "\n",
    "email_widget(pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246c2cb2",
   "metadata": {},
   "source": [
    "The classifier doesn't seem to work particularly intuitively. Try inputting a non-spammy email, like `'hi mom I love you'`, and you'll see a relatively high predicted probability of spam. **Why do you think this is the case?**\n",
    "\n",
    "You may be curious to know **where** the emails came from. For that, read [**this Wikipedia article**](https://en.wikipedia.org/wiki/Enron_Corpus), then manually look through a few of the emails in `X_train`. You should notice terms like `'enron'` and `'gas'` are common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fd6937",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9925e8b6",
   "metadata": {},
   "source": [
    "All of that said, as you see below, the **test** accuracy of our fit classifier is quite high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1c2577",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = create_pipe_tfidf(X_train, y_train)\n",
    "pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc5a7a5",
   "metadata": {},
   "source": [
    "### Question 1.2 [Autograded üíª] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">3 Points</div>\n",
    "\n",
    "But, what are the precision, recall, and false positive rate of our fit classifier? Instead of using the built-in implementations of precision and recall in `sklearn`, we'll have you implement functions that calculate these metrics manually. Remember:\n",
    "\n",
    "$$\\text{precision} = \\frac{TP}{TP + FP}$$\n",
    "\n",
    "$$\\text{recall} = \\frac{TP}{TP + FN}$$\n",
    "\n",
    "$$\\text{FPR} = \\frac{FP}{FP + TN}$$\n",
    "\n",
    "where $TP$ is the number of true positives, $FP$ is the number of false positives, $FN$ is the number of false negatives, and $TN$ is the number of true negatives. Here, a \"positive\" is a prediction of spam, and a \"negative\" is a prediction of ham.\n",
    "\n",
    "Complete the implementations of the following two functions:\n",
    "\n",
    "- `calculate_precision`, which takes in two binary Series/1D arrays, `y_actual` and `y_pred`, and returns the **precision** of the predictions `y_pred` relative to the actual $y$-values `y_actual`.\n",
    "- `calculate_recall`, which takes in two binary Series/1D arrays, `y_actual` and `y_pred`, and returns the **recall** of the predictions `y_pred` relative to the actual $y$-values `y_actual`.\n",
    "- `calculate_fpr`, which takes in two binary Series/1D arrays, `y_actual` and `y_pred`, and returns the **false positive rate (FPR)** of the predictions `y_pred` relative to the actual $y$-values `y_actual`.\n",
    "\n",
    "Example behavior is given below.\n",
    "\n",
    "```python\n",
    ">>> y_actual_ex = np.array([0, 1, 1, 0, 1, 1, 1])\n",
    ">>> y_pred_ex = np.array([  1, 1, 0, 0, 0, 1, 1])\n",
    "\n",
    "# 3 true positives, 1 false positive: 3 / (3 + 1) = 0.75.\n",
    ">>> calculate_precision(y_actual_ex, y_pred_ex)\n",
    "0.75\n",
    "\n",
    "# 3 true positives, 2 false negatives: 3 / (3 + 2) = 0.6.\n",
    ">>> calculate_recall(y_actual_ex, y_pred_ex)\n",
    "0.6\n",
    "\n",
    "# 1 false positive, 1 true negative: 1 / (1 + 1) = 0.5.\n",
    ">>> calculate_fpr(y_actual_ex, y_pred_ex)\n",
    "0.5\n",
    "```\n",
    "\n",
    "Remember that you **cannot** use any existing implementations, and also **cannot** use any loops! Each implementation here should be very short."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca9653a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_precision(y_actual, y_pred):\n",
    "    ...\n",
    "\n",
    "def calculate_recall(y_actual, y_pred):\n",
    "    ...\n",
    "\n",
    "def calculate_fpr(y_actual, y_pred):\n",
    "    ...\n",
    "\n",
    "# Feel free to change these inputs to make sure your functions work correctly.\n",
    "y_actual_ex = np.array([0, 1, 1, 0, 1, 1, 1])\n",
    "y_pred_ex = np.array([  1, 1, 0, 0, 0, 1, 1])\n",
    "display(Markdown(f'#### Precision: {round(calculate_precision(y_actual_ex, y_pred_ex), 5)}'))\n",
    "display(Markdown(f'#### Recall: {round(calculate_recall(y_actual_ex, y_pred_ex), 5)}'))\n",
    "display(Markdown(f'#### FPR: {round(calculate_fpr(y_actual_ex, y_pred_ex), 5)}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82080ef",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q01_02\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cef4ddf",
   "metadata": {},
   "source": [
    "### Question 1.3 [Autograded üíª] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">3 Points</div>\n",
    "\n",
    "Now that we have implementations of `calculate_precision`, `calculate_recall`, and `calculate_fpr`, we can use them to measure our Pipeline's performance.\n",
    "\n",
    "Below, complete the implementation of the function `pipeline_stats`, which takes in a fit Pipeline (like `pipe`), and a test set like `X_test` and `y_test`, and returns a **Series** with the following index-value pairs:\n",
    "- `'% spam correctly filtered'`: The percentage **of actually spam emails** that our classifier **correctly** identifies as spam, in the test set.\n",
    "- `'% lost'`: The percentage **of actually ham (not spam) emails** that our classifier **incorrectly** identifies as spam, in the test set.\n",
    "- `'% incorrectly flagged'`: The percentage **of predicted spam emails** that **aren't** actually spam, in the test set.\n",
    "\n",
    "Example behavior is given below.\n",
    "\n",
    "```python\n",
    ">>> pipe = create_pipe_tfidf(X_train, y_train)\n",
    ">>> stats = pipeline_stats(pipe, X_test, y_test)\n",
    "\n",
    "# Between 4% and 5% of the emails that are predicted to be spam are actually ham.\n",
    ">>> 4 < stats.loc['% incorrectly flagged'] < 5\n",
    "```\n",
    "\n",
    "Some guidance:\n",
    "- To determine your Pipeline's predictions, use its `predict` method (not `predict_proba`).\n",
    "- By default, the values in `y_test` ‚Äì and the values that result from `pipe.predict(...)` ‚Äì won't be binary, but will be strings. You'll need to convert them to binary Series/1D arrays, so that they can work with the functions you defined in the previous part.\n",
    "- Most of the work is in deeply understanding what you're being asked to calculate ‚Äì the code you'll write here is relatively short."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0940d90a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pipeline_stats(pipe, X_test, y_test):\n",
    "    ...\n",
    "\n",
    "emails = pd.read_csv('data/spam_ham_dataset.csv')\n",
    "X_train, X_test, y_train, y_test = train_test_split(emails[['text']], emails['label'], random_state=98)\n",
    "pipe = create_pipe_tfidf(X_train, y_train)\n",
    "\n",
    "# Feel free to change these inputs to make sure your function works correctly.\n",
    "# In particular, we may call your function on subsets of X_test and y_test!\n",
    "pipeline_stats(pipe, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b0e657",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q01_03\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a305de54",
   "metadata": {},
   "source": [
    "If you did everything correctly, `pipeline_stats(pipe, X_test, y_test)` should tell you that **the percentage of predicted spam emails that aren't actually spam is somewhere around 4.5%**. This seems relatively low, which at first may sound appealing. But, consider that you receive 100s of **real, non-spam** emails a week ‚Äì if 4.5% of them are incorrectly flagged as spam, you may miss out on seeing dozens of real emails, which is unacceptable! Let's see if we can dig deeper into how our Pipeline is making predictions.\n",
    "\n",
    "Linear regression is a **paramet**ric model, with one **paramet**er per feature. Logistic regression is **also** a parametric model, with one parameter per feature. Assuming the parameters $w_0^*, w_1^*, ..., w_d^*$ have already been found to minimize empirical risk, the logistic regression model makes predictions as follows:\n",
    "\n",
    "$$P(y_i = 1 | \\vec{x}_i) = \\sigma (w_0^* + w_1^* x_i^{(1)} + w_2^* x_i^{(2)} + ... + w_d^* x_i^{(d)})$$\n",
    "\n",
    "In our particular context:\n",
    "\n",
    "$$P(\\text{email } i \\text{ is spam}) = \\sigma \\big( w_0^* + w_1^* \\cdot \\text{tf-idf(``http\", email $i$}) + w_2^* \\cdot \\text{tf-idf(``thanks\", email $i$}) + w_3^* \\cdot \\text{tf-idf(``michigan\", email $i$}) \\: + \\: ...  \\big)$$\n",
    "\n",
    "- The $\\sigma$ represents the logistic function, or sigmoid function, $\\sigma(t) = \\frac{1}{1 + e^{-t}}$. One of the reasons we use it is because it guarantees our predicted probabilities are between 0 and 1.\n",
    "- By default, `sklearn`'s implementation of `LogisticRegression` predicts class 1 if the predicted probability is above 0.5, and class 0 otherwise.\n",
    "- The larger the input to $\\sigma( \\cdot )$ is, the closer the predicted probability is to 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9822928",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma(t):\n",
    "    return 1 / (1 + np.e ** (-t))\n",
    "\n",
    "sigma(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cd4546",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma(-0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ac60ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.linspace(-5, 5)\n",
    "ys = sigma(xs)\n",
    "px.line(x=xs, y=ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02e8d7c",
   "metadata": {},
   "source": [
    "In the explanation above, $\\text{\"http\"}$, $\\text{\"thanks\"}$, and $\\text{\"michigan\"}$ were used as examples of what the first three words in our corpus may be. Remember, here, all $d$ features being used in our model correspond to TF-IDF scores. As we learned in [Lecture 10](https://practicaldsc.org/resources/lectures/lec10/lec10-filled.html), \n",
    "\n",
    "$$\\text{tf-idf(word $j$, email $i$)}$$ \n",
    "\n",
    "is large when word $j$ is important to email $i$ ‚Äì that is, when word $j$ is common in email $i$, but rare across other emails.\n",
    "\n",
    "**Here's the main idea we'll now explore**: the features with the largest coefficients (i.e. optimal parameters) influence the predictions the most! Since all TF-IDF scores are non-negative:\n",
    "- If word $j$'s coefficient is very large and **positive**, it means that as $\\text{tf-idf(word $j$, email $i$})$ increases, the predicted probability that the email is **spam** increases.\n",
    "- If word $j$'s coefficient is very large and **negative**, it means as $\\text{tf-idf(word $j$, email $i$})$ increases, the predicted probability that the email is **ham (not spam)** increases.\n",
    "- If word $j$'s coefficient is close to 0, it means that the value of $\\text{tf-idf(word $j$, email $i$})$ does not change the predicted probability of being spam very much.\n",
    "\n",
    "So, **for example**, if we had:\n",
    "\n",
    "$$P(\\text{email } i \\text{ is spam}) = \\sigma \\big( -5.5 + 3.1 \\cdot \\text{tf-idf(\"http\", email $i$}) - 10 \\cdot \\text{tf-idf(\"thanks\", email $i$}) + 0.02 \\cdot \\text{tf-idf(\"michigan\", email $i$}) \\: + \\: ...  \\big)$$\n",
    "\n",
    "then, if $\\text{\"thanks\"}$ is very important to email $i$, then the predicted probability that email $i$ is spam would be relatively low. This is because the input to $\\sigma( \\cdot )$ would involve $-10 \\cdot \\text{some relatively large number}$, and the more negative the input to $\\sigma( \\cdot )$ is, the smaller the predicted probability of being spam is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084f0e49",
   "metadata": {},
   "source": [
    "### Question 1.4 [Autograded üíª] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">4 Points</div>\n",
    "\n",
    "Given the intuition above, let's try and understand how our particular Pipeline is making predictions.\n",
    "\n",
    "Below, complete the implementation of the function `d_largest_coefficients`, which takes in a fit Pipeline like `pipe`, a positive integer `d`, and an integer `sign` which is either `1` or `-1`. `d_largest_coefficients` should:\n",
    "- Determine the coefficient of each word (i.e. each TF-IDF feature) used by `pipe`.\n",
    "- If `sign == 1`:\n",
    "    - Return a horizontal bar chart visualizing the coefficients of the `d` words with the **largest, most positive coefficients**.\n",
    "- If `sign == -1`:\n",
    "    - Return a horizontal bar chart visualizing the coefficients of the `d` words with the **largest, most negative coefficients**.\n",
    " \n",
    "Example behavior is given below.\n",
    "\n",
    "```python\n",
    ">>> pipe = create_pipe_tfidf(X_train, y_train)\n",
    ">>> d_largest_coefficients(pipe, d=5, sign=1)\n",
    "```\n",
    "\n",
    "<div align=\"left\">\n",
    "<img src=\"imgs/pos_coefs.png\", width=400>\n",
    "</div>\n",
    "\n",
    "```python\n",
    ">>> d_largest_coefficients(pipe, d=5, sign=-1)\n",
    "```\n",
    "\n",
    "<div align=\"left\">\n",
    "<img src=\"imgs/neg_coefs.png\", width=400>\n",
    "</div>\n",
    "\n",
    "Some guidance:\n",
    "- You'll need to use some of the Pipeline methods and attributes introduced in [Lecture 17](https://practicaldsc.org/resources/lectures/lec17/lec17-filled.html) to get the names and coefficients of each feature.\n",
    "- As in the examples above, make sure your bar charts are sorted such that **the longest bar is always at the top**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87784b63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def d_largest_coefficients(pipe, d, sign):\n",
    "    ...\n",
    "\n",
    "# Feel free to change these inputs to make sure your function works correctly.\n",
    "emails = pd.read_csv('data/spam_ham_dataset.csv')\n",
    "X_train, X_test, y_train, y_test = train_test_split(emails[['text']], emails['label'], random_state=98)\n",
    "pipe = create_pipe_tfidf(X_train, y_train)\n",
    "\n",
    "# Feel free to change these inputs to make sure your function works correctly.\n",
    "d_largest_coefficients(pipe, d=5, sign=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d6acd7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q01_04\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2754fa71",
   "metadata": {},
   "source": [
    "The function `d_largest_coefficients` should make clear which words increase the predicted probability that an email is spam, and which decrease that probability.\n",
    "\n",
    "Below, we reintroduce the interactive widget you saw after Question 1.1. Can you try and make the predicted probability 99.9%? 0.01%?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065702de",
   "metadata": {},
   "outputs": [],
   "source": [
    "email_widget(pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0258eca",
   "metadata": {},
   "source": [
    "### Question 1.5 [Autograded üíª] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">3 Points</div>\n",
    "\n",
    "The Pipeline we produced in Question 1.1 achieved a very high accuracy, precision, and recall, without us really needing to do anything. By default, `TfidfVectorizer` uses all words in the corpus, i.e. it uses a very large **vocabulary**. You should verify that the Pipeline you've produced creates **43061 features**, i.e. uses 43061 words.\n",
    "\n",
    "Recall, $L_1$ regularization ‚Äì called LASSO in the context of linear regression ‚Äì is a form of regularization that not only prevents overfitting, but also encourages **sparsity**, in that many of the optimal parameters end up being set to 0. In Homework 9, we used LASSO as a form of feature selection ‚Äì coefficients that were set to 0 are \"turned off\" or \"disabled\" by the model, since they're not needed in order to maximize cross-validation performance.\n",
    "\n",
    "Let's use $L_1$-regularized logistic regression here, to determine **which** words are actually important for building a generalizable model. Typically, when regularizing, we've used `GridSearchCV` to use cross-validation to find an optimal choice of $\\lambda$, the regularization hyperparameter. But instead, here, we'll pick a value of $\\lambda$ for you to use in advance, to illustrate a point.\n",
    "\n",
    "Below, complete the implementation of the function `create_pipe_l1_reg`, which takes in a DataFrame like `X_train` and a Series like `y_train` and returns a **tuple** such that:\n",
    "- the first element is a fit Pipeline, just like the one in Question 1.1, but instead with an $L_1$-regularized logistic regression model at the end (see details below).\n",
    "- the second element is the **number of non-zero coefficients in the resulting fit model**, i.e. the number of words that the final model ended up using, after $L_1$ regularization assigned a coefficient of 0 to some words.\n",
    "\n",
    "Example behavior is given below.\n",
    "\n",
    "```python\n",
    ">>> pipe_l1_reg, num_words = create_pipe_l1_reg(X_train, y_train)\n",
    ">>> pipe_l1_reg.predict_proba(pd.DataFrame([{\n",
    "    'text': 'hey eecs 398 students attached is where you are sitting for the exam'\n",
    "}]))\n",
    "array([[0.64731552, 0.35268448]])\n",
    "\n",
    ">>> num_words\n",
    "31\n",
    "```\n",
    "\n",
    "Some guidance:\n",
    "\n",
    "- The `LogisticRegression` class supports regularization directly, but you'll need to look into the arguments that its constructor accepts. In our implementation, we only specified four arguments to `LogisticRegression`:\n",
    "    - `C=0.2`: `C` is the name for the regularization hyperparameter for `LogisticRegression` in `sklearn`, and **it behaves opposite to $\\lambda$ / `alpha` in `Ridge`/`Lasso`, in that small values of `C` imply _more_ regularization**! So, `C=0.2` will result in a very regularized model.\n",
    "    - `penalty`: Read the spec above to see what this should be.\n",
    "    - `solver`: Required to change the `penalty` from the default; the role of the solver is to minimize empirical risk and find optimal model parameters, similar to gradient descent.\n",
    "    - `random_state=98`: The solver you'll choose above behaves non-deterministically; set the `random_state` to `98` so that you get the same results (as us) every time.\n",
    "- **You'll _have_ to read the documentation!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db69b15c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_pipe_l1_reg(X_train, y_train):\n",
    "    ...\n",
    "\n",
    "emails = pd.read_csv('data/spam_ham_dataset.csv')\n",
    "X_train, X_test, y_train, y_test = train_test_split(emails[['text']], emails['label'], random_state=98)\n",
    "\n",
    "# Feel free to change these inputs to make sure your function works correctly.\n",
    "pipe_l1_reg, num_words = create_pipe_l1_reg(X_train, y_train)\n",
    "print(num_words)\n",
    "pipe_l1_reg.predict_proba(pd.DataFrame([{\n",
    "    'text': 'hey eecs 398 students attached is where you are sitting for the exam'\n",
    "}]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b30d1c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q01_05\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fc1e6a",
   "metadata": {},
   "source": [
    "If you completed Question 1.5 correctly, you should have noticed that the number of coefficients with non-zero values was relatively small, compared to the total number of words in the corpus!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d2a0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_l1_reg, num_words = create_pipe_l1_reg(X_train, y_train)\n",
    "num_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647efc81",
   "metadata": {},
   "source": [
    "But, even just by using a handful of words from the corpus, we're still able to achieve relatively high accuracy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e04579",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_l1_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b2add4",
   "metadata": {},
   "source": [
    "See if you can figure out which 31 words it ended up using ‚Äì and see if you can do it in one line below (using what you've learned in Question 1.4!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fefe45",
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd6ad85",
   "metadata": {},
   "source": [
    "Nice work! You've built a spam email classifier, and more importantly, you **understand** how it works under-the-hood.\n",
    "\n",
    "If you're curious to learn more about how Gmail's spam classifier works, [read this article](https://workspace.google.com/blog/identity-and-security/an-overview-of-gmails-spam-filters)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2fb77d",
   "metadata": {},
   "source": [
    "## Question 2: Vino üç∑\n",
    "\n",
    "If you're not super familiar with wine ‚Äì and, legally, perhaps you're not supposed to be! ‚Äì wine is an alcoholic beverage made from **grapes** üçá. There are several different types of grapes (formally known as \"cultivars\") grown for the purposes of making wine. In this question, we'll build various classifiers to predict the type of grape used to create a particular wine, given other properties of that wine.\n",
    "\n",
    "Run the cell below to load in the full dataset, taken from the [here](https://archive.ics.uci.edu/dataset/109/wine). The dataset was originally collected in 1991 in a region of Italy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dc0e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = pd.read_csv('data/wine.csv')\n",
    "wine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b4e980",
   "metadata": {},
   "source": [
    "The first column, `'Class'`, contains the type of grape used to produce the wine. There are three classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a93f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine['Class'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1a40b6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The other 13 columns describe various attributes of the wines. Conveniently, they're all already numerical, so we don't need to perform any one hot encoding.\n",
    "\n",
    "Before we build any models or draw any visualizations, let's perform a train-test split. The function below performs such a train-test split; we've implemented a function for this to make testing your code easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c05ac90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_wine_data(path='data/wine.csv'):\n",
    "    wine = pd.read_csv(path)\n",
    "    return train_test_split(wine.iloc[:, 1:], wine.iloc[:, 0], random_state=98)\n",
    "    \n",
    "X_train_wine, X_test_wine, y_train_wine, y_test_wine = split_wine_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf991fbf",
   "metadata": {},
   "source": [
    "Run the cell below to draw a scatter plot. The plotting code is abstracted away in the file `hw10_util.py` to keep this notebook shorter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2003dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "util.wine_scatter(X_train_wine, y_train_wine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3897acfb",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Remember, each point corresponds to a different wine. You'll notice there are three variables on display:\n",
    "- The class (type) of grape used to create the wine.\n",
    "- The wine's alcohol by volume percentage. For instance, an `'Alcohol'` value of 13 means that 13% of the wine, by volume, is alcohol; the other 87% is made up of water, grape, etc. Larger values correspond to \"stronger\" wines.\n",
    "- The wine's color intensity; presumably, larger values mean darker colors.\n",
    "\n",
    "To start, we'll aim to predict the class of grape of a wine, given its alcohol and color intensity values. Later, we'll consult the other features in the dataset. Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d75be8",
   "metadata": {},
   "source": [
    "### Question 2.1 [Autograded üíª] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">3 Points</div>\n",
    "\n",
    "Complete the implementation of the function `create_wine_tree`, which takes in a training set like `X_train_wine` and `y_train_wine` and returns a fit **decision tree**, such that:\n",
    "\n",
    "- The `max_depth` hyperparameter is chosen via cross-validation. Try all values between 1 and 25, inclusive, and use the default 5-fold cross-validation.\n",
    "- The tree is only trained using the `'Alcohol'` and `'Color Intensity'` features.\n",
    "\n",
    "Example behavior is given below.\n",
    "\n",
    "```python\n",
    "# Technically, wine_tree is a fit GridSearchCV object,\n",
    "# not a fit DecisionTreeClassifier object.\n",
    ">>> wine_tree = create_wine_tree(X_train_wine, y_train_wine)\n",
    ">>> wine_tree\n",
    "```\n",
    "\n",
    "<div align=\"left\">\n",
    "<img src=\"imgs/wine_tree_repr.png\" width=300>\n",
    "</div>\n",
    "\n",
    "```python\n",
    "# Note that we're only specifying 'Alcohol' and 'Color Intensity' values when\n",
    "# making predictions.\n",
    ">>> wine_tree.predict(pd.DataFrame([{\n",
    "    'Alcohol': 13,\n",
    "    'Color Intensity': 5\n",
    "}]))\n",
    "array(['Grape 3'], dtype=object)\n",
    "```\n",
    "\n",
    "Some guidance:\n",
    "- Since there is randomness in how decision trees are fit, set `random_state=98` when instantiating your `DecisionTreeClassifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b016e18d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_wine_tree(X_train_wine, y_train_wine):\n",
    "    # Hint: You'll need to import several classes yourself.\n",
    "    # Do so within your function.\n",
    "    ...\n",
    "    \n",
    "X_train_wine, X_test_wine, y_train_wine, y_test_wine = split_wine_data()\n",
    "\n",
    "# Feel free to change these inputs to make sure your function works correctly.\n",
    "wine_tree = create_wine_tree(X_train_wine, y_train_wine)\n",
    "wine_tree.predict(pd.DataFrame([{\n",
    "    'Alcohol': 12.5,\n",
    "    'Color Intensity': 3\n",
    "}]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decf0493",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q02_01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f9e13e",
   "metadata": {},
   "source": [
    "One benefit to using a decision tree is that we can visualize the resulting model as... a tree üå≤! Run the cell below to see your fit tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7192c961",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train_wine, X_test_wine, y_train_wine, y_test_wine = split_wine_data()\n",
    "wine_tree = create_wine_tree(X_train_wine, y_train_wine)\n",
    "util.show_wine_decision_tree(wine_tree.best_estimator_, X_train_wine[['Alcohol', 'Color Intensity']]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea57a6b",
   "metadata": {},
   "source": [
    "While the maximum depth of your tree is 4 (which should have been the optimal value of `max_depth` that `GridSearchCV` found), you'll notice that some branches terminate before a max depth of 4.\n",
    "\n",
    "Let's visualize the decision boundaries of your fit decision tree, in terms of the feature space (that is, in a plot of `'Color Intensity'` of `'Alcohol'`). The scatter plot drawn is of the **training set**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0502668b",
   "metadata": {},
   "outputs": [],
   "source": [
    "util.show_wine_decision_boundary(wine_tree, X_train_wine, y_train_wine, title=f\"Decision Tree of Depth {wine_tree.best_params_['max_depth']}, Drawn on Training Set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdccc7af",
   "metadata": {},
   "source": [
    "As we learned in Lecture 21, decision trees partition the feature space into rectangles!\n",
    "\n",
    "Let''s switch our attention to our tree's performance on the **test set**. First, we'll compute the accuracy of your model, just so we have a baseline to refer to later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f59cf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_tree.score(X_test_wine[['Alcohol', 'Color Intensity']], y_test_wine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58bbeed",
   "metadata": {},
   "source": [
    "And finally, let's draw the **confusion matrix** for your decision tree's predictions ‚Äì using the **test** set once again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd7016c",
   "metadata": {},
   "outputs": [],
   "source": [
    "util.show_wine_confusion_matrix(wine_tree, X_test_wine[['Alcohol', 'Color Intensity']], y_test_wine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c5268b",
   "metadata": {},
   "source": [
    "Above, we're seeing that for instance, in 2 cases, we predicted Grape 1 for a wine that actually used Grape 3.\n",
    "\n",
    "With these baselines in mind, let's see how other classification techniques perform!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864d1f92",
   "metadata": {},
   "source": [
    "### Question 2.2 [Autograded üíª] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">5 Points</div>\n",
    "\n",
    "In this question, your job is to train **six** different classifiers on the wine training set, so that we can compare and contrast their results. \n",
    "\n",
    "Complete the implementation of the function `train_wine_models`, which takes in a training set like `X_train_wine` and `y_train_wine` and returns a **dictionary** in which\n",
    "- the keys are model names as strings (specified below), and\n",
    "- the values are corresponding **already-fit** model objects, fit on just the `'Alcohol'` and `'Color Intensity'` features of `X_train_wine` like before.\n",
    "\n",
    "The models you need to fit are described below.\n",
    "\n",
    "| Model Name | Model Description |\n",
    "| --- | --- |\n",
    "| `'Decision Tree (max_depth=4)'` | Decision tree classifier with maximum depth hard-coded to 4 |\n",
    "| `'Random Forest (max_depth=4)'` | Random forest classifier with maximum depth hard-coded to 4 |\n",
    "| `'KNN (k=10)'` | $k$-nearest neighbors classifier with $k=10$ |\n",
    "| `'Naive Bayes'` | Gaussian Na√Øve Bayes classifier |\n",
    "| `'Logistic Regression'` | Logistic regression* (see \"Some guidance\" for more details) with `C=np.inf` (no regularization; `sklearn` regularizes by default)|\n",
    "| `'Neural Network'` | Multi-layer perceptron, i.e. a basic neural network |\n",
    "\n",
    "Example behavior is given below.\n",
    "\n",
    "```python\n",
    ">>> model_dict = train_wine_models(X_train_wine, y_train_wine)\n",
    ">>> model_dict.keys()\n",
    "dict_keys(['Decision Tree (max_depth=4)', 'Random Forest (max_depth=4)', 'KNN (k=10)', 'Naive Bayes', 'Logistic Regression', 'Neural Network'])\n",
    "\n",
    ">>> model_dict['Naive Bayes'].predict(pd.DataFrame([{'Alcohol': 15, 'Color Intensity': 15}]))[0]\n",
    "'Grape 3'\n",
    "```\n",
    "\n",
    "Some guidance:\n",
    "- **In all models that accept a `random_state` argument, set `random_state=98`.** Otherwise, if a hyperparameter isn't specified, don't set it. You shouldn't need to grid search anything in this question.\n",
    "- We've only covered a few of the models listed above in lecture. Fortunately, the `sklearn` model interface works the same for the rest too, you just need to determine what they're called and how to use them.\n",
    "- *As we'll see in Lecture 22, logistic regression is naively designed for binary classification, but can be extended to support multiple classes, in a way called \"multinomial\" logistic regression. Since `y_train_wine` has three classes, multinomial logistic regression will be performed automatically, so you don't really need to think about this.\n",
    "- In Question 2.3, we're going to retrain the classifiers above, but with some feature engineering steps. To make this process easier, we recommend defining a helper function that returns a dictionary of **un-fit** model instances, that `train_wine_models` then takes in, loops through, and trains. If you do this, you can reuse your helper function later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b884cd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_wine_models(X_train_wine, y_train_wine):\n",
    "    ...\n",
    "\n",
    "X_train_wine, X_test_wine, y_train_wine, y_test_wine = split_wine_data()\n",
    "model_dict = train_wine_models(X_train_wine, y_train_wine)\n",
    "# Feel free to experiment with the behavior of any of these models below.\n",
    "model_dict['Neural Network'].predict(pd.DataFrame([{'Alcohol': 15, 'Color Intensity': 15}]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4e4639",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q02_02\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27810149",
   "metadata": {},
   "source": [
    "Now that you've done the hard work of specifying these various models, let's look at how well they perform. First, let's visualize all six decision boundaries on the **training** set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ea6159",
   "metadata": {},
   "outputs": [],
   "source": [
    "util.show_wine_decision_boundaries_grid(model_dict, X_train_wine, y_train_wine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e7fe7f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "Before proceeding, **look üëÄ** at how all six decision boundaries are shaped, and think about _why_ they are shaped the way they are.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a12651",
   "metadata": {},
   "source": [
    "How do they perform on the test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b71c918",
   "metadata": {},
   "outputs": [],
   "source": [
    "util.compute_and_plot_accuracies(model_dict, X_train_wine, y_train_wine, X_test_wine, y_test_wine, features=['Alcohol', 'Color Intensity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419f329a",
   "metadata": {},
   "source": [
    "Interesting! Many of our models happen to perform better on the test set than they do on the training set. **Think about some possible reasons as to how this may have happened!**\n",
    "\n",
    "It seems that the (multinomial) logistic regression and Naive Bayes models happen to perform the best on this specific test set, both with a **test accuracy of 88.89%**. That's not to say logistic regression and Naive Bayes are _always_ better than the other techniques. If we tuned hyperparameters for various other models, we could almost surely improve our performance.\n",
    "\n",
    "Until now, we've only used two features to predict the type of grape used in a wine ‚Äì `'Alcohol'` and `'Color Intensity'` ‚Äì though there are 11 others that we haven't used. We also haven't _processed_ any of the features. In the next part of this question, we'll address the latter point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a87951c",
   "metadata": {},
   "source": [
    "### Question 2.3 [Autograded üíª] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">4 Points</div>\n",
    "\n",
    "Complete the implementation of the function `train_standardized_wine_models`, which takes in a training set like `X_train_wine` and `y_train_wine` and returns a **dictionary** with the exact same keys as the dictionary returned by `train_wine_models`. The values in the returned dictionary should still be **already-fit** models, the difference here being that all models should be **Pipelines that start with a `StandardScaler`**, i.e. all models must first standardize their features before training.\n",
    "\n",
    "Example behavior is given below.\n",
    "\n",
    "```python\n",
    ">>> standardized_model_dict = train_wine_models(X_train_wine, y_train_wine)\n",
    "\n",
    "# Keep the same specific hyperparameters (and names) we specified in Question 2.2!\n",
    ">>> standardized_model_dict.keys()\n",
    "dict_keys(['Decision Tree (max_depth=4)', 'Random Forest (max_depth=4)', 'KNN (k=10)', 'Naive Bayes', 'Logistic Regression', 'Neural Network'])\n",
    "\n",
    ">>> standardized_model_dict['Naive Bayes']\n",
    "```\n",
    "\n",
    "<div align=\"left\">\n",
    "<img src=\"imgs/pipe.png\" width=200>\n",
    "</div>\n",
    "\n",
    "Some guidance:\n",
    "- You **can't** start by calling `train_wine_models`, because the models in the dictionary that `train_wine_models` returns are all already trained. Instead, try following the guidance in Question 2.2 about writing a helper function.\n",
    "- Try and avoid copy-and-pasting: our implementation below only has one call to `make_pipeline`, and one call to `fit` (both in a `for`-loop)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9d8d3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_standardized_wine_models(X_train_wine, y_train_wine):\n",
    "    ...\n",
    "\n",
    "X_train_wine, X_test_wine, y_train_wine, y_test_wine = split_wine_data()\n",
    "standardized_model_dict = train_standardized_wine_models(X_train_wine, y_train_wine)\n",
    "# Feel free to experiment with the behavior of any of these models below.\n",
    "standardized_model_dict['Naive Bayes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da5e86d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q02_03\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2804aa88",
   "metadata": {},
   "source": [
    "What was the effect of standardizing on model performance? Let's see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42097199",
   "metadata": {},
   "outputs": [],
   "source": [
    "util.compare_model_dictionaries(model_dict, standardized_model_dict, X_train_wine, y_train_wine, X_test_wine, y_test_wine, features=['Alcohol', 'Color Intensity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239963ae",
   "metadata": {},
   "source": [
    "Let's summarize what we're seeing:\n",
    "\n",
    "| Performance UNCHANGED due to standardization | Performance CHANGED due to standardization |\n",
    "| --- | --- |\n",
    "| Logistic regression<br>Naive Bayes<br>Random forest<br>Decision tree | Neural network<br>KNN |\n",
    "\n",
    "It seems that in some cases, standardizing our features impacts model performance, and in other cases, it does not! **Why?**\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**Action Item**: Do a little bit of research into all six models above. In which of them is model performance impacted by standardization? In the case of logistic (and linear) regression, why do we still sometimes standardize, even though it doesn't impact performance? Would the results be different if we regularized our logistic regression model (i.e. set `C=1` in `LogisticRegression`)?\n",
    "\n",
    "You don't need to submit your answers to these prompts anywhere (since this homework is fully autograded), but you **must** think about them!\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f149f1f",
   "metadata": {},
   "source": [
    "### Question 2.4 [Autograded üíª] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">3 Points</div>\n",
    "\n",
    "You may have noticed that the best models above still only achieve **88.89%** test set accuracy. Complete the implementation of the function `create_best_wine_model`, which takes in a training set like `X_train_wine` and `y_train_wine` and returns a **single, already-fit model** that achieves **at least 91% test set accuracy**. As before, your model should be trained using just the `'Alcohol'` and `'Color Intensity'` features of `X_train_wine`.\n",
    "\n",
    "Some guidance:\n",
    "- You're free to use any classifier in `sklearn`, though it's possible to satisfy the requirements of the assignment using one of the types of models you've already used somewhere in Question 2.\n",
    "- Feel free to tune hyperparameters and engineer features as you wish.\n",
    "- If your model accepts a `random_state` argument, provide one, so that you don't accidentally achieve an accuracy of under 91% on Gradescope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f14c0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_best_wine_model(X_train_wine, y_train_wine):\n",
    "    ...\n",
    "\n",
    "X_train_wine, X_test_wine, y_train_wine, y_test_wine = split_wine_data()\n",
    "\n",
    "# The value below must be above 91%!\n",
    "best_model = create_best_wine_model(X_train_wine, y_train_wine)\n",
    "best_model.score(X_test_wine[['Alcohol', 'Color Intensity']], y_test_wine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ed7f72",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q02_04\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b13ddc",
   "metadata": {},
   "source": [
    "Feel free to continue experimenting with other features in the data and other types of classifiers built into `sklearn`. Happy exploring! üç∑"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbb07d4",
   "metadata": {},
   "source": [
    "## Question 3: Descendents üßë‚Äçüßë‚Äçüßí‚Äçüßí\n",
    "\n",
    "In this question, you'll develop a deep understanding of gradient descent, a numerical method (first introduced in [Lecture 20](https://practicaldsc.org/resources/lectures/lec20/lec20-filled.html)) designed to minimize functions computationally. We'll switch our focus back to regression, unlike in the first two questions, which were about classification.\n",
    "\n",
    "To motivate our specific goals, let's look at the commute times dataset that we're now very familiar with from lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e47bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/commute-times.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc749011",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "One of our running examples has been to build a simple linear regression model of the form $H(x_i) = w_0 + w_1 x_i$, that predicts commute time in `'minutes'` given `'departure_hour'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757476b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(df, x='departure_hour', y='minutes').update_layout(xaxis_title='Home Departure Time (AM)', yaxis_title='Minutes', title='Commuting Time vs. Home Departure Time')\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f851fea",
   "metadata": {},
   "source": [
    "The \"default\" approach has been to choose squared loss, meaning that we choose the intercept, $w_0^*$, and slope, $w_1^*$, that minimize **mean squared error**:\n",
    "\n",
    "$$R_\\text{sq}(w_0, w_1) = \\frac{1}{n} \\sum_{i = 1}^n \\left( y_i - (w_0 + w_1 x_i) \\right)^2$$\n",
    "\n",
    "We solved for $w_0^*$ and $w_1^*$ by hand using calculus in Lecture 12, and in Lectures 14 and 15 we looked at a solution that was derived using linear algebra (which is how we found the normal equations). For reference, we'll calculate these below here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3bd41f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "baseline = LinearRegression()\n",
    "baseline.fit(df[['departure_hour']], df['minutes'])\n",
    "w_squared_loss = baseline.intercept_, baseline.coef_[0]\n",
    "w_squared_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c88136",
   "metadata": {},
   "source": [
    "So, under squared loss, we have $w_0^* = 142.45$ and $w_1^* = -8.19$. Keep these values in mind throughout the question. For reference, here's what <b><span style=\"color:red\">the line that minimizes mean squared error</span></b> looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210ec6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.add_trace(\n",
    "    go.Scatter(x=[5.5, 11.5], y=[baseline.predict([[5.5]])[0], baseline.predict([[11.5]])[0]], mode='lines', line=dict(color='red'), name='Best Line (MSE)')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bcc571",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Another approach is to choose absolute loss, meaning that we choose intercept and slope that minimize **mean absolute error**:\n",
    "\n",
    "$$R_\\text{abs}(w_0, w_1) = \\frac{1}{n} \\sum_{i = 1}^n \\left| y_i - (w_0 + w_1 x_i) \\right|$$\n",
    "\n",
    "In Homework 7, Question 3, you implemented a brute-force computational routine that found the optimal slope and intercept in $O(n^3)$ time.\n",
    "\n",
    "<br>\n",
    "\n",
    "What we'll explore here is a **new** loss function, Tukey's loss function, named after [John Tukey](https://en.wikipedia.org/wiki/John_Tukey), the creator of the box plot. It is defined as follows:\n",
    "\n",
    "$$L_T(y_i, H(x_i)) = \\begin{cases} 1 - \\left( 1 - \\left( \\frac{y_i - H(x_i)}{50} \\right)^2 \\right)^3 && \\text{if} \\: |y_i - H(x_i)| \\leq 50, \\\\ 1 && \\text{otherwise} \\end{cases}$$\n",
    "\n",
    "To make sense of how the loss function behaves, let's graph it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f22579",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tukey(y_actual, y_pred, c=50):\n",
    "    error = y_actual - y_pred\n",
    "    if np.abs(error) <= c:\n",
    "        return 1 - (1 - (error / c) ** 2) ** 3\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "hs = np.linspace(-200, 200, 10000)\n",
    "px.line(x=hs, y=[tukey(0, h) for h in hs], title='Tukey Loss').update_layout(xaxis_title='h', yaxis_title='L(0, h)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf06ad9b",
   "metadata": {},
   "source": [
    "Note that Tukey loss is defined **piecewise**. For predictions in which $|y_i - H(x_i)|$ is more than 50, the loss is capped at 1, resulting in a loss function that is _very_ robust to outliers (unlike squared loss, which is influenced heavily by outliers). For predictions in which $|y_i - H(x_i)| \\leq 50$, the loss looks very similar to squared loss. The choice of 50 as the threshold was arbitrary; we could have chosen a different transition point (and, once you finish the question, it's worth investigating how your results would have changed if 50 was replaced with 5 or 100).\n",
    "\n",
    "You'll also notice that the \"handoff\" from the curved part to the flat part at $h = \\pm 50$ is smooth, meaning Tukey loss is differentiable, unlike absolute loss. This will be important!\n",
    "\n",
    "Let's continue to consider the simple linear regression model, $H(x_i) = w_0 + w_1 x_i$, where $x_i$ is a scalar, not a vector. In that case, the empirical risk $R_T$ using Tukey loss looks like:\n",
    "\n",
    "$$R_T(w_0, w_1) = \\frac{1}{n} \\sum_{i = 1}^n  \\begin{cases} 1 - \\left( 1 - \\left( \\frac{y_i - (w_0 + w_1 x_i)}{50} \\right)^2 \\right)^3 && \\text{if} \\: |y_i - (w_0 + w_1 x_i)| \\leq 50, \\\\ 1 && \\text{otherwise} \\end{cases}$$\n",
    "\n",
    "Let's graph the loss surface, using some help from the helper functions we've defined in `hw10_util.py`. Note that we're specifying that we want the $x$'s and $y$'s to come from the `'departure_hour'` and `'minutes'` columns in `df`, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70554c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "util.draw_loss_surface_tukey_commute(xs=df['departure_hour'], ys=df['minutes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ac6a33",
   "metadata": {},
   "source": [
    "Let's use gradient descent to find the intercept, $w_0^*$, and slope, $w_1^*$, that minimize the loss surface above. That is, let's find the best intercept and slope to use in a simple linear model that predicts `'minutes'` using `'departure_hour'`, using Tukey loss. We can think of this problem as trying to find the vector, $\\vec w^*$, that minimizes $R_T(\\vec w)$, where $\\vec w = \\begin{bmatrix} w_0 \\\\ w_1 \\end{bmatrix}$.\n",
    "\n",
    "The gradient descent update rule is as follows:\n",
    "\n",
    "$$\\vec w^{(t+1)} = \\vec w^{(t)} - \\alpha \\nabla R_T( \\vec w^{(t)})$$\n",
    "\n",
    "where $\\vec w^{(t)}$ is our guess for the minimizing $\\vec w^*$ at timestep $t$. To start the process, we'll need to decide on an initial guess, $\\vec w^{(0)}$, and a step size, $\\alpha$, which we will do later.\n",
    "\n",
    "But, more crucially, to run gradient descent ourselves, we'll need to be able to compute $\\nabla R_T(\\vec w^{(t)})$, i.e. the **gradient** of $R_T$ at any point $\\vec w$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e538c4",
   "metadata": {},
   "source": [
    "### Question 3.1 [Autograded üíª] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">5 Points</div>\n",
    "\n",
    "As a refresher, the empirical risk function that we're trying to minimize is:\n",
    "\n",
    "$$R_T(\\vec w) = R_T(w_0, w_1) = \\frac{1}{n} \\sum_{i = 1}^n  \\begin{cases} 1 - \\left( 1 - \\left( \\frac{y_i - (w_0 + w_1 x_i)}{50} \\right)^2 \\right)^3 && \\text{if} \\: |y_i - (w_0 + w_1 x_i)| \\leq 50, \\\\ 1 && \\text{otherwise} \\end{cases}$$\n",
    "\n",
    "Complete the implementation of the function `tukey_gradient`, which takes in:\n",
    "- `w`, an **array of length 2**, corresponding to a value of $w_0$ and a value of $w_1$, and\n",
    "- `xs` and `ys`, two Series/1D arrays with the same length, corresponding to sequences of $x$-values (like `df['departure_hour']`) and $y$-values (like `df['minutes']`), respectively.\n",
    "\n",
    "`tukey_gradient` should return an **array of length 2**, containing the value of the gradient of $R_T$, evaluated at the point `w` that is passed in. Example behavior is given below.\n",
    "\n",
    "```python\n",
    "# This says that dR/dw0, when (w0, w1) = (100, -5), is -0.02389409, and\n",
    "# dR/dw1, when (w0, w1) = (100, -5), is -0.20369193.\n",
    ">>> tukey_gradient(np.array([100, -5]), xs=df['departure_hour'], ys=df['minutes'])\n",
    "array([-0.02389409, -0.20369193])\n",
    "```\n",
    "\n",
    "Some guidance:\n",
    "- Remember, the gradient of a function is a vector of partial derivatives. So, $\\nabla R_T(\\vec w) = \\begin{bmatrix} \\frac{\\partial R}{\\partial w_0} \\\\ \\frac{\\partial R}{\\partial w_1} \\end{bmatrix}$.\n",
    "- Because $R_T$ is a piecewise function, both partial derivatives will also be piecewise, using the same condition as in $R_T$. So, your definition of `tukey_gradient` can involve `if`-statements.\n",
    "- You'll need to do a substantial amount of math on-paper to complete this implementation, and accurately translate it to code. `for`-loops are fine in your implementation.\n",
    "    - Back in Lecture 11, we stressed that the derivative of a sum of functions is equal to the sum of the derivatives of those functions. In other words, $\\frac{\\partial R_T}{\\partial w_0} = \\frac{1}{n} \\sum_{i = 1}^N \\frac{\\partial L_T}{\\partial w_0}$. Given this, it's easiest to start with finding the partial derivatives of just the loss function $L_T$ with respect to $w_0$ and $w_1$, and summing these partial derivatives in a `for`-loop.\n",
    "    - When computing the partial derivatives of $L_T$ with respect to the two parameters, you may find it helpful to perform a substitution, e.g. $e_i = y_i - (w_0 + w_1 x_i)$, and then use the chain rule from calculus, i.e. $\\frac{\\partial L_T}{\\partial w_0} = \\frac{\\partial L_T}{\\partial e_i} \\cdot \\frac{\\partial e_i}{\\partial w_0}$.\n",
    "    - $\\frac{\\partial R}{\\partial w_0}$ and $\\frac{\\partial R}{\\partial w_1}$ will look very similar, but with one small difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efd126d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tukey_gradient(w, xs, ys):\n",
    "    ...\n",
    "\n",
    "# Feel free to change these inputs to make sure your functions work correctly.\n",
    "tukey_gradient(np.array([100, -5]), xs=df['departure_hour'], ys=df['minutes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46009797",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q03_01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648bef5a",
   "metadata": {},
   "source": [
    "### Question 3.2 [Autograded üíª] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">4 Points</div>\n",
    "\n",
    "Complete the implementation of the function `run_gradient_descent_tukey`, which takes in:\n",
    "- `w_initial`, an **array of length 2**, corresponding to an initial guess, $\\vec w^{(0)}$, of the minimizer.\n",
    "- `alpha`, a positive number corresponding to a step size/learning rate.\n",
    "- `xs` and `ys`, two Series/1D arrays with the same length, corresponding to sequences of $x$-values (like `df['departure_hour']`) and $y$-values (like `df['minutes']`), respectively.\n",
    "- `tol`, a float representing the **convergence criteria**, the default value of which will be set to `0.0001` (i.e. $10^{-3}$).\n",
    "- `verbose`, a Boolean flag.\n",
    "\n",
    "`run_gradient_descent_tukey` should run as many iterations of gradient descent as necessary, terminating once $\\lVert \\nabla R_T(\\vec w^{(t)}) \\rVert_2 \\leq \\text{tol}$, i.e. once the $L_2$ norm of `tukey_gradient(w, xs, ys)` (where `w` is the current guess of $\\vec w^*$) is less than `tol`.\n",
    "`run_gradient_descent_tukey` should return a 2D array containing all vectors $\\vec w^{(t)}$ that were visited by gradient descent. In other words, it should return a 2D array of shape `(num_iterations, 2)`, where row 0 is $\\vec w^{(0)}$ (the initial guess), row 1 is $\\vec w^{(1)}$, row 2 is $\\vec w^{(2)}$, and so on, until row -1 is our final guess of $\\vec w^*$.\n",
    "\n",
    "If `verbose=True`, then on iterations 0, 1000, 2000, and so on, use the `display` function to show the iteration number $t$, the value of $\\vec w^{(t)}$, the value of  $R_T(\\vec w^{(t)})$, and the value of $\\lVert \\nabla R_T(\\vec w^{(t)}) \\rVert_2$ (i.e. the norm of the gradient vector) at the current iteration. You can compute $R_T(\\vec w^{(t)})$ using the `tukey` function defined at the top of Question 3, or using `util.empirical_risk`. We won't test your code with `verbose=True`, so you have some flexibility in how to implement it, but you'll need to complete this step in order for the remainder of the question to make sense.\n",
    "\n",
    "Finally, if more than 50,000 iterations have been completed (including the first and current guesses), terminate the algorithm and return an array of shape `(50000, 2)` containing the 50,000 vectors $\\vec w^{(0)}, \\vec w^{(1)}, ... \\vec w^{(49,999)}$ that were visited by the algorithm.\n",
    "\n",
    "Example behavior is given below.\n",
    "\n",
    "```python\n",
    ">>> path = run_gradient_descent_tukey(w_initial=np.array([100, 0]), \n",
    "                                      alpha=10, xs=df['departure_hour'], ys=df['minutes'])\n",
    "\n",
    "# Our guess of w^*, the optimal parameter vector.\n",
    ">>> path[-1]\n",
    "array([121.5414978 ,  -5.85456359])\n",
    "\n",
    "# The number of steps it took to reach the above guess, including the first and last guesses.\n",
    ">>> len(path)\n",
    "7616\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48de896",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_gradient_descent_tukey(w_initial, alpha, xs, ys, tol=0.0001, verbose=False):\n",
    "    ...\n",
    "\n",
    "# Feel free to change these inputs to make sure your functions work correctly.\n",
    "path = run_gradient_descent_tukey(w_initial=np.array([100, 0]), \n",
    "                           alpha=10, \n",
    "                           xs=df['departure_hour'], \n",
    "                           ys=df['minutes'], \n",
    "                           verbose=True)\n",
    "path[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829dc370",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q03_02\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccc7d13",
   "metadata": {},
   "source": [
    "Nice work! Let's experiment with what you've done. The expression below will call your implementation of `run_gradient_descent_tukey`, and draw out the path that gradient descent took to minimize $R_T(\\vec w)$ on the loss surface of $R_T(\\vec w)$ itself, using an initial guess of $\\vec w^{(0)} = \\begin{bmatrix} 100 \\\\ 0 \\end{bmatrix}$ and $\\alpha = 10$ (as in the example output provided in Question 3.2). If you hover over a point in gold, you'll see its iteration number, $t$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e314fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = run_gradient_descent_tukey(w_initial=np.array([100, 0]), alpha=10, xs=df['departure_hour'], ys=df['minutes'])\n",
    "util.draw_loss_surface_tukey_commute(xs=df['departure_hour'], ys=df['minutes'], path=path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d9261c",
   "metadata": {},
   "source": [
    "You should notice that within a few steps, gradient descent gets down to the valley, but it takes thousands more iterations to inch sufficiently close to the true minimum. If you called `run_gradient_descent_tukey` with `verbose=True` above, you should have seen that the value of $R_T(\\vec w^{(t)})$ decreased very slowly every 1000 iterations, and the norm of the gradient vector very, very slowly approached 0. If we settled for a greater tolerance ‚Äì say, $0.0005$ instead of $0.0001$, we'd have converged quicker:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c432bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_gradient_descent_tukey(w_initial=np.array([100, 0]), \n",
    "                           alpha=10, \n",
    "                           xs=df['departure_hour'], \n",
    "                           ys=df['minutes'], \n",
    "                           tol=0.0005,\n",
    "                           verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382d25f2",
   "metadata": {},
   "source": [
    "But, the resulting $\\vec w^*$ of $\\begin{bmatrix} 105.234 \\\\ -3.978 \\end{bmatrix}$ is quite far from what we got when using a tolerance of $0.0001$, which gave us $\\begin{bmatrix} 121.541 \\\\ -5.855 \\end{bmatrix}$. Why do you think this is happening?\n",
    "\n",
    "Instead of weakening our tolerance, perhaps we can try a different learning rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e34555",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_gradient_descent_tukey(w_initial=np.array([100, 0]), \n",
    "                           alpha=15, \n",
    "                           xs=df['departure_hour'], \n",
    "                           ys=df['minutes'], \n",
    "                           tol=0.0001,\n",
    "                           verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d80acb",
   "metadata": {},
   "source": [
    "If you've implemented everything correctly, you should see that the above call to gradient descent maxes out at 50,000 iterations. Something strange must be going on, since the guesses of $\\vec w^{(t)}$ seem to be relatively constant every 1000 iterations, as do the values of $R_T(\\vec w^{(t)})$ and $\\lVert \\nabla R_T(\\vec w^{(t)}) \\rVert_2$. What's going on? Make an educated guess, then run the cell below. (It should take ~30 seconds to render.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281d4587",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = run_gradient_descent_tukey(w_initial=np.array([100, 0]), alpha=15, xs=df['departure_hour'], ys=df['minutes'])\n",
    "util.draw_loss_surface_tukey_commute(xs=df['departure_hour'], ys=df['minutes'], path=path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f88b5a1",
   "metadata": {},
   "source": [
    "It seems that a learning rate of $\\alpha = 15$ is too large, and results in oscillatory behavior between iterations $t$ and $t+1$. Since we're only printing every 1000 iterations when `verbose=True`, we only get to see one of the two oscillatory states (e.g., in the sequence $a$, $b$, $a$, $b$, $a$, $b$, ..., if we sample just the even positions, we'd think the entire sequence was made up of $b$'s).\n",
    "\n",
    "Maybe an even larger learning rate will work better ‚Äì let's try $\\alpha = 50$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ed4f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_gradient_descent_tukey(w_initial=np.array([100, 0]), \n",
    "                           alpha=50, \n",
    "                           xs=df['departure_hour'], \n",
    "                           ys=df['minutes'], \n",
    "                           tol=0.0001,\n",
    "                           verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba9f461",
   "metadata": {},
   "source": [
    "That was quick... what happened?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ea448b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = run_gradient_descent_tukey(w_initial=np.array([100, 0]), alpha=50, xs=df['departure_hour'], ys=df['minutes'])\n",
    "util.draw_loss_surface_tukey_commute(xs=df['departure_hour'], ys=df['minutes'], path=path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f38a2d",
   "metadata": {},
   "source": [
    "Why did gradient descent get stuck up top? Something you may have noticed is that $R_T(\\vec w)$ is **not convex**. This means that there can be regions in which the gradient of $R_T(\\vec w)$ is 0 that don't correspond to a global minimum (which isn't possible for convex functions). The step size of $\\alpha = 50$ is so large that, after a few iterations, gradient descent lands us in the flat region, and once a $\\vec w^{(t)}$ lands there, $\\nabla R_T(\\vec w^{(t)}) = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$, terminating the algorithm instantly.\n",
    "\n",
    "So, to summarize:\n",
    "- Due to the nature of the loss surface, gradient descent can get _near_ the minimum fairly quickly, but may take many iterations to actually converge.\n",
    "- If we choose the step size to be too large, gradient descent may oscillate infinitely, \"bouncing\" over the minimum.\n",
    "- Since the loss surface is not convex, gradient descent can get \"trapped\" in flat regions and terminate mistakenly.\n",
    "\n",
    "In future courses ‚Äì and in the real world ‚Äì you'll look at solutions to all of these problems. But for now, you hopefully have a better understanding of how gradient descent works, and how it can go wrong.\n",
    "\n",
    "Finally, let's actually take a look üëÄ at the line that minimizes mean Tukey loss on the commute times dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6144946d",
   "metadata": {},
   "outputs": [],
   "source": [
    "w0, w1 = run_gradient_descent_tukey(w_initial=np.array([100, 0]), \n",
    "                                    alpha=10, xs=df['departure_hour'], ys=df['minutes'],\n",
    "                                    verbose=True)[-1]\n",
    "w0, w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6d52fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.add_trace(\n",
    "    go.Scatter(x=[5.5, 11.5], y=[w0 + w1 * 5.5, w0 + w1 * 11.5], mode='lines', line=dict(color='gold'), name='Best Line (Mean Tukey Loss)')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f2dd01",
   "metadata": {},
   "source": [
    "Knowing what you know about Tukey loss, how does the <b><span style=\"color:red\">line that minimizes mean squared error</span></b> compare to the <b><span style=\"color: gold\">line that minimizes mean Tukey loss</span></b>? You don't need to write the answer to this question ‚Äì or any of the leading questions in this notebook ‚Äì anywhere, but you _should_ think about them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cc1d5b",
   "metadata": {},
   "source": [
    "## Finish Line üèÅ\n",
    "\n",
    "Congratulations! You're ready to submit Homework 10. Remember, Homework 10 is fully autograded, so you only need to submit it once.\n",
    "\n",
    "1. Select `Kernel -> Restart & Run All` to ensure that you have executed all cells, including the test cells.\n",
    "2. Read through the notebook to make sure everything is fine and all tests passed.\n",
    "3. Run the cell below to run all tests, and make sure that they all pass.\n",
    "4. Download your notebook using `File -> Download as -> Notebook (.ipynb)`, then upload your notebook to Gradescope under **\"Homework 10\"**. Make sure your notebook is still named `hw10.ipynb` and the name has not been changed.\n",
    "5. Stick around while the Gradescope autograder grades your work.\n",
    "6. Check that you have a confirmation email from Gradescope and save it as proof of your submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "otter": {
   "tests": {
    "q01_01": {
     "name": "q01_01",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> emails = pd.read_csv('data/spam_ham_dataset.csv')\n>>> X_train, X_test, y_train, y_test = train_test_split(emails[['text']], emails['label'], random_state=98)\n>>> pipe = create_pipe_tfidf(X_train, y_train)\n>>> pipe[:-1].transform(X_train).shape == (3878, 43061)\nTrue",
         "failure_message": "create_pipe_tfidf(X_train, y_train) creates the wrong number of features.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> emails = pd.read_csv('data/spam_ham_dataset.csv')\n>>> X_train, X_test, y_train, y_test = train_test_split(emails[['text']], emails['label'], random_state=98)\n>>> pipe = create_pipe_tfidf(X_train, y_train)\n>>> np.isclose(pipe[:-1].transform(X_train).mean(), 0.00015912472223089343)\nTrue",
         "failure_message": "create_pipe_tfidf(X_train, y_train) doesn't create TF-IDF features.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> import sklearn\n>>> emails = pd.read_csv('data/spam_ham_dataset.csv')\n>>> X_train, X_test, y_train, y_test = train_test_split(emails[['text']], emails['label'], random_state=98)\n>>> pipe = create_pipe_tfidf(X_train, y_train)\n>>> isinstance(pipe[-1], sklearn.linear_model._logistic.LogisticRegression)\nTrue",
         "failure_message": "create_pipe_tfidf(X_train, y_train) doesn't end with a LogisticRegression model.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> emails = pd.read_csv('data/spam_ham_dataset.csv')\n>>> X_train, X_test, y_train, y_test = train_test_split(emails[['text']], emails['label'], random_state=98)\n>>> pipe = create_pipe_tfidf(X_train, y_train)\n>>> probs = pipe.predict_proba(pd.DataFrame([{'text': 'hey eecs 398 students attached is where you are sitting for the exam'}]))\n>>> np.allclose(probs, np.array([[0.59450521, 0.40549479]]))\nTrue",
         "failure_message": "create_pipe_tfidf(X_train, y_train) returns the wrong predicted probabilities for the example in the question.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> emails = pd.read_csv('data/spam_ham_dataset.csv')\n>>> X_train, X_test, y_train, y_test = train_test_split(emails[['text']], emails['label'], random_state=98)\n>>> pipe = create_pipe_tfidf(X_train, y_train)\n>>> preds = pipe.predict(X_train)\n>>> np.sum(preds == 'spam') == 1152\nTrue",
         "failure_message": "create_pipe_tfidf(X_train, y_train) returns the wrong number of spam predictions on the training set.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> emails = pd.read_csv('data/spam_ham_dataset.csv')\n>>> X_train, X_test, y_train, y_test = train_test_split(emails[['text']], emails['label'], random_state=98)\n>>> pipe = create_pipe_tfidf(X_train, y_train)\n>>> probs = pipe.predict_proba(pd.DataFrame([{'text': 'subject: save on prescription medications dear lucky reader'}]))\n>>> np.allclose(probs, np.array([[0.19116901, 0.80883099]]))\nTrue",
         "failure_message": "create_pipe_tfidf(X_train, y_train) returns the wrong predicted probabilities for a new input email.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> emails = pd.read_csv('data/spam_ham_dataset.csv')\n>>> X_train, X_test, y_train, y_test = train_test_split(emails[['text']], emails['label'], random_state=98)\n>>> pipe = create_pipe_tfidf(X_train.tail(30), y_train.tail(30))\n>>> probs = pipe.predict_proba(pd.DataFrame([{'text': 'santa ono is not in the dataset'}]))\n>>> np.allclose(probs, np.array([[0.65571626, 0.34428374]]))\nTrue",
         "failure_message": "create_pipe_tfidf(X_train.tail(30), y_train.tail(30)) returns the wrong predicted probabilities for a new input email.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q01_02": {
     "name": "q01_02",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> y_actual_ex = np.array([0, 1, 1, 0, 1, 1, 1])\n>>> y_pred_ex = np.array([1, 1, 0, 0, 0, 1, 1])\n>>> np.isclose(calculate_precision(y_actual_ex, y_pred_ex), 0.75)\nTrue",
         "failure_message": "calculate_precision returns the wrong value.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> y_actual_ex = np.array([0, 1, 1, 0, 1, 1, 1])\n>>> y_pred_ex = np.array([1, 1, 0, 0, 0, 1, 1])\n>>> np.isclose(calculate_recall(y_actual_ex, y_pred_ex), 0.6)\nTrue",
         "failure_message": "calculate_recall returns the wrong value.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> y_actual_ex = np.array([0, 1, 1, 0, 1, 1, 1])\n>>> y_pred_ex = np.array([1, 1, 0, 0, 0, 1, 1])\n>>> np.isclose(calculate_fpr(y_actual_ex, y_pred_ex), 0.5)\nTrue",
         "failure_message": "calculate_fpr returns the wrong value.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> y_actual_ex2 = np.array([0, 1, 0, 1])\n>>> y_pred_ex2 = np.array([0, 1, 0, 1])\n>>> np.isclose(calculate_precision(y_actual_ex2, y_pred_ex2), 1.0)\nTrue",
         "failure_message": "calculate_precision returns the wrong value for perfect predictions.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> y_actual_ex2 = np.array([0, 1, 0, 1])\n>>> y_pred_ex2 = np.array([0, 1, 0, 1])\n>>> np.isclose(calculate_recall(y_actual_ex2, y_pred_ex2), 1.0)\nTrue",
         "failure_message": "calculate_recall returns the wrong value for perfect predictions.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> y_actual_ex2 = np.array([0, 1, 0, 1])\n>>> y_pred_ex2 = np.array([0, 1, 0, 1])\n>>> np.isclose(calculate_fpr(y_actual_ex2, y_pred_ex2), 0.0)\nTrue",
         "failure_message": "calculate_fpr returns the wrong value for perfect predictions.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> y_actual_ex3 = np.array([0, 1, 0, 1])\n>>> y_pred_ex3 = np.array([1, 1, 1, 1])\n>>> np.isclose(calculate_precision(y_actual_ex3, y_pred_ex3), 0.5)\nTrue",
         "failure_message": "calculate_precision returns the wrong value when all predictions are spam.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> y_actual_ex3 = np.array([0, 1, 0, 1])\n>>> y_pred_ex3 = np.array([1, 1, 1, 1])\n>>> np.isclose(calculate_recall(y_actual_ex3, y_pred_ex3), 1.0)\nTrue",
         "failure_message": "calculate_recall returns the wrong value when all predictions are spam.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> y_actual_ex3 = np.array([0, 1, 0, 1])\n>>> y_pred_ex3 = np.array([1, 1, 1, 1])\n>>> np.isclose(calculate_fpr(y_actual_ex3, y_pred_ex3), 1.0)\nTrue",
         "failure_message": "calculate_fpr returns the wrong value when all predictions are spam.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> y_actual_ex4 = np.array([0, 0, 1, 1, 1, 0, 1])\n>>> y_pred_ex4 = np.array([0, 1, 1, 0, 1, 0, 1])\n>>> np.isclose(calculate_precision(y_actual_ex4, y_pred_ex4), 0.75)\nTrue",
         "failure_message": "calculate_precision returns the wrong value for a mixed prediction scenario.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> y_actual_ex4 = np.array([0, 0, 1, 1, 1, 0, 1])\n>>> y_pred_ex4 = np.array([0, 1, 1, 0, 1, 0, 1])\n>>> np.isclose(calculate_recall(y_actual_ex4, y_pred_ex4), 0.75)\nTrue",
         "failure_message": "calculate_recall returns the wrong value for a mixed prediction scenario.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> y_actual_ex4 = np.array([0, 0, 1, 1, 1, 0, 1])\n>>> y_pred_ex4 = np.array([0, 1, 1, 0, 1, 0, 1])\n>>> np.isclose(calculate_fpr(y_actual_ex4, y_pred_ex4), 1/3)\nTrue",
         "failure_message": "calculate_fpr returns the wrong value for a mixed prediction scenario.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q01_03": {
     "name": "q01_03",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> emails = pd.read_csv('data/spam_ham_dataset.csv')\n>>> X_train, X_test, y_train, y_test = train_test_split(emails[['text']], emails['label'], random_state=98)\n>>> pipe = create_pipe_tfidf(X_train, y_train)\n>>> stats = pipeline_stats(pipe, X_test, y_test)\n>>> stats.shape[0] == 3\nTrue",
         "failure_message": "pipeline_stats does not return a Series with the correct shape.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> emails = pd.read_csv('data/spam_ham_dataset.csv')\n>>> X_train, X_test, y_train, y_test = train_test_split(emails[['text']], emails['label'], random_state=98)\n>>> pipe = create_pipe_tfidf(X_train, y_train)\n>>> stats = pipeline_stats(pipe, X_test, y_test)\n>>> expected_keys = {'% spam correctly filtered', '% lost', '% incorrectly flagged'}\n>>> set(stats.index) == expected_keys\nTrue",
         "failure_message": "pipeline_stats does not return a Series with the correct index keys.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> emails = pd.read_csv('data/spam_ham_dataset.csv')\n>>> X_train, X_test, y_train, y_test = train_test_split(emails[['text']], emails['label'], random_state=98)\n>>> pipe = create_pipe_tfidf(X_train, y_train)\n>>> stats = pipeline_stats(pipe, X_test, y_test)\n>>> # 4 < stats.loc['% incorrectly flagged'] < 5\n>>> np.isclose(stats.loc['% incorrectly flagged'], 4.533333)\nTrue",
         "failure_message": "pipeline_stats returns an incorrect value for '% incorrectly flagged'.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> emails = pd.read_csv('data/spam_ham_dataset.csv')\n>>> X_train, X_test, y_train, y_test = train_test_split(emails[['text']], emails['label'], random_state=98)\n>>> pipe = create_pipe_tfidf(X_train, y_train)\n>>> stats = pipeline_stats(pipe, X_test, y_test)\n>>> np.isclose(stats.loc['% lost'], 1.825994)\nTrue",
         "failure_message": "pipeline_stats returns an incorrect value for '% lost'.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> emails = pd.read_csv('data/spam_ham_dataset.csv')\n>>> X_train, X_test, y_train, y_test = train_test_split(emails[['text']], emails['label'], random_state=98)\n>>> pipe = create_pipe_tfidf(X_train, y_train)\n>>> stats = pipeline_stats(pipe, X_test, y_test)\n>>> np.isclose(stats.loc['% spam correctly filtered'], 98.895028)\nTrue",
         "failure_message": "pipeline_stats returns an incorrect value for '% spam correctly filtered'.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> emails = pd.read_csv('data/spam_ham_dataset.csv')\n>>> X_train, X_test, y_train, y_test = train_test_split(emails[['text']], emails['label'], random_state=98)\n>>> pipe = create_pipe_tfidf(X_train, y_train)\n>>> subset_stats = pipeline_stats(pipe, X_test.iloc[5:100], y_test.iloc[5:100])\n>>> np.isclose(subset_stats.loc['% spam correctly filtered'], 93.75)\nTrue",
         "failure_message": "pipeline_stats returns an incorrect value for '% spam correctly filtered' on subset.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> emails = pd.read_csv('data/spam_ham_dataset.csv')\n>>> X_train, X_test, y_train, y_test = train_test_split(emails[['text']], emails['label'], random_state=98)\n>>> pipe = create_pipe_tfidf(X_train, y_train)\n>>> subset_stats = pipeline_stats(pipe, X_test.iloc[5:100], y_test.iloc[5:100])\n>>> np.isclose(subset_stats.loc['% incorrectly flagged'], 6.25)\nTrue",
         "failure_message": "pipeline_stats returns an incorrect value for '% incorrectly flagged' on subset.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> emails = pd.read_csv('data/spam_ham_dataset.csv')\n>>> X_train, X_test, y_train, y_test = train_test_split(emails[['text']], emails['label'], random_state=98)\n>>> pipe = create_pipe_tfidf(X_train, y_train)\n>>> subset_stats = pipeline_stats(pipe, X_test.iloc[5:100], y_test.iloc[5:100])\n>>> np.isclose(subset_stats.loc['% lost'], 1.2658227848101267)\nTrue",
         "failure_message": "pipeline_stats returns an incorrect value for '% lost' on subset.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> emails = pd.read_csv('data/spam_ham_dataset.csv')\n>>> X_train, X_test, y_train, y_test = train_test_split(emails[['text']], emails['label'], random_state=98)\n>>> pipe = create_pipe_tfidf(X_train, y_train)\n>>> subset_stats = pipeline_stats(pipe, X_test.iloc[500:900], y_test.iloc[500:900])\n>>> np.isclose(subset_stats.loc['% spam correctly filtered'], 99.18032786885246)\nTrue",
         "failure_message": "pipeline_stats returns an incorrect value for '% spam correctly filtered' on subset.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> emails = pd.read_csv('data/spam_ham_dataset.csv')\n>>> X_train, X_test, y_train, y_test = train_test_split(emails[['text']], emails['label'], random_state=98)\n>>> pipe = create_pipe_tfidf(X_train, y_train)\n>>> subset_stats = pipeline_stats(pipe, X_test.iloc[500:900], y_test.iloc[500:900])\n>>> np.isclose(subset_stats.loc['% incorrectly flagged'], 1.6260162601625994)\nTrue",
         "failure_message": "pipeline_stats returns an incorrect value for '% incorrectly flagged' on subset.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> emails = pd.read_csv('data/spam_ham_dataset.csv')\n>>> X_train, X_test, y_train, y_test = train_test_split(emails[['text']], emails['label'], random_state=98)\n>>> pipe = create_pipe_tfidf(X_train, y_train)\n>>> subset_stats = pipeline_stats(pipe, X_test.iloc[500:900], y_test.iloc[500:900])\n>>> np.isclose(subset_stats.loc['% lost'], 0.7194244604316548)\nTrue",
         "failure_message": "pipeline_stats returns an incorrect value for '% lost' on subset.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q01_04": {
     "name": "q01_04",
     "points": 4,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> emails = pd.read_csv('data/spam_ham_dataset.csv')\n>>> X_train, X_test, y_train, y_test = train_test_split(emails[['text']], emails['label'], random_state=98)\n>>> pipe = create_pipe_tfidf(X_train, y_train)\n>>> fig_pos = d_largest_coefficients(pipe, d=5, sign=1)\n>>> np.allclose(fig_pos.data[0]['x'], np.array([1.79596973, 1.8403086 , 1.90024643, 2.47989072, 2.69703333]))\nTrue",
         "failure_message": "d_largest_coefficients (positive) does not return the correct coefficient values.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> emails = pd.read_csv('data/spam_ham_dataset.csv')\n>>> X_train, X_test, y_train, y_test = train_test_split(emails[['text']], emails['label'], random_state=98)\n>>> pipe = create_pipe_tfidf(X_train, y_train)\n>>> fig_neg = d_largest_coefficients(pipe, d=5, sign=-1)\n>>> np.allclose(fig_neg.data[0]['x'], np.array([-3.16307832, -3.19036387, -3.22162337, -3.32774047, -4.44372644]))\nTrue",
         "failure_message": "d_largest_coefficients (negative) does not return the correct coefficient values.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> emails = pd.read_csv('data/spam_ham_dataset.csv')\n>>> X_train, X_test, y_train, y_test = train_test_split(emails[['text']], emails['label'], random_state=98)\n>>> pipe = create_pipe_tfidf(X_train, y_train)\n>>> fig_pos = d_largest_coefficients(pipe, d=7, sign=1)\n>>> np.allclose(fig_pos.data[0]['x'], np.array([1.73216615, 1.7878482 , 1.79596973, 1.8403086 , 1.90024643,\n...        2.47989072, 2.69703333]))\nTrue",
         "failure_message": "d_largest_coefficients (positive) does not return the correct coefficient values.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> emails = pd.read_csv('data/spam_ham_dataset.csv')\n>>> X_train, X_test, y_train, y_test = train_test_split(emails[['text']], emails['label'], random_state=98)\n>>> pipe = create_pipe_tfidf(X_train, y_train)\n>>> fig_neg = d_largest_coefficients(pipe, d=7, sign=-1)\n>>> np.allclose(fig_neg.data[0]['x'], np.array([-3.02666953, -3.11500532, -3.16307832, -3.19036387, -3.22162337,\n...        -3.32774047, -4.44372644]))\nTrue",
         "failure_message": "d_largest_coefficients (negative) does not return the correct coefficient values.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> emails = pd.read_csv('data/spam_ham_dataset.csv')\n>>> X_train, X_test, y_train, y_test = train_test_split(emails[['text']], emails['label'], random_state=98)\n>>> pipe = create_pipe_tfidf(X_train, y_train)\n>>> fig_pos = d_largest_coefficients(pipe, d=15, sign=1)\n>>> np.allclose(fig_pos.data[0]['x'], np.array([1.26533793, 1.28173567, 1.28525788, 1.29712869, 1.35690318,\n...        1.46382189, 1.46390168, 1.4809323 , 1.73216615, 1.7878482 ,\n...        1.79596973, 1.8403086 , 1.90024643, 2.47989072, 2.69703333]))\nTrue",
         "failure_message": "d_largest_coefficients (positive) does not return the correct coefficient values.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> emails = pd.read_csv('data/spam_ham_dataset.csv')\n>>> X_train, X_test, y_train, y_test = train_test_split(emails[['text']], emails['label'], random_state=98)\n>>> pipe = create_pipe_tfidf(X_train, y_train)\n>>> fig_neg = d_largest_coefficients(pipe, d=15, sign=-1)\n>>> np.allclose(fig_neg.data[0]['x'], np.array([-2.52960698, -2.53853856, -2.69569172, -2.71344745, -2.73790203,\n...        -2.75261927, -2.7664086 , -2.89051508, -3.02666953, -3.11500532,\n...        -3.16307832, -3.19036387, -3.22162337, -3.32774047, -4.44372644]))\nTrue",
         "failure_message": "d_largest_coefficients (negative) does not return the correct coefficient values.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> emails = pd.read_csv('data/spam_ham_dataset.csv')\n>>> X_train, X_test, y_train, y_test = train_test_split(emails[['text']], emails['label'], random_state=98)\n>>> pipe = create_pipe_tfidf(X_train, y_train)\n>>> fig_pos = d_largest_coefficients(pipe, d=1, sign=1)\n>>> np.allclose(fig_pos.data[0]['x'], np.array([2.69703333]))\nTrue",
         "failure_message": "d_largest_coefficients (positive) does not return the correct coefficient value.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> emails = pd.read_csv('data/spam_ham_dataset.csv')\n>>> X_train, X_test, y_train, y_test = train_test_split(emails[['text']], emails['label'], random_state=98)\n>>> pipe = create_pipe_tfidf(X_train, y_train)\n>>> fig_neg = d_largest_coefficients(pipe, d=1, sign=-1)\n>>> np.allclose(fig_neg.data[0]['x'], np.array([-4.44372644]))\nTrue",
         "failure_message": "d_largest_coefficients (negative) does not return the correct coefficient value.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q01_05": {
     "name": "q01_05",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> emails = pd.read_csv('data/spam_ham_dataset.csv')\n>>> X_train, X_test, y_train, y_test = train_test_split(emails[['text']], emails['label'], random_state=98)\n>>> pipe_l1_reg, non_zero_coefs = create_pipe_l1_reg(X_train, y_train)\n>>> pipe_l1_reg[:-1].transform(X_train).shape[1] == 43061\nTrue",
         "failure_message": "create_pipe_l1_reg(X_train, y_train) returns a pipeline whose TF-IDF step does not create 43061 features.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> from sklearn.linear_model import LogisticRegression\n>>> emails = pd.read_csv('data/spam_ham_dataset.csv')\n>>> X_train, X_test, y_train, y_test = train_test_split(emails[['text']], emails['label'], random_state=98)\n>>> pipe_l1_reg, non_zero_coefs = create_pipe_l1_reg(X_train, y_train)\n>>> (isinstance(pipe_l1_reg[-1], LogisticRegression) and pipe_l1_reg[-1].penalty == 'l1' and pipe_l1_reg[-1].C == 0.2 and pipe_l1_reg[-1].solver == 'liblinear' and pipe_l1_reg[-1].random_state == 98)\nTrue",
         "failure_message": "create_pipe_l1_reg(X_train, y_train) does not use the correct hyperparameters (penalty, C, solver, random_state).",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> emails = pd.read_csv('data/spam_ham_dataset.csv')\n>>> X_train, X_test, y_train, y_test = train_test_split(emails[['text']], emails['label'], random_state=98)\n>>> pipe_l1_reg, num_words = create_pipe_l1_reg(X_train, y_train)\n>>> num_words == 31\nTrue",
         "failure_message": "create_pipe_l1_reg(X_train, y_train) returns an incorrect number of non-zero coefficients.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> emails = pd.read_csv('data/spam_ham_dataset.csv')\n>>> X_train, X_test, y_train, y_test = train_test_split(emails[['text']], emails['label'], random_state=98)\n>>> pipe_l1_reg, num_words = create_pipe_l1_reg(X_train, y_train)\n>>> input_text = [{'text': 'hey eecs 398 students attached is where you are sitting for the exam'}]\n>>> sample_probs = pipe_l1_reg.predict_proba(pd.DataFrame(input_text))\n>>> np.allclose(sample_probs, np.array([[0.64731552, 0.35268448]]))\nTrue",
         "failure_message": "create_pipe_l1_reg(X_train, y_train) does not produce the correct predicted probabilities.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> emails = pd.read_csv('data/spam_ham_dataset.csv')\n>>> X_train, X_test, y_train, y_test = train_test_split(emails[['text']], emails['label'], random_state=98)\n>>> pipe_l1_reg, num_words = create_pipe_l1_reg(X_train, y_train)\n>>> input_text = [{'text': 'hi mom I love you'}]\n>>> sample_probs = pipe_l1_reg.predict_proba(pd.DataFrame(input_text))\n>>> np.allclose(sample_probs, np.array([[0.39792628, 0.60207372]]))\nTrue",
         "failure_message": "create_pipe_l1_reg(X_train, y_train) does not produce the correct predicted probabilities.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> emails = pd.read_csv('data/spam_ham_dataset.csv')\n>>> X_train, X_test, y_train, y_test = train_test_split(emails[['text']], emails['label'], random_state=98)\n>>> pipe_l1_reg, num_words = create_pipe_l1_reg(X_train, y_train)\n>>> input_text = [{'text': 'For those interested in becoming an IA for the Fall 2025 semester, the application deadline is now April 9th!'}]\n>>> sample_probs = pipe_l1_reg.predict_proba(pd.DataFrame(input_text))\n>>> np.allclose(sample_probs, np.array([[0.52524767, 0.47475233]]))\nTrue",
         "failure_message": "create_pipe_l1_reg(X_train, y_train) does not produce the correct predicted probabilities.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q02_01": {
     "name": "q02_01",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> X_train_wine, X_test_wine, y_train_wine, y_test_wine = split_wine_data()\n>>> wine_tree = create_wine_tree(X_train_wine, y_train_wine)\n>>> wine_tree.best_params_['max_depth'] == 4\nTrue",
         "failure_message": "create_wine_tree does not produce a Decision Tree with correct max depth.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> X_train_wine, X_test_wine, y_train_wine, y_test_wine = split_wine_data()\n>>> wine_tree = create_wine_tree(X_train_wine, y_train_wine)\n>>> pred = wine_tree.predict(pd.DataFrame([{'Alcohol': 13, 'Color Intensity': 5}]))[0]\n>>> pred == 'Grape 3'\nTrue",
         "failure_message": "create_wine_tree returns incorrect predictions, when trained on full training set.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> X_train_wine, X_test_wine, y_train_wine, y_test_wine = split_wine_data()\n>>> wine_tree = create_wine_tree(X_train_wine, y_train_wine)\n>>> wine_tree = create_wine_tree(X_train_wine, y_train_wine)\n>>> pred = wine_tree.predict(pd.DataFrame([{'Alcohol': 30, 'Color Intensity': 10}]))[0]\n>>> pred == 'Grape 1'\nTrue",
         "failure_message": "create_wine_tree returns incorrect predictions, when trained on full training set.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> X_train_wine, X_test_wine, y_train_wine, y_test_wine = split_wine_data()\n>>> wine_tree = create_wine_tree(X_train_wine, y_train_wine)\n>>> preds = wine_tree.predict(X_train_wine[['Alcohol', 'Color Intensity']])\n>>> np.array_equal(pd.Series(preds).value_counts().sort_index(), [52, 49, 32])\nTrue",
         "failure_message": "create_wine_tree returns an incorrect distribution of predictions, when trained on full training set.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> wine_tree = create_wine_tree(X_train_wine.iloc[30:100], y_train_wine.iloc[30:100])\n>>> preds = wine_tree.predict(X_train_wine[['Alcohol', 'Color Intensity']])\n>>> np.array_equal(pd.Series(preds).value_counts().sort_index(), [38, 38, 57])\nTrue",
         "failure_message": "create_wine_tree returns incorrect predictions, when trained on a subset of the training set.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q02_02": {
     "name": "q02_02",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> X_train_wine, X_test_wine, y_train_wine, y_test_wine = split_wine_data()\n>>> model_dict = train_wine_models(X_train_wine, y_train_wine)\n>>> isinstance(model_dict, dict) and set(model_dict.keys()) == {'Decision Tree (max_depth=4)', 'Random Forest (max_depth=4)', 'KNN (k=10)', 'Naive Bayes', 'Logistic Regression', 'Neural Network'}\nTrue",
         "failure_message": "train_wine_models must return a dictionary with 6 key-value pairs with the correct key names.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> X_train_wine, X_test_wine, y_train_wine, y_test_wine = split_wine_data()\n>>> model_dict = train_wine_models(X_train_wine, y_train_wine)\n>>> correct_type = str(type(model_dict['Decision Tree (max_depth=4)'])) == \"<class 'sklearn.tree._classes.DecisionTreeClassifier'>\"\n>>> correct_accuracy = np.isclose(model_dict['Decision Tree (max_depth=4)'].score(X_test_wine[['Alcohol', 'Color Intensity']], y_test_wine), 0.8)\n>>> correct_type and correct_accuracy\nTrue",
         "failure_message": "Decision tree was fit incorrectly, since it has the wrong test accuracy. Double-check how you fit the decision tree.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> X_train_wine, X_test_wine, y_train_wine, y_test_wine = split_wine_data()\n>>> model_dict = train_wine_models(X_train_wine, y_train_wine)\n>>> correct_type = str(type(model_dict['Random Forest (max_depth=4)'])) == \"<class 'sklearn.ensemble._forest.RandomForestClassifier'>\"\n>>> correct_accuracy = np.isclose(model_dict['Random Forest (max_depth=4)'].score(X_test_wine[['Alcohol', 'Color Intensity']], y_test_wine), 0.8666666666666667)\n>>> correct_type and correct_accuracy\nTrue",
         "failure_message": "Random forest was fit incorrectly, since it has the wrong test accuracy. Double-check how you fit the random forest.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> X_train_wine, X_test_wine, y_train_wine, y_test_wine = split_wine_data()\n>>> model_dict = train_wine_models(X_train_wine, y_train_wine)\n>>> correct_type = str(type(model_dict['KNN (k=10)'])) == \"<class 'sklearn.neighbors._classification.KNeighborsClassifier'>\"\n>>> correct_accuracy = np.isclose(model_dict['KNN (k=10)'].score(X_test_wine[['Alcohol', 'Color Intensity']], y_test_wine), 0.82222222222222)\n>>> correct_type and correct_accuracy\nTrue",
         "failure_message": "KNN with k=10 was fit incorrectly, since it has the wrong test accuracy. Double-check how you fit the KNN with k=10.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> X_train_wine, X_test_wine, y_train_wine, y_test_wine = split_wine_data()\n>>> model_dict = train_wine_models(X_train_wine, y_train_wine)\n>>> correct_type = str(type(model_dict['Naive Bayes'])) == \"<class 'sklearn.naive_bayes.GaussianNB'>\"\n>>> correct_accuracy = np.isclose(model_dict['Naive Bayes'].score(X_test_wine[['Alcohol', 'Color Intensity']], y_test_wine), 0.8888888888888888)\n>>> correct_type and correct_accuracy\nTrue",
         "failure_message": "Naive Bayes model was fit incorrectly, since it has the wrong test accuracy. Double-check how you fit the Naive Bayes model.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> X_train_wine, X_test_wine, y_train_wine, y_test_wine = split_wine_data()\n>>> model_dict = train_wine_models(X_train_wine, y_train_wine)\n>>> correct_type = str(type(model_dict['Logistic Regression'])) == \"<class 'sklearn.linear_model._logistic.LogisticRegression'>\"\n>>> correct_accuracy = np.isclose(model_dict['Logistic Regression'].score(X_test_wine[['Alcohol', 'Color Intensity']], y_test_wine), 0.8888888888888888)\n>>> correct_type and correct_accuracy\nTrue",
         "failure_message": "Logistic regression model was fit incorrectly, since it has the wrong test accuracy. Double-check how you fit the logistic regression model; remember to specify C=np.inf!",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> X_train_wine, X_test_wine, y_train_wine, y_test_wine = split_wine_data()\n>>> model_dict = train_wine_models(X_train_wine, y_train_wine)\n>>> correct_type = str(type(model_dict['Neural Network'])) == \"<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\"\n>>> correct_accuracy = np.isclose(model_dict['Neural Network'].score(X_test_wine[['Alcohol', 'Color Intensity']], y_test_wine), 0.7333333333333333)\n>>> correct_type and correct_accuracy\nTrue",
         "failure_message": "Neural network model was fit incorrectly, since it has the wrong test accuracy. Double-check how you fit the neural network model.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q02_03": {
     "name": "q02_03",
     "points": 4,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> X_train_wine, X_test_wine, y_train_wine, y_test_wine = split_wine_data()\n>>> standardized_model_dict = train_standardized_wine_models(X_train_wine, y_train_wine)\n>>> isinstance(model_dict, dict) and set(model_dict.keys()) == {'Decision Tree (max_depth=4)', 'Random Forest (max_depth=4)', 'KNN (k=10)', 'Naive Bayes', 'Logistic Regression', 'Neural Network'}\nTrue",
         "failure_message": "train_standardized_wine_models must return a dictionary with 6 key-value pairs with the correct key names.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> X_train_wine, X_test_wine, y_train_wine, y_test_wine = split_wine_data()\n>>> standardized_model_dict = train_standardized_wine_models(X_train_wine, y_train_wine)\n>>> all([str(type(standardized_model_dict[model])) == \"<class 'sklearn.pipeline.Pipeline'>\" for model in standardized_model_dict.keys()])\nTrue",
         "failure_message": "train_standardized_wine_models must return a dictionary of models in which all models are Pipelines.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> X_train_wine, X_test_wine, y_train_wine, y_test_wine = split_wine_data()\n>>> standardized_model_dict = train_standardized_wine_models(X_train_wine, y_train_wine)\n>>> np.isclose(standardized_model_dict['Decision Tree (max_depth=4)'].score(X_test_wine[['Alcohol', 'Color Intensity']], y_test_wine), 0.8)\nTrue",
         "failure_message": "Decision tree was fit incorrectly, since it has the wrong test accuracy. Double-check how you fit the decision tree.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> X_train_wine, X_test_wine, y_train_wine, y_test_wine = split_wine_data()\n>>> standardized_model_dict = train_standardized_wine_models(X_train_wine, y_train_wine)\n>>> np.isclose(standardized_model_dict['Random Forest (max_depth=4)'].score(X_test_wine[['Alcohol', 'Color Intensity']], y_test_wine), 0.8666666666666667)\nTrue",
         "failure_message": "Random forest was incorrectly, since it has the wrong test accuracy. Double-check how you fit the random forest.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> X_train_wine, X_test_wine, y_train_wine, y_test_wine = split_wine_data()\n>>> standardized_model_dict = train_standardized_wine_models(X_train_wine, y_train_wine)\n>>> np.isclose(standardized_model_dict['KNN (k=10)'].score(X_test_wine[['Alcohol', 'Color Intensity']], y_test_wine), 0.8666666666666667)\nTrue",
         "failure_message": "KNN with k=10 was fit incorrectly, since it has the wrong test accuracy. Double-check how you fit the KNN with k=10.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> X_train_wine, X_test_wine, y_train_wine, y_test_wine = split_wine_data()\n>>> standardized_model_dict = train_standardized_wine_models(X_train_wine, y_train_wine)\n>>> np.isclose(standardized_model_dict['Naive Bayes'].score(X_test_wine[['Alcohol', 'Color Intensity']], y_test_wine), 0.8888888888888888)\nTrue",
         "failure_message": "Naive Bayes model was fit incorrectly, since it has the wrong test accuracy. Double-check how you fit the Naive Bayes model.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> X_train_wine, X_test_wine, y_train_wine, y_test_wine = split_wine_data()\n>>> standardized_model_dict = train_standardized_wine_models(X_train_wine, y_train_wine)\n>>> np.isclose(standardized_model_dict['Logistic Regression'].score(X_test_wine[['Alcohol', 'Color Intensity']], y_test_wine), 0.8888888888888888)\nTrue",
         "failure_message": "Logistic regression model was fit incorrectly, since it has the wrong test accuracy. Double-check how you fit the logistic regression model; remember to specify C=np.inf!",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> X_train_wine, X_test_wine, y_train_wine, y_test_wine = split_wine_data()\n>>> standardized_model_dict = train_standardized_wine_models(X_train_wine, y_train_wine)\n>>> np.isclose(standardized_model_dict['Neural Network'].score(X_test_wine[['Alcohol', 'Color Intensity']], y_test_wine), 0.8888888888888888)\nTrue",
         "failure_message": "Neural network model was fit incorrectly, since it has the wrong test accuracy. Double-check how you fit the neural network model.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q02_04": {
     "name": "q02_04",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> X_train_wine, X_test_wine, y_train_wine, y_test_wine = split_wine_data()\n>>> best_model = create_best_wine_model(X_train_wine, y_train_wine)\n>>> 'sklearn' in str(type(best_model))\nTrue",
         "failure_message": "create_best_wine_model is some sklearn model.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> X_train_wine, X_test_wine, y_train_wine, y_test_wine = split_wine_data()\n>>> best_model = create_best_wine_model(X_train_wine, y_train_wine)\n>>> best_model.score(X_test_wine[['Alcohol', 'Color Intensity']], y_test_wine) >= 0.91\nTrue",
         "failure_message": "create_best_wine_model must have a test accuracy of at least 91%.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> X_train_wine, X_test_wine, y_train_wine, y_test_wine = split_wine_data()\n>>> best_model = create_best_wine_model(X_train_wine, y_train_wine)\n>>> best_model.score(X_test_wine[['Alcohol', 'Color Intensity']], y_test_wine) > 8 / 9\nTrue",
         "failure_message": "create_best_wine_model must have a test accuracy of better than 88.8888%, since the best model from 2.2 achieved that.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> X_train_wine, X_test_wine, y_train_wine, y_test_wine = split_wine_data()\n>>> best_model = create_best_wine_model(X_train_wine, y_train_wine)\n>>> best_model.score(X_test_wine[['Alcohol', 'Color Intensity']], y_test_wine) < 1\nTrue",
         "failure_message": "create_best_wine_model must not have somehow hardcoded the test set.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q03_01": {
     "name": "q03_01",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> xs_test = df['departure_hour']\n>>> ys_test = df['minutes'] \n>>> grad_test = tukey_gradient(np.array([100, -5]), xs_test, ys_test)\n>>> grad_test.shape[0] == 2\nTrue",
         "failure_message": "tukey_gradient returns a gradient with the incorrect shape.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> xs_test = df['departure_hour']\n>>> ys_test = df['minutes'] \n>>> grad_test = tukey_gradient(np.array([100, -5]), xs_test, ys_test)\n>>> expected_grad = np.array([-0.02389409, -0.20369193])\n>>> np.allclose(grad_test, expected_grad)\nTrue",
         "failure_message": "tukey_gradient returns an incorrect gradient.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> xs_test = df['departure_hour']\n>>> ys_test = df['minutes'] \n>>> grad_test = tukey_gradient(np.array([50, 50]), xs_test, ys_test)\n>>> expected_grad = np.array([0, 0])\n>>> np.allclose(grad_test, expected_grad)\nTrue",
         "failure_message": "tukey_gradient returns a nonzero gradient when all errors exceed the threshold.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> xs_test = df['departure_hour']\n>>> ys_test = df['minutes'] \n>>> grad_test = tukey_gradient(np.array([5, 5]), xs_test, ys_test)\n>>> expected_grad = np.array([-0.02286421, -0.19319173])\n>>> np.allclose(grad_test, expected_grad)\nTrue",
         "failure_message": "tukey_gradient returns a nonzero gradient when all errors exceed the threshold.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> xs_test = df['departure_hour'].iloc[:50]\n>>> ys_test = df['minutes'].iloc[:50]\n>>> grad_test = tukey_gradient(np.array([100, 0]), xs_test, ys_test)\n>>> expected_grad = np.array([0.02270738, 0.19825894])\n>>> np.allclose(grad_test, expected_grad)\nTrue",
         "failure_message": "tukey_gradient returns a nonzero gradient when all errors exceed the threshold.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> xs_test = np.array([1, 2, 3])\n>>> ys_test = np.array([200, 210, 220])  \n>>> grad_test = tukey_gradient(np.array([0, 0]), xs_test, ys_test)\n>>> expected_grad = np.array([0.0, 0.0])\n>>> np.allclose(grad_test, expected_grad)\nTrue",
         "failure_message": "tukey_gradient returns a nonzero gradient when all errors exceed the threshold.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> xs_test = np.array([1])\n>>> ys_test = np.array([140])\n>>> grad_test = tukey_gradient(np.array([100, 0]), xs_test, ys_test)\n>>> expected_grad = np.array([-0.0124416, -0.0124416])\n>>> np.allclose(grad_test, expected_grad)\nTrue",
         "failure_message": "tukey_gradient returns an incorrect gradient for a single data point.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> xs_test = np.array([1, 2])\n>>> ys_test = np.array([140, 50])\n>>> grad_test = tukey_gradient(np.array([100, 0]), xs_test, ys_test)\n>>> expected_grad = np.array([-0.0062208, -0.0062208])\n>>> np.allclose(grad_test, expected_grad)\nTrue",
         "failure_message": "tukey_gradient returns an incorrect gradient for a mixed dataset.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q03_02": {
     "name": "q03_02",
     "points": 4,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> path = run_gradient_descent_tukey(w_initial=np.array([5, 5]), alpha=0.01, xs=df['departure_hour'], ys=df['minutes'], verbose=False)\n>>> len(path) == 50000\nTrue",
         "failure_message": "run_gradient_descent_tukey does not handle non-convergent cases correctly.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> path = run_gradient_descent_tukey(w_initial=np.array([100, 0]), alpha=10, xs=df['departure_hour'], ys=df['minutes'], verbose=False)\n>>> len(path) == 7616\nTrue",
         "failure_message": "run_gradient_descent_tukey does not converge in the right number of steps.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> path = run_gradient_descent_tukey(w_initial=np.array([50, 50]), alpha=10, xs=df['departure_hour'], ys=df['minutes'], verbose=False)\n>>> len(path) == 1\nTrue",
         "failure_message": "run_gradient_descent_tukey does not converge in the right number of steps.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> path = run_gradient_descent_tukey(w_initial=np.array([5, 5]), alpha=10, xs=df['departure_hour'], ys=df['minutes'], verbose=False)\n>>> len(path) == 14765\nTrue",
         "failure_message": "run_gradient_descent_tukey does not converge in the right amount of steps.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> path = run_gradient_descent_tukey(w_initial=np.array([100, 0]), alpha=10, xs=df['departure_hour'], ys=df['minutes'], verbose=False)\n>>> np.allclose(path[-1], np.array([121.54137119,  -5.85454902]))\nTrue",
         "failure_message": "run_gradient_descent_tukey does not return the correct parameter values for w0 and w1.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> path = run_gradient_descent_tukey(w_initial=np.array([200, -10]), alpha=5, xs=df['departure_hour'], ys=df['minutes'], verbose=False)\n>>> np.allclose(path[-1], np.array([129.94993349,  -6.82222999]))\nTrue",
         "failure_message": "run_gradient_descent_tukey does not return the correct parameter values for w0 and w1.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> path = run_gradient_descent_tukey(w_initial=np.array([200, -10]), alpha=15, xs=df['departure_hour'], ys=df['minutes'], verbose=False)\n>>> np.allclose(path[-1], np.array([130.18091462,  -5.53174297]))\nTrue",
         "failure_message": "run_gradient_descent_tukey does not return the correct parameter values for w0 and w1.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
