{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49befadb",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"hw06.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc58b33",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" markdown=\"1\">\n",
    "\n",
    "#### Homework 6\n",
    "\n",
    "# GPTEECS and Loss Functions\n",
    "\n",
    "### EECS 398: Practical Data Science, Winter 2025\n",
    "\n",
    "#### Due Tuesday, March 11th at 11:59PM (due after Spring Break!)\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cf762d",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "Welcome to Homework 6! In the first part of the homework (Question 1), you will apply your knowledge of cosine similarity and TF-IDF to implement a supercharged ChatGPT-like bot. Throughout the rest of the homework, you will develop your understanding of the theoretical foundations of machine learning ‚Äì specifically, loss functions and simple linear regression ‚Äì which will enable us to build useful, practical models in the latter half of the semester.\n",
    "\n",
    "You are given 8 slip days throughout the semester to extend deadlines. See the [Syllabus](https://practicaldsc.org/syllabus) for more details. With the exception of using slip days, late work will not be accepted unless you have made special arrangements with your instructor.\n",
    "\n",
    "To access this notebook, you'll need to clone our [public GitHub repository](https://github.com/practicaldsc/wn25/). The [Environment Setup](https://practicaldsc.org/env-setup) page on the course website walks you through the necessary steps. Once you're done, you'll submit your completed notebook to Gradescope.\n",
    "\n",
    "<div class=\"alert alert-info\" markdown=\"1\">\n",
    "\n",
    "### No Hidden Tests; Late Deadline; Disclaimer\n",
    "\n",
    "Unlike other homeworks, Homework 6 <b>has no hidden tests</b>, because of its proximity to the Midterm Exam. This means the tests you see in your notebook are the exact same as the ones that will be used to grade your work on Gradescope. When you submit on Gradescope, you'll see your score shortly after you submit, once the autograder finishes running.\n",
    "<br><br>\n",
    "<b>Even though Homework 6 is due after the Midterm Exam, you should work on it before, since most of the homework is in scope for the exam!</b> In particular, we recommend working on Questions 2-5 before the exam, because they provide core practice with the constant model and simple linear regression, both of which will appear on the exam. \n",
    "- Question 6 involves linear algebra review, which will be important for the content we cover after the exam, but not relevant before (except for in how it relates to cosine similarity and dot products, which we covered in Lecture 10).\n",
    "- Question 1 is more \"applied\", and while cosine similarity, bag of words, and TF-IDF will appear on the exam, the best way to practice with those ideas is by working on relevant old exam problems at the <a href=\"https://study.practicaldsc.org\"><b>Study Site</b></a>.\n",
    "</div>\n",
    "\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "### Submission\n",
    "    \n",
    "This homework features a mix of autograded programming questions and manually-graded questions.\n",
    "  \n",
    "- Question 1 is **fully autograded**, and each part will say **[Autograded üíª]** in the title. For these questions, all you need to is write your code in this notebook, run the local `grader.check` tests, and submit to the **Homework 6 (Question 1; autograded problems)** assignment on Gradescope to have your code graded by the autograder.\n",
    "    \n",
    "- Questions 2-6 are **manually graded**, and say **[Written ‚úèÔ∏è]** in their titles. For this question, **do not write your answers in this notebook**! Instead, write **all** of your answers in a separate PDF. Submit this separate PDF to the **Homework 6 (Questions 2-6; written problems)** assignment on Gradescope, and **make sure to correctly select the pages associated with each question**! Make sure to show your work for all written questions, as answers without work shown may not receive full credit.\n",
    "\n",
    "    \n",
    "Your Homework 6 submission time will be the **later** of your two individual submissions. Please start early and submit often. You can submit as many times as you'd like to Gradescope, and we'll take your **most recent** submission. \n",
    "</div>\n",
    "</div>\n",
    "\n",
    "This homework is worth a total of **76 points**, 19 of which come from the autograder (Question 1), and **58 of which are manually graded by us (Questions 2-6)**. The number of points each question is worth is listed at the start of each question. **The 6 questions in the assignment are independent, so feel free to move around if you get stuck**. Tip: if you're using Jupyter Lab, you can see a Table of Contents for the notebook by going to View > Table of Contents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ab2496",
   "metadata": {},
   "source": [
    "To get started, run the cell below, plus the cell at the top of the notebook that imports and initializes `otter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0cc657",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import groq\n",
    "from IPython.display import Markdown\n",
    "\n",
    "import plotly\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.io as pio\n",
    "\n",
    "# Preferred styles\n",
    "pio.templates[\"pds\"] = go.layout.Template(\n",
    "    layout=dict(\n",
    "        margin=dict(l=30, r=30, t=30, b=30),\n",
    "        autosize=True,\n",
    "        width=600,\n",
    "        height=400,\n",
    "        xaxis=dict(showgrid=True),\n",
    "        yaxis=dict(showgrid=True),\n",
    "        title=dict(x=0.5, xanchor=\"center\"),\n",
    "    )\n",
    ")\n",
    "pio.templates.default = \"simple_white+pds\"\n",
    "pd.options.plotting.backend = 'plotly'\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d904617",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Question 1: GPTEECS ü§ñ\n",
    "\n",
    "---\n",
    "\n",
    "### Overview\n",
    "\n",
    "Large Language Models (LLM), like GPT-4 by OpenAI, Claude by Anthropic, Llama by Meta, or DeepSeek-R1, are statistical models that were trained on massive datasets for the purpose of generating useful new text. [ChatGPT](https://chat.openai.com) and other similar chat interfaces make calls to an LLM API under-the-hood, and show you the results in a text message-like format.\n",
    "\n",
    "Open ChatGPT or your favorite other LLM chat interface, and ask it:\n",
    "\n",
    "> What are some courses related to machine learning I can take at Michigan, other than EECS 445?\n",
    "\n",
    "Until very recently (when ChatGPT started being able to search the internet), ChatGPT would either tell you that it doesn't know what EECS 445 is, or make up an answer. Even if it did give you an answer, it's not necessarily clear whether it pulled the answer from a reliable source, or whether it's still true today (it may have found syllabi or course descriptions online several years ago, and could be hallucinating). \n",
    "\n",
    "### Retrieval-Augmented Generation (RAG)\n",
    "\n",
    "A solution to this issue is **Retrieval-Augmented Generation (RAG)**. **In this question, we will use RAG to implement GPTEECS, a chat interface designed to answer questions about courses at the University of Michigan (UM).** Here's the general idea behind RAG, and how we'll use it in this question:\n",
    "\n",
    "1. We want to implement a chat bot that can answer questions about something specific.<br><small>**Here**, we want our chat bot to answer questions classes at UM.</small>\n",
    "1. To do so, we download and store documents that contain the relevant context that we wish our LLM knew about.<br><small>**Here**, we'll download the course descriptions of various classes at UM. We've already done this for you.</small>\n",
    "1. Then, when the user asks a question ‚Äì called a **query** ‚Äì we determine which of our locally-stored documents (course descriptions) are most relevant in answering their question.<br><small>**Here**, when a user asks a question about UM classes, we'll determine the course description(s) that are most relevant.</small>\n",
    "1. Once we find the most relevant documents, we send the user's query, **along with** the most relevant documents, to our language model, allowing it to find the answer for us with the context it needs.\n",
    "\n",
    "<center><img src=\"imgs/retrieval-augmented-generation.png\" width=700><br>(<a href=\"https://towhee.io/tasks/detail/pipeline/retrieval-augmented-generation\">image source</a>)</center>\n",
    "\n",
    "RAG enables organizations to create customized chat interfaces that are better equipped to answer questions about the organization than an out-of-the-box language model. For instance, if you operated a store and wanted an AI-powered customer support chat, you may use RAG to create a chat bot that knows about your store's catalog, return policies, etc. ChatGPT even allows you to make custom GPTs [yourself](https://openai.com/index/introducing-gpts/) by uploading customized knowledge bases, and these (likely) use a process similar to RAG.\n",
    "\n",
    "### FAQs\n",
    "\n",
    "- **How do we determine which documents are most relevant to the user's query?** Here, we'll implement this using TF-IDF and cosine similarity, as we've seen in [Lecture 10](https://practicaldsc.org/resources/lectures/lec10/lec10-filled.html)! In practice, more sophisticated, state-of-the-art techniques for converting text to numbers are used (if you're curious, look into \"word embeddings\").\n",
    "- **Why not just send all of the documents to our language model, instead of finding the documents that are most relevant?** LLMs have a [context window](https://www.hopsworks.ai/dictionary/context-window-for-llms), which is a limit on the length of the input query they can take in. If your query is too long, an LLM may not be able to process it. (And, if it includes unnecessary information, it can be hard for the LLM to give you an accurate response.)\n",
    "\n",
    "### Your Task\n",
    "The file `data/courses.txt` contains course descriptions for every class offered at UM. Think of each description as its own document, even though all descriptions are technically just in one `.txt` file. All of these descriptions together comprise our **corpus**.\n",
    "\n",
    "Shortly, using the ideas from Lecture 10, you will develop a working implementation of the following function:\n",
    "\n",
    "```python\n",
    ">>> top_n_similar_documents('probability theory and randomness', 4, bow)\n",
    "['STATS 425', 'MATH 425', 'STATS 412', 'ECE 501']\n",
    "\n",
    "```\n",
    "\n",
    "And even cooler, you'll implement a function that can fully answer questions, like:\n",
    "\n",
    "```python\n",
    ">>> ask_gpteecs(\"What are some courses related to machine learning I can take at Michigan, other than EECS 445?\")\n",
    "```\n",
    "\n",
    "And get back answers like:\n",
    "\n",
    "> Here are 5 relevant courses to Machine Learning that you can take at the University of Michigan:\n",
    "> - ECE 559 Optimization Methods in Signal Processing and Machine Learning: This course covers optimization methods for signal and image processing and machine learning problems.\n",
    "> - EECS 553 Machine Learning (ECE): This course covers the fundamentals of supervised, unsupervised, and sequential learning, including linear and nonlinear regression, logistic regression, and neural networks.\n",
    "> - ASTRO 416 Data Science for Astrophysicists: Although targeted towards astrophysics, this course covers essential skills in machine learning, including unsupervised and supervised learning, regularization, and neural networks.\n",
    "> - EECS 492 Introduction to Artificial Intelligence: This course introduces the core concepts of AI, including search, logic, knowledge representation, reasoning, and decision making under uncertainty.\n",
    "> - EECS 481 Software Engineering: Although not exclusively focused on machine learning, this course deals with software engineering principles, including development of large, complex software systems, and covers software development techniques that are applicable to machine learning projects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee2430e",
   "metadata": {},
   "source": [
    "### Question 1.1 [Autograded üíª] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">1 Point</div>\n",
    "\n",
    "First, let's figure out how to call a Large Language Model directly from our notebook. Another term for \"calling\" an API is \"querying\" the API ‚Äì confusing, we know, since for us \"querying\" means \"selecting a subset of rows in a DataFrame\", but this is an industry-standard term.\n",
    "\n",
    "OpenAI does have a Python API, but it's relatively limited on the free plan. Instead, we'll use tools from [Groq](https://groq.com/). Groq is a hardware company designing processors for training LLMs efficiently, and allows for fast, free access to open-source LLM APIs. We'll use the [Groq API](https://console.groq.com/docs/quickstart) to query Meta (formerly, Facebook)'s Llama 3 model.\n",
    "\n",
    "Go [**here**](https://console.groq.com/docs/quickstart) and create a Groq API key. Then, complete the implementation of `query_llm`, a function that takes in a string (`query_string`) and returns the text response that results from passing `query_string` to Groq. The function has largely been implemented for you; most of what you need to do is create an API key and put it in the right place below.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "APIs will limit the number of queries you can make per minute, and the number of tokens (words) you send per minute. We call these limits \"rate limits\". Each LLM also has a maximum \"context window\" size, which is the length (in words) of the largest query you can make. If you run into rate limit or context window issues while working on this homework, try switching to a new model. You can find the list of models and their IDs [**here**](https://console.groq.com/docs/models).\n",
    "- We recommend starting with the `'llama-3.1-8b-instant'` as it offers very high usage limits, but you can test out different models if you'd like.\n",
    "- If you want, you can use a _reasoning_ model, like the brand-new `'deepseek-r1-distill-qwen-32b'` model. Reasoning models \"think\" before they say a final answer, sometimes improving the quality of the final response. But, our queries are relatively simple, and the reasoning steps make the responses much longer, so we've chosen to _not_ use a reasoning model by default (`'llama-3.1-8b-instant'` is _not_ a reasoning model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859644ae",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def query_llm(query_string):\n",
    "    client = groq.Groq(\n",
    "        api_key= ...\n",
    "    )\n",
    "    \n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": query_string\n",
    "            }\n",
    "        ],\n",
    "        model=\"llama-3.1-8b-instant\",\n",
    "        # temperature=0 # Try uncommenting this and running the call to query_llm below many times. What do you notice? Recomment it out afterwards.\n",
    "    )\n",
    "\n",
    "    return chat_completion.choices[0].message.content\n",
    "\n",
    "# Feel free to change the input below to test out your implementation of query_llm.\n",
    "# The Markdown function behaves like the print function,\n",
    "# but renders text formatting (e.g. bolding, bullet points) when the output from Deepseek\n",
    "# contains these elements.\n",
    "Markdown(query_llm('Tell me a joke about data science'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88af7d42",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q01_01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ced378",
   "metadata": {},
   "source": [
    "Now, we can call `query_llm`! Run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6037e1f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Markdown(query_llm('''\n",
    "What are some courses related to machine learning I can take at Michigan, other than EECS 445? \n",
    "Keep it concise: just one paragraph.'''))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dab32fd",
   "metadata": {},
   "source": [
    "To experiment:\n",
    "- Run the cell many times. You'll notice that the response is very different every time; most of the course numbers it tells you about are made up. Google them!\n",
    "- Uncomment the line that says `temperature=0` in your definition of `query_llm`, and then run the above cell many times again. What do you notice now? (To see what argument is doing, go to the [documentation](https://console.groq.com/docs/api-reference#chat-create) and search for \"temperature\".) Recomment out the line before proceeding.\n",
    "- If you remove \"Keep it concise: just one paragraph.\", what do you notice?\n",
    "\n",
    "Now we have a way of passing queries to a LLM and getting back results. Right now, it's not knowledgeable enough to answer questions about specific UM classes. Soon, we'll change that.\n",
    "\n",
    "We'll get back to using `query_llm` in the final part of this question. For now, we need to switch our attention to implementing RAG ‚Äì that is, being able to find the course descriptions that are most related to our input query. Once we implement it, when we pass our (new) function the input `'What are some courses related to machine learning I can take at Michigan, other than EECS 445? Keep it concise: just one paragraph.'`, it'll provide accurate, up-to-date information about real courses, because we'll send real course descriptions to the LLM along with the original input. **Keep this goal in mind. The next few parts may seem unrelated, but they all come together at the end!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cac81b",
   "metadata": {},
   "source": [
    "### Question 1.2 [Autograded üíª] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">1 Point</div>\n",
    "\n",
    "A **token** is an alphanumeric string. In Lecture 10, we referred to tokens as \"terms\". Before computing any numbers, we need to find the terms in each course description, i.e. we need to **tokenize** each course description.\n",
    "\n",
    "Complete the implementation of the function `tokenize`, which takes in a string (`string`) of text and returns a list containing all of the tokens in `string`. Convert all characters to lowercase before extracting tokens.\n",
    "\n",
    "Example behavior is given below.\n",
    "\n",
    "```python\n",
    ">>> tokenize(\"EECS 398 Practical Data Science's about data management and applied machine learning.\")\n",
    "['eecs',\n",
    " '398',\n",
    " 'practical',\n",
    " 'data',\n",
    " 'science',\n",
    " 's',\n",
    " 'about',\n",
    " 'data',\n",
    " 'management',\n",
    " 'and',\n",
    " 'applied',\n",
    " 'machine',\n",
    " 'learning']\n",
    ">>> tokenize('This course is an introduction to the modern. qualitative. theory... of ordinary differential equations')\n",
    "['this',\n",
    " 'course',\n",
    " 'is',\n",
    " 'an',\n",
    " 'introduction',\n",
    " 'to',\n",
    " 'the',\n",
    " 'modern',\n",
    " 'qualitative',\n",
    " 'theory',\n",
    " 'of',\n",
    " 'ordinary',\n",
    " 'differential',\n",
    " 'equations']\n",
    "```\n",
    "\n",
    "Note that this part is only worth 1 point, so it shouldn't take very long!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0670f5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize(string):\n",
    "    ...\n",
    "\n",
    "# Feel free to change the input below to test out your implementation of tokenize.\n",
    "tokenize(\"EECS 398 Practical Data Science's about data management and applied machine learning.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb51b0a4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q01_02\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157c8b13",
   "metadata": {},
   "source": [
    "Before we move onto Question 1.3, it's worth mentioning that in practice, we'd put a bit more care into tokenizing our documents. For one, we might **lemmatize** our tokens, which would allow us to group words like `'eating'`, `'ate'`, and `'eatery'` all to `'eat'`. We've omitted such steps here for simplicity.\n",
    "\n",
    "Where do the course descriptions come from? They're all already stored in `courses.txt`, which we've scraped for you. Run the cell below to extract course information out of `courses.txt` and store it in the DataFrame `courses_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaede6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell, and don't change it!\n",
    "def extract_course_data(path):\n",
    "    # path = 'data/courses.txt'\n",
    "    with open(path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "    \n",
    "    course_sections = content.split(\"# COURSE\")[1:]  # Ignore first empty split.\n",
    "    \n",
    "    course_codes = []\n",
    "    course_titles = []\n",
    "    descriptions = []\n",
    "    for section in course_sections:\n",
    "        lines = section.strip().split(\"\\n\")\n",
    "        course_code = lines[0].split('-')[0].strip()\n",
    "        course_title = lines[0].split('-')[1].strip()\n",
    "        description = \" \".join(lines[1:]) \n",
    "        # Some courses have an empty description, so just fill it with placeholder to take care of possible NaNs later on.\n",
    "        if not description:\n",
    "            description = 'No course description'\n",
    "            \n",
    "        description = course_code + ' ' + course_title + ' ' + description\n",
    "        course_codes.append(course_code)\n",
    "        descriptions.append(description)\n",
    "    \n",
    "    courses = pd.DataFrame({\n",
    "        'Course' : course_codes,\n",
    "        'Description' : descriptions\n",
    "    })\n",
    "    \n",
    "    courses = courses.set_index('Course')\n",
    "    return courses\n",
    "\n",
    "courses_df = extract_course_data('data/courses.txt')\n",
    "courses_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35adbafc",
   "metadata": {},
   "source": [
    "Throughout the rest of this homework, we'll need `courses_df` to be defined as it is above. In the next part, we'll compute the frequencies of every token in every course description. **For the rest of this question, by \"course description\", we're referring to a value from the `'Description'` column of `courses_df`, which technically also includes the course number and title.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79909f8",
   "metadata": {},
   "source": [
    "### Question 1.3 [Autograded üíª] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">4 Points</div>\n",
    "\n",
    "Complete the implementation of the function `courses_to_bow`, which takes in the DataFrame `courses_df` and returns the corresponding **bag of words matrix** as a DataFrame, with:\n",
    "- One row per course, indexed by the course code, just like in `courses_df`.\n",
    "- One column per unique word (token) among all course descriptions (i.e. across the entire corpus). The order of the columns in the returned DataFrame does not matter. \n",
    "- Values corresponding to the number of occurrences of each word in each course description.\n",
    "\n",
    "Example behavior is given below.\n",
    "\n",
    "```python\n",
    ">>> out = courses_to_bow(courses_df)\n",
    ">>> out.shape\n",
    "(1638, 10865) # Same number of rows as courses_df\n",
    ">>> out.loc['EECS 280', 'data']\n",
    "4\n",
    "```\n",
    "\n",
    "Some guidance:\n",
    "- You must implement all of the steps by hand, i.e. no using `sklearn`'s `CountVectorizer`.\n",
    "- Since we already have a function for tokenizing each description, it's not necessary to use regular expressions to count the number of occurrences of particular words in each document. Look into the list `count` method, which you can use in conjunction with a `for`-loop or the Series `apply` method. Our solution follows the work in Lecture 10 closely. That said, feel free to use a `for`-loop if needed (we did).\n",
    "- Our solution takes ~10-20 seconds to run; make sure yours is similarly quick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8f50c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def courses_to_bow(courses_df):\n",
    "    # Make sure your solution does not actually modify courses_df!\n",
    "    ...\n",
    "\n",
    "# Uncomment the two lines below once you've implemented courses_to_bow.\n",
    "# The autograder tests will not work unless you've run these two lines.\n",
    "# bow = courses_to_bow(courses_df)\n",
    "# bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b0348f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q01_03\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45066769",
   "metadata": {},
   "source": [
    "**Make sure that throughout the rest of your notebook, `bow` is defined exactly as below!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841f8b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell.\n",
    "bow = courses_to_bow(courses_df)\n",
    "bow.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34e2dd0",
   "metadata": {
    "id": "69ae9112"
   },
   "source": [
    "### Question 1.4 [Autograded üíª] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">3 Points</div>\n",
    "\n",
    "Complete the implementation of the function `bow_to_tfidf`, which takes in a bag of words matrix (`bow`) returned by `courses_to_bow`. `bow_to_tfidf` should return a DataFrame with the same index and column names as `bow`, in the same order, but with all values converted to TF-IDFs ‚Äì that is, the outputted DataFrame should contain the TF-IDF of every word in every course description.\n",
    "\n",
    "Example behavior is given below.\n",
    "\n",
    "```python\n",
    "# Here, we're referring to the globally-defined bow.\n",
    ">>> out = bow_to_tfidf(bow)\n",
    ">>> out.shape == bow.shape\n",
    "True\n",
    ">>> out.loc['EECS 280', 'data']\n",
    "0.19708242779519058\n",
    "```\n",
    "\n",
    "Some guidance:\n",
    "- Follow our logic from Lecture 10 to convert `bow` to a TF-IDF matrix. Your implementation here should be relatively short (< 10 lines).\n",
    "- While not strictly required (in that we won't test it), we recommend you implement `compute_idfs`, which takes in a DataFrame like `bow` and returns a **Series** containing the inverse document frequency (IDF) of each word in `bow`. Not only will this help compartmentalize your work for this question, but it'll make your life much easier in Question 1.5, when you'll again need to use the IDFs of every word in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f83b480",
   "metadata": {
    "id": "78cb787f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_idfs(bow):\n",
    "    # Not required, but suggested!\n",
    "    ...\n",
    "\n",
    "def bow_to_tfidf(bow):\n",
    "    ...\n",
    "\n",
    "bow_to_tfidf(bow).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e719857",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q01_04\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c481b4",
   "metadata": {},
   "source": [
    "Before we move forward, it's worth stopping and looking at what we've already accomplished. Run the cell below to see the 5 words with the highest TF-IDFs in each course description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7532675d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def five_largest(row):\n",
    "    return ', '.join(row.index[row.argsort()][-5:])\n",
    "\n",
    "bow_to_tfidf(bow).apply(five_largest, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea37c48",
   "metadata": {},
   "source": [
    "Compare that to the 5 words with the highest frequences in each course description:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574f41c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow.apply(five_largest, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c266fe8",
   "metadata": {},
   "source": [
    "Hopefully, the value of TF-IDF is clear, but it's also clear that TF-IDF isn't perfect in summarizing documents. But, as we'll soon see, it'll serve our purposes well!\n",
    "\n",
    "Before you move to Question 1.5, there's one piece of syntax that you'll find useful: the Series `reindex` method. Here's an example of how it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be18873a",
   "metadata": {},
   "outputs": [],
   "source": [
    "things = pd.Series({'a': 2, 'b': 5, 'c': 1})\n",
    "things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13480b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stuff = pd.Series({'a': 'hello', 'b': 'hi', 'x': 9})\n",
    "stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287987c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "things.reindex(stuff.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f763e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "things.reindex(stuff.index).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf4b562",
   "metadata": {
    "id": "37808b3c"
   },
   "source": [
    "### Question 1.5 [Autograded üíª] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">3 Points</div>\n",
    "\n",
    "Complete the implementation of the function `new_query_to_tfidf`, which takes in a string (`query_string`) and a bag of words matrix (`bow`) and returns a Series such that:\n",
    "- The index contains the same labels as `bow`'s columns (meaning that if `bow` has 10865 columns, the outputted Series should have 10865 elements).\n",
    "- The values contain the TF-IDF of each word, using `query_string` to compute TFs and **the entire corpus of course descriptions (not including the new query)** to compute IDFs.\n",
    "\n",
    "Example behavior is given below.\n",
    "\n",
    "```python\n",
    ">>> out = new_query_to_tfidf('yooo I am very very very interested in biochemistry and cellular biology courses', bow)\n",
    ">>> out.shape\n",
    "(10865,)\n",
    "\n",
    "# Most of the values in out are 0, since\n",
    "# \"yooo I am very very very interested in biochemistry and cellular biology courses\"\n",
    "# doesn't contain most of the 10865 words in bow.\n",
    "# Since 'yooo' is not in bow.columns, it doesn't appear in the index of out, either.\n",
    "# The order of the returned Series does not matter; your Series may be in a different order.\n",
    "```\n",
    "```\n",
    ">>> out[out > 0]\n",
    "cellular        0.346989\n",
    "i               0.220664\n",
    "biochemistry    0.361014\n",
    "in              0.020182\n",
    "courses         0.248219\n",
    "and             0.007285\n",
    "interested      0.291563\n",
    "very            0.930908\n",
    "biology         0.274815\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "To be clear, the TF-IDF of a word $t$ in a new query string $q$ is:\n",
    "\n",
    "$$\\text{tfidf}(t, q) = \\underbrace{\\frac{\\text{# of occurrences of $t$ in $q$}}{\\text{total # of tokens in $q$}}}_{\\text{computed using } q \\: (\\texttt{query_string})} \\cdot \\underbrace{\\log \\left(\\frac{\\text{total # of course descriptions}}{\\text{# of course descriptions in which $t$ appears}} \\right)}_{\\text{computed solely using bow}}$$\n",
    "\n",
    "Note that this means that the IDFs of each word have nothing to do with the `query_string` that is passed in. This is precisely why we suggested you implement `compute_idfs(bow)` in the previous part ‚Äì because it would help your implementation of `bow_to_tfidf`, and also help your implementation of `new_query_to_tfidf`.\n",
    "\n",
    "Some additional guidance:\n",
    "- This function should only take a few lines to implement, but requires combining several steps, going all the way back to Question 1.2. Think about how the `reindex` method might be useful.\n",
    "- In the function signature below, you'll see `new_query_to_tfidf(query_string, bow=bow)`. `bow=bow` sets the default value of the `bow` argument to the globally-defined value of `bow`, meaning if we only pass one argument (`query_string`) to `new_query_to_tfidf`, it will automatically use the global `bow`. It's important for our function to be able to take in bag of words matrices other than our globally-defined `bow`, in case we want to use it on a different corpus of documents. But, most of the time we will call it on the global `bow`, so this is done for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dd22bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def new_query_to_tfidf(query_string, bow=bow):\n",
    "    ...\n",
    "\n",
    "# Feel free to change the input below to test out your implementation of new_query_to_tfidf.\n",
    "# Remember that the order of the returned Series does not matter.\n",
    "out = new_query_to_tfidf('yooo I am very very very interested in biochemistry and cellular biology courses')\n",
    "out[out > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3ad8b6",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q01_05\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58005822",
   "metadata": {},
   "source": [
    "Let's take stock of what we have so far.\n",
    "- We have the TF-IDFs of every word in every document in our corpus. This means that we have a **vector representation** of each course description.\n",
    "- We have a function that can take any query string and turn it into a **vector** of TF-IDF scores, as well.\n",
    "\n",
    "Now, we can use techniques from Lecture 10 ‚Äì specifically, cosine similarity ‚Äì to find the course descriptions that are most similar (and, hence, most relevant) to our query string!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f21e7f9",
   "metadata": {},
   "source": [
    "### Question 1.6 [Autograded üíª] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">3 Points</div>\n",
    "\n",
    "Complete the implementation of the function `top_n_similar_documents`, which takes in a string (`query_string`), a positive integer `n`, and a bag of words matrix (`bow`) and returns a list containing the course codes of the `n` most similar courses to `query_string`, based on course descriptions.\n",
    "\n",
    "Use cosine similarity to measure the similarity between two vectors; you can implement cosine similarity however you'd like. Remember that course codes are stored in the index of `bow`. The documents in the returned list should be sorted in **decreasing order of similarity**.\n",
    "\n",
    "Example behavior is given below.\n",
    "\n",
    "```python\n",
    ">>> top_n_similar_documents('yooo I am very interested in biochemistry and cellular biology courses', 3)\n",
    "['CHEM 351', 'BIOLOGY 172', 'CHEM 218']\n",
    "\n",
    ">>> top_n_similar_documents(\"What are some courses related to machine learning I can take at Michigan, other than EECS 445?\", 5)\n",
    "['EECS 445', 'ALA 171', 'EECS 492', 'MECHENG 499', 'ECE 559']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b042d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def top_n_similar_documents(query_string, n, bow=bow):\n",
    "    ...\n",
    "\n",
    "# Feel free to change the inputs below to test out your implementation of top_n_similar_documents.\n",
    "top_n_similar_documents('yooo I am very interested in biochemistry and cellular biology courses', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c02071",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q01_06\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78e95b5",
   "metadata": {},
   "source": [
    "Awesome! You've implemented the retrieval step in RAG. That is, given a query, you're able to automatically find the most relevant documents in our \"knowledge database\" for answering that query. Note that this process isn't flawless, as we see below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0a1d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n_similar_documents(\"What are some courses related to machine learning I can take at Michigan, other than EECS 445?\", \n",
    "                        n=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70c9296",
   "metadata": {},
   "source": [
    "<b><span style=\"color:red\">Stop</span></b> and think about why courses that are truly related to EECS 445, like STATS 415, don't appear in the list of 20 \"related\" courses above, and think about what impacts this will have on our results in the next step.\n",
    "\n",
    "Once you've done that, it's time for that final step: passing a `query_string`, along with the contents of the most relevant documents, to a Large Language Model (which we already learned how to access, using `query_llm`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15846690",
   "metadata": {},
   "source": [
    "### Question 1.7 [Autograded üíª] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">4 Points</div>\n",
    "\n",
    "Complete the implementation of the function `ask_gpteecs`, which takes in a string (`query_string`) containing a question about University of Michigan courses, a positive integer `n`, and a bag of words matrix `bow`. `ask_gpteecs` should return a **string** containing the result of:\n",
    "\n",
    "- querying a Large Language Model using the function `query_llm` from Question 1.1,\n",
    "- where the query contains **both** the contents of `query_string` and\n",
    "- the **top `n`** most similar course descriptions (`n=20` by default),\n",
    "- stitched together in a way that you deem appropriate.\n",
    "\n",
    "Here's what we mean by \"in a way that you deem appropriate.\" Suppose our query is `'yooo I am very interested in biochemistry and cellular biology courses'`, and suppose `n=3`.\n",
    "- The top 3 most similar courses to this query are `'CHEM 351'`, `'BIOLOGY 172'`, and `'CHEM 218'`.\n",
    "- If we just ask a LLM, `'yooo I am very interested in biochemistry and cellular biology courses'`, it won't know anything about any of these three courses. If we ask it, `'yooo I am very interested in biochemistry and cellular biology courses, tell me about them: CHEM 351, BIOLOGY 172, CHEM 218'`, it still won't know anything about those courses.\n",
    "- Instead, once we identify which 3 courses are most relevant, we need to create a new `query_string` that looks something like:\n",
    "\n",
    "```python\n",
    "'''\n",
    "Hi! I'm looking to answer this query that a student sent me, regarding courses at the University of Michigan:\n",
    "\n",
    "yooo I am very interested in biochemistry and cellular biology courses\n",
    "\n",
    "Here are some potentially relevant courses from my knowledge base; they might not all be relevant, so double-check.\n",
    "\n",
    "CHEM 351 Fundamentals of Biochemistry This course is designed to serve as an introduction to biochemistry for students intending to pursue the BS major in biochemistry and for others who are interested in gaining an overview of the fundamental chemistry underlying cellular functions. The material includes an introduction to the structures of biological macromolecules and an overview of the fundamental cellular processes associated with metabolism, biosynthesis, and replication. It is taught from a chemical perspective with and emphasis on understanding biochemical phenomena through chemical structure and mechanism.\n",
    "\n",
    "BIOLOGY 172 Introductory Biology BIOLOGY 172 is a one-term course in molecular, cellular, and developmental biology that, together with BIOLOGY 171 and 173, collectively forms the introductory biology course sequence.\n",
    "\n",
    "CHEM 218 Independent Study in Biochemistry This course provides an introduction to independent biochemistry research under the direction of a faculty member whose project is in the biochemistry area.  The Chemistry Department encourages students to get involved with undergraduate research as early as possible.\n",
    "'''\n",
    "```\n",
    "\n",
    "- Remember, course descriptions are stored in their original form in `courses_df`.\n",
    "- You can structure your final query string however you'd like, and you're encouraged to experiment with different phrasings to see if they influence your results; you can start by copying the example format above, but then try and make it your own. This is called **prompt engineering**.\n",
    "- You'll need to figure out a way of programmatically adding the course information to your prompt string. By default, we've set `n=20`, in case the most similar descriptions aren't actually relevant and the most relevant descriptions have lower similarities. But when calling `ask_gpteecs`, we could set `n` to something else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b50a21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ask_gpteecs(query_string, n=20, bow=bow):\n",
    "    ...\n",
    "\n",
    "# Feel free to change the inputs below to test out your implementation of ask_gpteecs.\n",
    "# The Markdown function behaves like the print function,\n",
    "# but renders text formatting (e.g. bolding, bullet points) when the output from the LLM contains these elements.\n",
    "Markdown(ask_gpteecs('yooo I am very interested in biochemistry and cellular biology courses'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7147bca1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q01_07\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d928676",
   "metadata": {},
   "source": [
    "**Great work!** You've now implemented Retrieval-Augmented Generation, and have your very own ChatGPT-like interface that knows about University of Michigan courses.\n",
    "\n",
    "Let's wrap up by asking GPTEECS the question we posed at the start of this exploration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2beb02cb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Markdown(ask_gpteecs(\"What are some courses related to machine learning I can take at Michigan, other than EECS 445?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f335441",
   "metadata": {},
   "source": [
    "Feel free to keep toying with `query_llm` (see the [Groq documentation here](https://console.groq.com/docs/quickstart) to see what you can customize) and `ask_gpteecs` to try and improve the performance of your implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176052f9",
   "metadata": {},
   "source": [
    "## Question 2: Relative Squared Loss üßë‚Äçüßë‚Äçüßí‚Äçüßí\n",
    "\n",
    "---\n",
    "\n",
    "In [Lecture 11](https://practicaldsc.org/resources/lectures/lec11/lec11-filled.pdf), we introduced the \"modeling recipe\" for making predictions:\n",
    "\n",
    "1. Choose a model.\n",
    "1. Choose a loss function.\n",
    "1. Minimize average loss to find optimal model parameters.\n",
    "\n",
    "The first instance of this recipe saw us choose:\n",
    "1. The constant model, $H(x_i) = h$.\n",
    "1. The squared loss function: $L_\\text{sq}(y_i, h) = (y_i - h)^2$.\n",
    "1. The average squared loss across our entire dataset, then, was:\n",
    "$$R_\\text{sq}(h) = \\frac{1}{n} \\sum_{i = 1}^n (y_i - h)^2$$\n",
    "which, using calculus, we showed is minimized when: $$h^* = \\text{Mean}(y_1, y_2, ..., y_n)$$\n",
    "This means that using the squared loss function, the **best** constant prediction is $h^* = \\text{Mean}(y_1, y_2, ..., y_n)$.\n",
    "\n",
    "In this question, you will find the best constant prediction when using a different loss function. In particular, here, we'll explore the **relative squared loss** function, $L_{\\text{rsq}}(y_i, h)$:\n",
    "\n",
    "$$L_{\\text{rsq}}(y_i, h) = \\frac{(y_i - h)^2}{y_i}$$\n",
    "\n",
    "Throughout this question, assume that each of $y_1, y_2, ..., y_n$ is positive.\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "Before attempting this question, you may want to watch [**this video üé•**](https://youtu.be/NSIEP74ifyg), which walks through most of the proof of the above, in addition to reviewing Lecture 11's [**filled slides**](https://practicaldsc.org/resources/lectures/lec11/lec11-filled.pdf).\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1bf700",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 2.1 [Written ‚úèÔ∏è] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">2 Points</div>\n",
    "\n",
    "Determine $\\frac{d}{d h} L_{\\text{rsq}}(h)$, the derivative of the relative squared loss function with respect to $h$.\n",
    "\n",
    "(Technically, this is a **partial** derivative, since there are other variables in the definition of $L_\\text{rsq}(h)$, but in our setting, $h$ is the only _unknown_.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef1993a",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 2.2 [Written ‚úèÔ∏è]  <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">4 Points</div>\n",
    "\n",
    "What value of $h$ minimizes average loss when using the relative squared loss function ‚Äì that is, what is $h^*$? Your answer should only be in terms of the variables $n, y_1, y_2, ..., y_n$, and any constants."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be1b54a",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 2.3 [Written ‚úèÔ∏è] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">3 Points</div>\n",
    "\n",
    "Let $C(y_1, y_2, ..., y_n)$ be your minimizer $h^*$ from Question 2.2. That is, for a particular dataset $y_1, y_2, ..., y_n$, $C(y_1, y_2, ..., y_n)$ is the value of $h$ that minimizes empirical risk for relative squared loss on that dataset.\n",
    "\n",
    "What is the value of $\\displaystyle\\lim_{y_4 \\rightarrow \\infty} C(1, 3, 5, y_4)$ in terms of $C(1, 3, 5)$? Your answer should involve the function $C$ and/or one or more constants.\n",
    "\n",
    "Some guidance: To notice the pattern, evaluate $C(1, 3, 5, 100)$, $C(1, 3, 5, 10000)$, and $C(1, 3, 5, 1000000)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68836050",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 2.4 [Written ‚úèÔ∏è] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">2 Points</div>\n",
    "\n",
    "What is the value of $\\displaystyle\\lim_{y_4 \\rightarrow 0} C(1, 3, 5, y_4)$? Again, your answer should involve the function $C$ and/or one or more constants."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8319b842",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 2.5 [Written ‚úèÔ∏è] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">2 Points</div>\n",
    "\n",
    "Based on the results of Questions 2.3 and 2.4, when is the prediction $C(y_1, y_2, ..., y_n)$ robust to outliers? When is it not robust to outliers?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcc00c4",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## Question 3: Bye, Calculus üëã\n",
    "\n",
    "---\n",
    "\n",
    "As we discussed in the previous question, in Lecture 11, we found that $h^* = \\text{Mean}(y_1, y_2, ..., y_n)$ is the constant prediction that minimizes mean squared error:\n",
    "\n",
    "$$R_\\text{sq}(h) = \\frac{1}{n} \\sum_{i = 1}^n (y_i-h)^2$$\n",
    "\n",
    "To arrive at this result, we used calculus: we took the derivative of $R_\\text{sq}(h)$ with respect to $h$, set it equal to 0, and solved for the resulting value of $h$, which we called $h^*$.\n",
    "\n",
    "In this question, we will minimize $R_\\text{sq}(h)$ in a way that **doesn't** use calculus. The general idea is this: if $f(x) = (x - c)^2 + k$, then we know that $f$ is a quadratic function that opens upwards with a vertex at $(c, k)$, meaning that $x = c$ minimizes $f$. As we saw in class (see [Lecture 11, Slide 29](https://practicaldsc.org/resources/lectures/lec11/lec11-filled.pdf#page=29)), $R_\\text{sq}(h)$ is a quadratic function of $h$!\n",
    "\n",
    "Throughout this problem, let $y_1, y_2, ..., y_n$ be an arbitrary dataset, and let $\\bar{y} = \\frac{1}{n} \\sum_{i = 1}^n y_i$ be the mean of the $y$'s.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425fbcf5",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 3.1 [Written ‚úèÔ∏è]  <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">2 Points</div>\n",
    "\n",
    "What is the value of $\\sum_{i = 1}^n (y_i - \\bar{y})$? Show your work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571286c0",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 3.2 [Written ‚úèÔ∏è]  <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">2 Points</div>\n",
    "\n",
    "Show that:\n",
    "\n",
    "$$R_\\text{sq}(h) = \\frac{1}{n} \\sum_{i = 1}^n \\left( (y_i - \\bar{y})^2 + 2(y_i - \\bar{y})(\\bar{y} - h) + (\\bar{y} - h)^2 \\right)$$\n",
    "\n",
    "Some guidance:\n",
    "- To proceed, start by rewriting $y_i - h$ in the definition of $R_\\text{sq}(h)$ as $(y_i - \\bar{y}) + (\\bar{y} - h)$. Why is this a valid step?\n",
    "- Make sure not to expand unnecessarily. Your work should only take ~3 lines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bfb01b",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 3.3 [Written ‚úèÔ∏è]  <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">2 Points</div>\n",
    "\n",
    "Show that:\n",
    "\n",
    "$$R_\\text{sq}(h) = \\frac{1}{n} \\sum_{i = 1}^n (y_i - \\bar{y})^2 + (\\bar{y} - h)^2$$\n",
    "\n",
    "This is called the **bias-variance decomposition** of $R_\\text{sq}(h)$, which is an idea we'll revisit in the coming weeks.\n",
    "\n",
    "Some guidance: At some point, you will need to use your result from Question 3.1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9652df",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 3.4 [Written ‚úèÔ∏è] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">1 Point</div>\n",
    "\n",
    "Why does the result in Question 3.3 prove that $h^* = \\text{Mean}(y_1, y_2, ..., y_n)$ minimizes $R_\\text{sq}(h)$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a1ff1a",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 3.5 [Written ‚úèÔ∏è] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">1 Point</div>\n",
    "\n",
    "In Question 3.3, you showed that:\n",
    "\n",
    "$$R_\\text{sq}(h) = \\frac{1}{n} \\sum_{i = 1}^n (y_i - \\bar{y})^2 + (\\bar{y} - h)^2$$\n",
    "\n",
    "Take a close look at the equation above, then fill in the blank below with **a single word**:\n",
    "\n",
    "> The value of $R_\\text{sq}(h^*)$, when $h^* = \\text{Mean}(y_1, y_2, ..., y_n)$, is equal to the ____ of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39ead42",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## Question 4: More and More Losses üÖª\n",
    "\n",
    "---\n",
    "\n",
    "As we mentioned in Questions 2 and 3, $h^* = \\text{Mean}(y_1, y_2, ..., y_n)$ is the constant prediction that minimizes mean squared error, i.e. average squared loss:\n",
    "\n",
    "$$R_\\text{sq}(h) = \\frac{1}{n} \\sum_{i = 1}^n (y_i-h)^2$$\n",
    "\n",
    "Related, $h^* = \\text{Median}(y_1, y_2, ..., y_n)$ is the constant prediction that minimizes mean absolute error, i.e. average absolute loss:\n",
    "\n",
    "$$R_{\\text{abs}}(h) = \\frac{1}{n} \\sum_{i=1}^n \\left|y_i - h\\right|$$\n",
    "\n",
    "You may notice that the formulas for $R_\\text{sq}(h)$ and $R_\\text{abs}(h)$ look awfully similar ‚Äì they're nearly identical besides the exponent. More generally, for any positive integer $p$, define the $L_p$ loss as follows:\n",
    "\n",
    "$$L_p(y_i, h) = |y_i - h|^p$$\n",
    "\n",
    "With this definition, $L_2$ loss is the same as squared loss and $L_1$ loss is the same as absolute loss. The corresponding average loss, for any value of $p$, is then:\n",
    "\n",
    "$$ R_{p}(h) = \\frac{1}{n} \\sum_{i=1}^n \\left|y_i - h\\right| ^ p $$\n",
    "\n",
    "Written in terms of $R_p(h)$, we know ‚Äì from the top of this question ‚Äì that:\n",
    "\n",
    "- The minimizer of $R_1(h)$ is $\\text{Median}(y_1, y_2, ..., y_n)$:\n",
    "\n",
    "$$\\text{Median}(y_1, y_2, ..., y_n) = \\underset{h}{\\mathrm{argmin}} \\: R_1(h)$$\n",
    "\n",
    "- The minimizer of $R_2(h)$ is $\\text{Mean}(y_1, y_2, ..., y_n)$:\n",
    "\n",
    "$$\\text{Mean}(y_1, y_2, ..., y_n) = \\underset{h}{\\mathrm{argmin}} \\: R_2(h)$$\n",
    "\n",
    "But what constant prediction $h^*$ minimizes $R_3(h)$, or $R_{10}(h)$, or $R_{10000}(h)$? In this question, we'll explore this idea ‚Äì more specifically, we'll study how $h^*$ changes as $p$ (the exponent on $|y_i - h|$) increases.\n",
    "\n",
    "[Lecture 11](https://practicaldsc.org/resources/lectures/lec11/lec11-filled.pdf#page=37) (and the [video linked above](https://youtu.be/NSIEP74ifyg)) worked through how to solve for constant prediction $h^*$ that minimized average squared loss (i.e. minimized $R_2(h)$), and we linked to [another video](https://youtu.be/0s7M8OsnBNA?si=lHm6eN3rns7PzPOW) that works through a similar derivation for average absolute loss (i.e. $R_1(h)$). Unfortunately, $p = 1$ and $p = 2$ are the only cases in which we can solve for the minimizer to $R_p(h)$ by hand. \n",
    "\n",
    "For all other values of $p$, there is no closed-form solution (i.e. no \"formula\" for the best constant prediction), and so we need to approximate the solution using the computer. Later in the class, we'll learn how to minimize functions using code we write ourselves (the idea is called gradient descent if you're curious), but for now, we're going to use `scipy.optimize.minimize`, which does the hard work for us.\n",
    "\n",
    "The `minimize` function is a versatile tool from the `scipy` library that can help us find the input that minimizes the output of a function. Let's test it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a1b913",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f607ab",
   "metadata": {},
   "source": [
    "Below, we've defined and plotted a quadratic function. We can see üëÄ that it's minimized when $x = -4$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862bfa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return (x + 4) ** 2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19249162",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.linspace(-20, 20)\n",
    "ys = f(xs)\n",
    "px.line(x=xs, y=ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f683312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To call minimize, we have to provide an array of initial \"guesses\"\n",
    "# as to where the minimizing input might be.\n",
    "# For our purposes, using 0 as an initial guess will work fine.\n",
    "minimize(f, x0=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4495efae",
   "metadata": {},
   "source": [
    "Above, the `x` attribute of the output tells us that the minimizing input to `f` is `-4.0000`, which is what we were able to see ourselves! Cool."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7630aa41",
   "metadata": {},
   "source": [
    "In this question, we'll deal with the following example array of values, `vals`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ee4676",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = np.array([ 10,  10,  10,  10,  15,  15,  15,  15,  15,  20,  25,  50,  50, 150])\n",
    "vals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5186fd2",
   "metadata": {},
   "source": [
    "For context, let's see what the distribution of `vals` looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da6ae97",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(vals).hist(nbins=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939fb3c2",
   "metadata": {},
   "source": [
    "To reiterate, the constant prediction $h^*$ that minimizes $R_1(h)$ for `vals` is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0e82c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3883ae51",
   "metadata": {},
   "source": [
    "And the constant prediction $h^*$ that minimizes $R_2(h)$ for `vals` is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf524c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829f4707",
   "metadata": {},
   "source": [
    "### Question 4.1 <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">0 Points</div>\n",
    "\n",
    "Complete the implementation of the function `h_star`, which takes in a positive integer `p` and an array `vals` and returns the value of the constant prediction $h^*$ that minimizes average $L_p$ loss for `vals`, i.e. the value of $h^*$ that minimizes $R_p(h)$ for `vals`. Example behavior is given below.\n",
    "\n",
    "```python\n",
    ">>> h_star(1, vals)\n",
    "2.999999995854613\n",
    "\n",
    ">>> h_star(2, vals)\n",
    "6.499999104239989\n",
    "```\n",
    "\n",
    "Some guidance:\n",
    "- Your solution should use `minimize`, and will likely involve defining a helper function inside.\n",
    "- It's okay if your example values are slightly different than those above, but they should be roughly the same. (So, it's fine if `h_star(1, vals)` gives you `1.9999999920558864` or something similar.)\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "**We're not autograding Question 4.1, and it's not worth any points.** But, you need to do it in order to answer Question 4.2, which is worth points (and which you will answer on paper!).\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a8b297",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def h_star(deg, vals):\n",
    "    ...\n",
    "\n",
    "# Feel free to change this input to make sure your function works correctly.\n",
    "h_star(2, vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf916f7",
   "metadata": {},
   "source": [
    "Before proceeding, make sure that the following cells both say `True`, otherwise you did something incorrectly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc57e28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isclose(h_star(1, vals), np.median(vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d9d9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isclose(h_star(2, vals), np.mean(vals))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0051dc62",
   "metadata": {},
   "source": [
    "Once you have a working implementation of `h_star`, run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209a2ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = np.arange(1, 61)\n",
    "hs = [h_star(p, vals) for p in ps]\n",
    "px.line(x=ps, y=hs).update_layout(xaxis_title=r'$p$', yaxis_title=r'$h^* = \\text{minimizer of } R_p(h)$')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c099a1c8",
   "metadata": {},
   "source": [
    "It seems like as $p$ increases, the value of $h^*$ that minimizes $R_p(h)$ approaches some fixed value. But what is that value? For context, look at `vals` again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481d0ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5859abf0",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    \n",
    "If your graph has a sharp sudden drop, that is **not** what we're referring to here. That sharp drop is instead a consequence of choosing very large values of $p$, which correspond to very large exponents, leading to numerical overflow, i.e. numbers too big for Python to represent. $|100 - 90|^{2000}$ is too big for Python!\n",
    "\n",
    "If you run into this issue, change `61` to something smaller in the line `ps = np.arange(1, 61)`. As $p$ increases, you should see the graph of $h^*$ look more and more like a flat line.    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ac11b0",
   "metadata": {
    "tags": []
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 4.2 [Written ‚úèÔ∏è] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">4 Points</div>\n",
    "\n",
    "Use the plot above to answer the following prompts:\n",
    "\n",
    "1. In the `vals` dataset, as $p$ increases, what does the value of $h^*$ that minimizes $R_p(h)$ approach?\n",
    "1. In any general dataset of values $y_1, y_2, ..., y_n$, as $p$ increases, what does the value of $h^*$ that minimizes $R_p(h)$ approach? Why?\n",
    "\n",
    "Put another way, we're asking you to evaluate the following limit, but using your plot, not calculus (you're welcome üòä):\n",
    "\n",
    "$$\\lim_{p \\rightarrow \\infty} \\left( \\underset{h}{\\mathrm{argmin}} \\frac{1}{n} \\sum_{i = 1}^n |y_i - h|^p \\right)$$\n",
    "\n",
    "To answer the second prompt, try calling `h_star` with different arrays that you create. Try and see if you can find a pattern in the values that `h_star` returns when `p` is very large."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443f903e",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## Question 5: Zoe's Bakery üßÅ\n",
    "\n",
    "---\n",
    "\n",
    "Zoe owns a bakery and wants to figure out how to sell the most baked goods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb55f86",
   "metadata": {
    "tags": []
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 5.1 [Written ‚úèÔ∏è] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">3 Points</div>\n",
    "For each of her five baked goods, Zoe recorded the cost in dollars for making the baked good, $x$, and the number of orders for that baked good on a particular day, $y$.\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th>baked good</th>\n",
    "      <th>cost ($x$)</th>\n",
    "      <th>number of baked goods sold ($y$)</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>Cookies</td>\n",
    "      <td>4</td>\n",
    "      <td>70</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Brownies</td>\n",
    "      <td>11</td>\n",
    "      <td>80</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Croissants</td>\n",
    "      <td>8</td>\n",
    "      <td>40</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Cupcakes</td>\n",
    "      <td>7</td>\n",
    "      <td>57</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Muffins</td>\n",
    "      <td>5</td>\n",
    "      <td>43</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "For example, Zoe spent \\$11 making brownies, and sold 80 brownies.\n",
    "\n",
    "Find the optimal parameters $c_0^*$ and $c_1^*$ that minimize mean squared error for the hypothesis function $H(x_i) = c_0 + c_1 x_i$, which predicts the number of baked goods sold of a particular item as a function of the cost of baking that item. Give exact, fractional values for $c_0^*$ and $c_1^*$; do not round.\n",
    "\n",
    "You may use a calculator, but you must show all of your work when you submit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ee3bd2",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 5.2 [Written ‚úèÔ∏è] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">2 Points</div>\n",
    "\n",
    "Let's interpret the meaning of the hypothesis function $H(x_i) = c_0^*+c_1^*x_i$ that you found in Question 5.1.\n",
    "\n",
    "- What does $50 \\cdot c_1^*$ represent in terms of Zoe's bakery?\n",
    "- What does the reciprocal of the slope, $\\frac{1}{c_1^*}$, represent in terms of Zoe's bakery?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ef322f",
   "metadata": {
    "tags": []
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 5.3 [Written ‚úèÔ∏è] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">2 Points</div>\n",
    "What is the mean squared error, $\\text{MSE}_x$, for this dataset, using the line you found in Question 5.1? Round your final answer to two decimal places. Again, you may use a calculator, but you must show all of your work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1916db68",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 5.4 [Written ‚úèÔ∏è] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">3 Points</div>\n",
    "Zoe knows that baking each baked good takes a significant amount of time. She decides to quantify the value of baking time in terms of the number of baked goods sold. For each baked good she baked, Zoe recorded the number of hours to bake one unit of the good, $z$, and the number of items sold on a particular day, $y$.\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th>baked good</th>\n",
    "      <th>baking time (z)</th>\n",
    "      <th>number of baked goods sold (y)</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>Cookies</td>\n",
    "      <td>30</td>\n",
    "      <td>70</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Brownies</td>\n",
    "      <td>44</td>\n",
    "      <td>80</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Croissants</td>\n",
    "      <td>38</td>\n",
    "      <td>40</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Cupcakes</td>\n",
    "      <td>36</td>\n",
    "      <td>57</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Muffins</td>\n",
    "      <td>32</td>\n",
    "      <td>43</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "Find the optimal parameters $d_0^*$ and $d_1^*$ that minimize mean squared error for the hypothesis function $H(z_i) = d_0 + d_1 z_i$, which predicts the number of baked goods sold of a particular item as a function of the baking time of that item. Give exact, fractional values for $d_0^*$ and $d_1^*$; do not round. You may use a calculator, but you must show all of your work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba508143",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 5.5 [Written ‚úèÔ∏è] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\"> 2 Points</div>\n",
    "What is the mean squared error, $\\text{MSE}_z$, for this dataset, using the line you found in Question 5.4? Round your final answer to two decimal places. Again, you may use a calculator, but you must show all of your work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013efc0d",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 5.6 [Written ‚úèÔ∏è] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">5 Points</div>\n",
    "You should have found that $\\text{MSE}_x = \\text{MSE}_z$, which says that for this data, the mean squared error is the same if we use the variable $x$ or the variable $z$ to make our hypothesis function $H$. This happens because the number of hours required to bake one unit of a baked good ($z$) is linearly related to the cost of baking that baked good ($x$) by the formula: $$\\text{baking time} = 22 + 2 \\cdot \\text{cost}$$\n",
    "\n",
    "In the rest of this question, we'll verify some general properties concerning the scenario where we predict some variable $y$ based on $x$, as compared to predicting $y$ based on $z$, when $z$ is a linear transformation of $x$. We'll no longer use the bakery data given above, but we'll prove properties in general.\n",
    "\n",
    "First, suppose we have a dataset $\\{x_1, x_2, \\dots, x_n\\}$ and we define a dataset $\\{z_1, z_2, \\dots, z_n\\}$ by the linear transformation:\n",
    "$$z_i = ax_i + b$$\n",
    "\n",
    "Suppose also we have a dataset $\\{y_1, y_2, \\dots, y_n\\}$.\n",
    "\n",
    "Let $c_0^*$ and $c_1^*$ be the optimal intercept and slope of the regression line (that is, the optimal linear hypothesis function) for $y$ with $x$ as the predictor variable,\n",
    "$$H(x_i) = c_0^* + c_1^* x_i$$\n",
    "Similarly, let $d_0$ and $d_1$ be the intercept and slope of the regression line for $y$ with $z$ as the predictor variable,\n",
    "$$H(z_i) = d_0^* + d_1^*z_i$$\n",
    "\n",
    "Express $d_0^*$ and $d_1^*$ in terms of $c_0^*$, $c_1^*$, $a$, and $b$, and/or one or more constants.\n",
    "\n",
    "_Hint: You can use the fact that if $y_i = ax_i + b$, then $\\bar{y} = a \\bar{x} + b$ without proof._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b645631",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 5.7 [Written ‚úèÔ∏è] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">3 Points</div>\n",
    "Let $\\text{MSE}_x$ be the mean squared error for the dataset $\\{y_1, y_2, \\dots, y_n\\}$ using the hypothesis function:\n",
    "$$H(x_i) = c_0^* + c_1^* x_i.$$\n",
    "Similarly, let $\\text{MSE}_z$ be the mean squared error for the dataset $\\{y_1, y_2, \\dots, y_n\\}$ using the hypothesis function:\n",
    "$$H(z_i) = d_0^* + d_1^* z_i$$\n",
    "Show that $\\text{MSE}_x = \\text{MSE}_z$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d900c4",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## Question 6: Algebra, Too üìê\n",
    "\n",
    "---\n",
    "\n",
    "In the coming lectures, we'll start formulating the problem of making predictions about future data given past data in terms of matrices and vectors. Why? The answer is simple: doing so will allow us to build models that use multiple input variables (i.e. features) in order to make predictions.\n",
    "\n",
    "This question serves to review the key linear algebra knowledge you'll need to be familiar with as we start using matrices and vectors in lecture. If any of this feels foreign ‚Äì and it's totally fine if it does! ‚Äì review the following pages of our [Linear Algebra Guide](https://practicaldsc.org/guides/linear-algebra/):\n",
    "1. [Vectors and angles](https://practicaldsc.org/guides/linear-algebra/vectors-angles/).\n",
    "1. [Linear combinations](https://practicaldsc.org/guides/linear-algebra/linear-combinations/).\n",
    "1. [Matrices](https://practicaldsc.org/guides/linear-algebra/matrices/).\n",
    "1. [Projections](https://practicaldsc.org/guides/linear-algebra/projections/).\n",
    "\n",
    "\n",
    "We'll link to specific sections of our linear algebra guide for each part of this question.\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "Don't worry ‚Äì the content in Question 6 is **not** in scope for the Midterm Exam.\n",
    "    \n",
    "</div>\n",
    "\n",
    "Throughout this question, consider the following vectors in $\\mathbb{R}^3$, where $\\beta \\in \\mathbb{R}$ is a scalar:\n",
    "\n",
    "$$\n",
    "\\vec{v}_1 = \\begin{bmatrix} 0 \\\\ 1 \\\\ 1 \\end{bmatrix}, \\quad \n",
    "\\vec{v}_2 = \\begin{bmatrix} 1 \\\\ 0 \\\\ 1 \\end{bmatrix}, \\quad \n",
    "\\vec{v}_3 = \\begin{bmatrix} \\beta \\\\ 1 \\\\ 2 \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371beef0",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 6.1 [Written ‚úèÔ∏è] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">1 Point</div>\n",
    "\n",
    "For what value(s) of $\\beta$ are $\\vec{v}_1$ and $\\vec{v}_3$ orthogonal?\n",
    "\n",
    "<small><small>üìï To review, read the guide on [Vectors and angles](https://practicaldsc.org/guides/linear-algebra/vectors-angles/).</small></small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1623838",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 6.2 [Written ‚úèÔ∏è] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">1 Point</div>\n",
    "\n",
    "For what value(s) of $\\beta$ are $\\vec{v}_2$ and $\\vec{v}_3$ orthogonal?\n",
    "\n",
    "<small><small>üìï To review, read the guide on [Vectors and angles](https://practicaldsc.org/guides/linear-algebra/vectors-angles/).</small></small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4017280",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 6.3 [Written ‚úèÔ∏è] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">2 Points</div>\n",
    "\n",
    "For what value(s) of $\\beta$ are $\\vec{v}_1, \\vec{v}_2,$ and $\\vec{v}_3$ linearly **in**dependent?\n",
    "\n",
    "<small><small>üìï To review, read the guide on [Linear combinations](https://practicaldsc.org/guides/linear-algebra/linear-combinations/).</small></small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8828ce53",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 6.4 [Written ‚úèÔ∏è] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">2 Points</div>\n",
    "\n",
    "Regardless of your answers to the previous three parts, in this part, let $\\beta = 3$.\n",
    "\n",
    "Is the vector $\\begin{bmatrix}\n",
    "3 \\\\\n",
    "5 \\\\\n",
    "8\n",
    "\\end{bmatrix}$ in $\\text{span}(\\vec{v}_1, \\vec{v}_2, \\vec{v}_3)$? Why or why not?\n",
    "\n",
    "<small><small>üìï To review, read the guide on [Linear combinations](https://practicaldsc.org/guides/linear-algebra/linear-combinations/).</small></small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da4c49e",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 6.5 [Written ‚úèÔ∏è] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">3 Points</div>\n",
    "\n",
    "What is the projection of the vector $\\begin{bmatrix}\n",
    "3 \\\\\n",
    "15 \\\\\n",
    "21\n",
    "\\end{bmatrix}$ onto $\\vec{v}_1$?  Give your answer in the form of a vector.\n",
    "\n",
    "<small><small>üìï To review, read the guide on [Projections](https://practicaldsc.org/guides/linear-algebra/projections/). The first video is all you need for this part.</small></small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e183c5a",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 6.6 [Written ‚úèÔ∏è] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">4 Points</div>\n",
    "\n",
    "What is the orthogonal projection of the vector $\\begin{bmatrix}\n",
    "3 \\\\\n",
    "15 \\\\\n",
    "21\n",
    "\\end{bmatrix}$ \n",
    "onto $\\text{span}(\\vec{v}_1, \\vec{v}_2)$?\n",
    "\n",
    "The answer is a vector, $\\vec{z}$, which can be written in the form:\n",
    "\n",
    "$$\\vec{z} = \\lambda_1 \\vec v_1 + \\lambda_2 \\vec v_2$$\n",
    "\n",
    "**Your job** is to find the values of scalars $\\lambda_1$ and $\\lambda_2$, and then, the vector $\\vec z$. As done in the [Projections](https://practicaldsc.org/guides/linear-algebra/projections) guide, one of the intermediate steps in answering this question involves defining a particular matrix $X$ and computing $(X^T X) ^{-1}X^T$.\n",
    "\n",
    "<small><small>üìï To review, read the guide on [Projections](https://practicaldsc.org/guides/linear-algebra/projections/). </small></small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c36664",
   "metadata": {
    "tags": []
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## Finish Line üèÅ\n",
    "\n",
    "Congratulations! You're ready to submit Homework 6.\n",
    "\n",
    "You need to submit Homework 6 twice:\n",
    "\n",
    "### To submit the manually graded problems (Questions 2-6; marked [Written ‚úèÔ∏è])\n",
    "\n",
    "- Make sure your answers **are not** in this notebook, but rather in a separate PDF.\n",
    "    - You can create this PDF either digitally, using your tablet or using [Overleaf + LaTeX](https://overleaf.com) (or some other sort of digital document), or by writing your answers on a piece of paper and scanning them in.\n",
    "- Submit this separate PDF to the **Homework 6 (Questions 2-6; written problems)** assignment on Gradescope, and **make sure to correctly select the pages associated with each question**!\n",
    "\n",
    "### To submit the autograded problems (Question 1; marked [Autograded üíª])\n",
    "\n",
    "1. Select `Kernel -> Restart & Run All` to ensure that you have executed all cells, including the test cells.\n",
    "2. Read through the notebook to make sure everything is fine and all tests passed.\n",
    "3. Download your notebook using `File -> Download as -> Notebook (.ipynb)`, then upload your notebook to Gradescope under **Homework 6 (Question 1; autograded problems)**.\n",
    "4. Stick around while the Gradescope autograder grades your work. **Remember that Homework 6 has no hidden tests! This means the tests you see in your notebook are the exact same as the ones that will be used to grade your work on Gradescope. When you submit on Gradescope, you'll see your score shortly after you submit, once the autograder finishes running.** \n",
    "5. Check that you have a confirmation email from Gradescope and save it as proof of your submission.\n",
    "\n",
    "Your Homework 6 submission time will be the **later** of your two individual submissions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "otter": {
   "tests": {
    "q01_01": {
     "name": "q01_01",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(query_llm('Tell me a joke about data science'), str)\nTrue",
         "failure_message": "Make sure query_llm returns a string.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> query_llm('Tell me a joke about data science') != query_llm('Tell me a joke about data science')\nTrue",
         "failure_message": "Make sure query_llm isn't hard-coded to always return the same string.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q01_02": {
     "name": "q01_02",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> tokenize('hi there') == ['hi', 'there']\nTrue",
         "failure_message": "Incorrect output for input 'hi there'.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> tokenize(\"EECS 398: Practical Data Science, Fall 2024's about data management and applied machine learning.\") == ['eecs', '398', 'practical', 'data', 'science', 'fall', '2024', 's', 'about', 'data', 'management', 'and', 'applied', 'machine', 'learning']\nTrue",
         "failure_message": "Incorrect output for input \"EECS 398 Practical Data Science's about data management and applied machine learning.\".",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out = tokenize(open('data/courses.txt', 'r').read())\n>>> out[1:40] == ['aas', '103', 'first', 'year', 'social', 'science', 'seminar', 'this', 'seminar', 'introduces', 'first', 'year', 'students', 'to', 'the', 'intellectual', 'community','of','social','scientists','working','in','the','field','of','afroamerican','and','african','studies','the','topic','of','the','seminar','varies','from','year','to','year']\nTrue",
         "failure_message": "Incorrect output for AAS 103 (first course) on courses.txt (first 40 tokens).",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out = tokenize(open('data/courses.txt', 'r').read())[45055:45070]\n>>> 'essential tools for computer programming shells environments scripting makefiles compilers debugging tools and version control' in ' '.join(out)\nTrue",
         "failure_message": "Incorrect output for EECS 201 course description (missing substring).",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out = tokenize(open('data/courses.txt', 'r').read())[45392:45440]\n>>> ('.' not in out) and ('!' not in out) and (':' not in out) and ('@' not in out)\nTrue",
         "failure_message": "Incorrect output for EECS 280 course description (found punctuation, but there should be none).",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out = tokenize(open('data/courses.txt', 'r').read())[48439:48484]\n>>> counts = pd.Series(out).value_counts()\n>>> counts.loc['community'] == 2 and counts.loc['writing'] == 2\nTrue",
         "failure_message": "Incorrect output for ENGLISH 126 course description (wrong frequency of tokens).",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q01_03": {
     "name": "q01_03",
     "points": 4,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> bow.shape == (1638, 10865)\nTrue",
         "failure_message": "Outputted DataFrame has incorrect shape. Remember to run the code defining `bow` above!",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> selected = bow.index[0:6].tolist() + bow.index[1600:1606].tolist()\n>>> selected == ['AAS 103', 'AAS 104', 'AAS 116', 'AAS 200', 'AAS 202', 'AAS 216', 'UC 402', 'UC 403', 'UC 415', 'UKR 152', 'UKR 352', 'UKR 450']\nTrue",
         "failure_message": "Outputted DataFrame has incorrect index (remember to sort it in ascending order). Remember to run the code defining `bow` above!",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> set(bow.columns) >= {'data', 'and', 'collaboration', 'computer'}\nTrue",
         "failure_message": "Outputted DataFrame has missing column names (i.e. missing tokens). Remember to run the code defining `bow` above!",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> bow.loc['EECS 280', 'data'] == 4\nTrue",
         "failure_message": "Outputted DataFrame has incorrect 'data' frequency for 'EECS 280'. Remember to run the code defining `bow` above!",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> (bow.loc['ENGLISH 125'] > 0).sum() == 71\nTrue",
         "failure_message": "Outputted DataFrame has incorrect counts for 'ENGLISH 125'. Remember to run the code defining `bow` above!",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> bow.sum(axis=1).max() == 349 and bow.sum(axis=1).idxmax() == 'EDUC 118'\nTrue",
         "failure_message": "Outputted DataFrame has incorrect counts for 'EDUC 118'. Remember to run the code defining `bow` above!",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q01_04": {
     "name": "q01_04",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> out = bow_to_tfidf(bow)\n>>> out.shape == (1638, 10865)\nTrue",
         "failure_message": "Outputted DataFrame has incorrect shape.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out = bow_to_tfidf(bow)\n>>> selected = out.index[0:6].tolist() + out.index[1600:1606].tolist()\n>>> selected == ['AAS 103', 'AAS 104', 'AAS 116', 'AAS 200', 'AAS 202', 'AAS 216', 'UC 402', 'UC 403', 'UC 415', 'UKR 152', 'UKR 352', 'UKR 450']\nTrue",
         "failure_message": "Outputted DataFrame has incorrect index (keep the same index as bow).",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out = bow_to_tfidf(bow)\n>>> np.isclose(out.loc['EECS 280', 'data'], 0.19708242779519058)\nTrue",
         "failure_message": "Outputted DataFrame has incorrect 'data' TF-IDF for 'EECS 280'.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out = bow_to_tfidf(bow)\n>>> np.isclose(out.loc['ENGLISH 125', 'writing'], 0.045412922624550225)\nTrue",
         "failure_message": "Outputted DataFrame has incorrect 'writing' TF-IDF for 'ENGLISH 125'.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out = bow_to_tfidf(bow)\n>>> (out.loc['STATS 250'] > 0).sum() == 97\nTrue",
         "failure_message": "Outputted DataFrame has incorrect number of non-zero values for 'STATS 250'.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out = bow_to_tfidf(bow)\n>>> out.loc['EECS 201'].idxmax() in ['makefiles', 'compilers']\nTrue",
         "failure_message": "Outputted DataFrame has incorrect largest TF-IDF for 'EECS 201' (there are two tied idxmaxes).",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q01_05": {
     "name": "q01_05",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> out = new_query_to_tfidf('yooo I am very very very interested in biochemistry and cellular biology courses')\n>>> (out > 0).sum() == 9\nTrue",
         "failure_message": "Outputted Series has incorrect number of non-zero values for query below.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out = new_query_to_tfidf('yooo I am very very very interested in biochemistry and cellular biology courses')\n>>> np.allclose(np.sort(out[out > 0]), np.array([0.00728461, 0.02018187, 0.22066398, 0.24821877, 0.27481461, 0.29156257, 0.34698919, 0.36101393, 0.93090818]))\nTrue",
         "failure_message": "Outputted Series has incorrect number values for query below.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out = new_query_to_tfidf('yooo I am very very very interested in biochemistry and cellular biology courses')\n>>> set(out[out > 0].index) == {'cellular', 'biology', 'interested', 'courses', 'i', 'and', 'very', 'in', 'biochemistry'}\nTrue",
         "failure_message": "Outputted Series has incorrect non-zero values for query below.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out = new_query_to_tfidf('sEIG;H I  seigh;o ')\n>>> set(out[out > 0].index) == {'i', 'o'} and np.allclose(np.sort(out[out > 0]), np.array([0.57372635, 1.09106422]))\nTrue",
         "failure_message": "Outputted Series has incorrect non-zero values for query below.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out = new_query_to_tfidf('logical programming Fundamentals C++ compiler operator linear FUNCtional computer science 60 exam')\n>>> set(out[out > 0].index) == {'computer', 'linear', 'c', 'fundamentals', '60', 'functional', 'science', 'programming', 'logical', 'exam'}\nTrue",
         "failure_message": "Outputted Series has incorrect non-zero values for query below.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out = new_query_to_tfidf('logical programming Fundamentals C++ compiler operator linear FUNCtional computer science 60 exam')\n>>> np.allclose(np.sort(out[out > 0]), np.array([0.20319889, 0.27557389, 0.32290589, 0.32290589, 0.33060367, 0.38066816, 0.41694467, 0.45461009, 0.48264945, 0.55900701]))\nTrue",
         "failure_message": "Outputted Series has incorrect non-zero values for query below.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out = new_query_to_tfidf('logical programming Fundamentals C++ compiler operator linear FUNCtional computer science 60 exam')\n>>> out.shape[0] == 10865\nTrue",
         "failure_message": "Outputted Series has incorrect shape.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q01_06": {
     "name": "q01_06",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> out = top_n_similar_documents('yooo I am very interested in biochemistry and cellular biology courses', 3)\n>>> set(out) == {'BIOLOGY 172', 'CHEM 351', 'CHEM 218'}\nTrue",
         "failure_message": "Incorrect documents for input 'yooo I am very interested in biochemistry and cellular biology courses', n = 3.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out = top_n_similar_documents('yooo I am very interested in biochemistry and cellular biology courses', 3)\n>>> out == ['CHEM 351', 'BIOLOGY 172', 'CHEM 218']\nTrue",
         "failure_message": "Incorrect document order for 'yooo I am very interested in biochemistry and cellular biology courses', n = 3.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out = top_n_similar_documents('algorithms, programming, system design', 4)\n>>> out == ['ENGR 101', 'COMPFOR 150', 'EECS 281', 'LING 123']\nTrue",
         "failure_message": "Incorrect documents for 'algorithms, programming, system design', n = 4.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out = top_n_similar_documents('algorithms, programming, system design', 6)\n>>> out == ['ENGR 101', 'COMPFOR 150', 'EECS 281', 'LING 123', 'BIOPHYS 131', 'COMPFOR 131']\nTrue",
         "failure_message": "Incorrect documents for 'C++ programming and systems design', n = 6.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out = top_n_similar_documents('mathematical foundations of computing', 3)\n>>> out == ['COMPFOR 111', 'COMPFOR 121', 'EECS 479']\nTrue",
         "failure_message": "Incorrect documents for 'mathematical foundations of computing', n = 3.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out = top_n_similar_documents('probability theory and randomness', 7)\n>>> out == ['STATS 425', 'MATH 425', 'STATS 412', 'ECE 501', 'MATH 525', 'STATS 525', 'STATS 426']\nTrue",
         "failure_message": "Incorrect documents for 'probability theory and randomness', n = 7.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q01_07": {
     "name": "q01_07",
     "points": 4,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> out = ask_gpteecs('yooo I am very interested in biochemistry and cellular biology courses', n=5)\n>>> \"351\" in out or \"172\" in out or \"CHEM\" in out\nTrue",
         "failure_message": "CHEM 351 not found in response for the query \"yooo I am very interested in biochemistry and cellular biology courses\", or queries were all the same when called repeatedly (but should not be).",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out = ask_gpteecs('programming', n=5)\n>>> \"EECS\" in out or \"LING\" in out\nTrue",
         "failure_message": "Neither EECS or LING were found in response for the query \"programming\", or queries were all the same when called repeatedly (but should not be).",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out = ask_gpteecs('what Spanish courses are best for advanced speakers', n=5)\n>>> '277' in out or '100' in out or 'pan' in out and (not 'EECS' in out)\nTrue",
         "failure_message": "Neither Spanish 277 or Spanish 100 were found in response for the query below, or queries were all the same when called repeatedly (but should not be).",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
