{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ddb75c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"hw09.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33e1b18",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" markdown=\"1\">\n",
    "\n",
    "#### Homework 9\n",
    "\n",
    "# Cross-Validation and Regularization\n",
    "\n",
    "### EECS 398: Practical Data Science, Winter 2025\n",
    "\n",
    "#### Due Wednesday, April 2nd at 11:59PM (one day later than usual)\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca8e28c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Instructions\n",
    "\n",
    "Welcome to Homework 9! In this homework, you'll implement cross-validation to choose model hyperparameters,\n",
    "understand why ridge regression works the way it does (down to the linear algebraic details), and build more sophisticated `sklearn` Pipelines using these techniques. Only content through Lecture 19 is necessary.\n",
    "\n",
    "You are given **eight** slip days throughout the semester to extend deadlines. See the [Syllabus](https://practicaldsc.org/syllabus) for more details. With the exception of using slip days, late work will not be accepted unless you have made special arrangements with your instructor.\n",
    "\n",
    "To access this notebook, you'll need to clone our [public GitHub repository](https://github.com/practicaldsc/wn25/). The [Environment Setup](https://practicaldsc.org/env-setup) page on the course website walks you through the necessary steps.\n",
    "<div class=\"alert alert-warning\" markdown=\"1\">\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "This homework features a mix of autograded programming questions and manually-graded questions.\n",
    "    \n",
    "- Question 1 is **manually graded**, like in Homework 8, and its parts say **[Written ‚úèÔ∏è]** in the title. For this question, **do not write your answers in this notebook**! Instead, like in Homework 8, write **all** of your answers to the written questions in this homework in a separate PDF. You can create this PDF either digitally, using your tablet or using [Overleaf + LaTeX](https://overleaf.com) (or some other sort of digital document), or by writing your answers on a piece of paper and scanning them in. Submit this separate PDF to the **Homework 9 (Question 1; written problem)** assignment on Gradescope, and **make sure to correctly select the pages associated with each question**!\n",
    "\n",
    "- Questions 2-3 are **fully autograded**, and its parts say **[Autograded üíª]** in the title. For these questions, all you need to is write your code in this notebook, run the local `grader.check` tests, and submit to the **Homework 9 (Questions 2-3; autograded problems)** assignment on Gradescope to have your code graded by the hidden autograder. This is the same workflow you followed in previous homeworks.\n",
    "\n",
    "Your Homework 9 submission time will be the **later** of your two individual submissions.\n",
    "</div>\n",
    "</div>\n",
    "\n",
    "**Make sure to show your work for all written questions! Answers without work shown may not receive full credit.**\n",
    "\n",
    "    \n",
    "This homework is worth a total of **39 points**, 15 of which are manually graded and 24 of which come from the autograder. This is not including the potential extra credit provided by Question 3.4, which only 5 students in the class can receive (see Question 3.4 for more details). The number of points each question is worth is listed at the start of each question. **All questions in the assignment are independent, so feel free to move around if you get stuck**, but keep in mind that you'll need to submit this homework twice ‚Äì one submission for your written problems, and one submission for your autograded problems. Tip: if you're using Jupyter Lab, you can see a Table of Contents for the notebook by going to View > Table of Contents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c82d50",
   "metadata": {},
   "source": [
    "To get started, run the cell below, plus the cell at the top of the notebook that imports and initializes `otter`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ed20a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "\n",
    "# Preferred styles\n",
    "pio.templates[\"pds\"] = go.layout.Template(\n",
    "    layout=dict(\n",
    "        margin=dict(l=30, r=30, t=30, b=30),\n",
    "        autosize=True,\n",
    "        width=600,\n",
    "        height=400,\n",
    "        xaxis=dict(showgrid=True),\n",
    "        yaxis=dict(showgrid=True),\n",
    "        title=dict(x=0.5, xanchor=\"center\"),\n",
    "    )\n",
    ")\n",
    "pio.templates.default = \"simple_white+pds\"\n",
    "\n",
    "# Use plotly as default plotting engine\n",
    "pd.options.plotting.backend = \"plotly\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9635b0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Question 1: Ruffles Have Ridges ‚õ∞Ô∏è\n",
    "\n",
    "---\n",
    "\n",
    "In this question, you'll gain deep familiarity with **why** and **how** ridge regression ‚Äì that is, least squares regression with an $L_2$ regularization penalty ‚Äì works.\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "To get started, read [**this guide**](https://practicaldsc.org/guides/machine-learning/ridge-regression/) we've written about ridge regression, after completing Lecture 19 (Regularization). Think of it as an extension of the homework spec.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a21a224",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 1.1 [Written ‚úèÔ∏è] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">3 Points</div>\n",
    "\n",
    "Prove that all of the eigenvalues of $X^TX$, where $X$ is the design matrix, are non-negative.\n",
    "\n",
    "Some guidance:\n",
    "- Start by letting $\\lambda_i$ and $\\vec{v}_i$ be an arbitrary eigenvalue-eigenvector pair of $X^TX$. By the definition of eigenvalues and eigenvectors, what does this mean? (Hint: can $\\vec{v}_i = \\vec{0}$?)\n",
    "- Left-multiply both sides of the equation by $\\vec{v}_i^T$. What does this give us?\n",
    "- From here, use the facts that $(AB)^T = B^T A^T$ and that $\\lVert \\vec u \\rVert^2 = \\vec u \\cdot \\vec u$ to show that $\\lambda_i \\geq 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148e38a5",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 1.2 [Written ‚úèÔ∏è] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">3 Points</div>\n",
    "\n",
    "If $\\lambda_i$ and $\\vec{v}_i$ are an eigenvalue-eigenvector pair of $X^TX$, then show that $\\vec{v}_i$ is **also** an eigenvector of $X^TX + n \\lambda_\\text{ridge} I$, with a different eigenvalue. What is the corresponding eigenvalue?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fec308",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 1.3 [Written ‚úèÔ∏è] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">2 Points</div>\n",
    "\n",
    "Putting the results of 1.1 and 1.2 together, explain why it is **guaranteed** that $X^TX + n \\lambda_\\text{ridge} I$ is invertible, for any $\\lambda_\\text{ridge} > 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712172a2",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 1.4 [Written ‚úèÔ∏è] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">2 Points</div>\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "Before proceeding, make sure you've read the last two sections of [**this guide**](https://practicaldsc.org/guides/machine-learning/ridge-regression/), since we'll use definitions and terms from there that aren't in this homework notebook.\n",
    "    \n",
    "</div>\n",
    "\n",
    "Show that:\n",
    "\n",
    "$$ X_{\\text{adj}}^T \\vec{y}_\\text{adj} = X_c^T \\vec{y}_c $$\n",
    "\n",
    "Some guidance: Make sure you've carefully read our work in Step 1 of [**\"The final derivation\" in the guide**](https://practicaldsc.org/guides/machine-learning/ridge-regression/#the-final-derivation), because you'll need to follow a similar sequence of reasoning; when multiplying $X_\\text{adj}^T \\vec{y}_\\text{adj}$, many of the terms in the resulting matrix are 0 ‚Äì make sure you're clear on which terms those are."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db62e522",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 1.5 [Written ‚úèÔ∏è] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">3 Points</div>\n",
    "Step 3 of [**\"The final derivation\" in the guide**](https://practicaldsc.org/guides/machine-learning/ridge-regression/#the-final-derivation) relates the objective functions we seek to minimize in linear and ridge regression. Again, we'll reason about how the adjusted terms $X_{\\text{adj}}$ and $\\vec{y}_\\text{adj}$, in the context of un-regularized linear regression, relate to the ridge regression objective function. Using the work done in Question 1.4 and before, show that:\n",
    "\n",
    "$$\\frac{1}{n} \\lVert \\vec{y}_{\\text{adj}} - X_{\\text{adj}} \\vec{w} \\rVert_2^2 = \\frac{1}{n} \\lVert \\vec{y}_c - X_c \\vec{w} \\rVert_2^2 + \\lambda_\\text{ridge} \\sum_{j = 1}^d w_j^2$$\n",
    "\n",
    "Some guidance: \n",
    "- One way to proceed is to recall the definition $\\lVert \\vec v \\rVert_2^2 = \\vec v \\cdot \\vec v = \\vec v \\cdot \\vec v$ and expand from there. A useful fact is that:\n",
    "\n",
    "    $$(\\vec a - \\vec b) \\cdot (\\vec a - \\vec b) = \\vec a \\cdot \\vec a - 2 \\vec a \\cdot \\vec b + \\vec b \\cdot \\vec b,$$\n",
    "\n",
    "    which follows from the commutative and distributive properties of the dot product. Another way to proceed is to re-write $\\lVert \\vec v \\rVert_2^2 = \\sum_{i = 1}^n v_i^2$ and separate sums from there.\n",
    "- Note that $\\sum_{j = 1}^d w_j^2 = \\lVert \\vec w \\rVert_2^2$; we've written it in this summation notation throughout to remain consistent with the notation from class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f3c4c4",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 1.6 [Written ‚úèÔ∏è] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">2 Points</div>\n",
    "\n",
    "Finally, argue why:\n",
    "   $$\n",
    "   \\vec{w}^* = \\left(X_c^T X_c + n \\lambda_\\text{ridge} I\\right)^{-1} X_c^T \\vec{y}\n",
    "   $$\n",
    "\n",
    "minimizes the ridge regression objective function: $$\\frac{1}{n} \\lVert \\vec{y}_c - X_c \\vec{w} \\rVert_2^2 + \\lambda_\\text{ridge} \\sum_{j = 1}^d w_j^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d05ee65",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "Thanks for bearing with us through this (extremely) long question! We hope you've left it with a deeper understanding of what ridge regression is, and how and why it works."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dabd4dd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Question 2: $k$-Nearest Neighbors Returns! üè°üè†\n",
    "\n",
    "---\n",
    "\n",
    "In Homework 8, you implemented $k$-nearest neighbors regression. For a refresher of how the method words, review the writeup to Question 1.3 in [Homework 8](https://github.com/practicaldsc/wn25/blob/main/homeworks/hw08/hw08.ipynb). (In Lecture 21, you will also learn about the $k$-nearest neighbors classifier; the classifier and regressor work similarly, but our exploration here is about the **regressor**.)\n",
    "\n",
    "In $k$-NN regression, $k$ was a **hyperparameter** ‚Äì you got to choose it before the model was fit to the data. In Question 1.4, we had you estimate, intuitively, a value of $k$ that would create a regressor that generalized well to unseen data. In this question, we'll have you use a more principled approach ‚Äì cross-validation. And, you'll have to implement the cross-validation yourself!\n",
    "\n",
    "Let's start by loading in the same `homeruns` dataset from Homework 8, Question 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4134228e",
   "metadata": {},
   "outputs": [],
   "source": [
    "homeruns = pd.read_csv('data/homeruns.csv')\n",
    "homeruns.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43d18cf",
   "metadata": {},
   "source": [
    "You'll notice that the `'Year'` values aren't integers. That's because we've added a small amount of artificial noise to the `'Year'` column so that `sklearn`'s $k$-NN regressor ‚Äì which you'll use in this question ‚Äì _doesn't_ encounter any ties when determining the $k$ nearest points. This was problematic last semester, since ties were broken by `sklearn` non-deterministically in a way that we cannot control.\n",
    "\n",
    "Once you run the cell below, you will see that this additional noise does not affect the general trend we observed last time from the `homeruns` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21c2b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "homeruns.plot(kind='scatter', x='Year', y='Homeruns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601685d9",
   "metadata": {},
   "source": [
    "We'll continue trying to predict `'Homeruns'` as a function of `'Year'`. Last time, we had you implement $k$-nearest neighbors regression by hand. Since you know how to do that already, here, we'll use `sklearn`'s implementation. `KNeighborsRegressor` is imported for you below, along with another useful function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7a83b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81333f6",
   "metadata": {},
   "source": [
    "### Question 2.1 [Autograded üíª] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">1 Point</div>\n",
    "\n",
    "Assign `X_train`, `X_test`, `y_train`, and `y_test` to the result of performing a train-test split on `homeruns`. Use the default train-test split size, and set `random_state=98`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facabe64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e9f37f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q02_01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7f7f19",
   "metadata": {},
   "source": [
    "### Question 2.2 [Autograded üíª] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">5 Points</div>\n",
    "\n",
    "Eventually, we'll want to use cross-validation to identify the value of $k$ ‚Äì that is, the number of neighbors ‚Äì that specifies a model that best generalizes to unseen data. But first, we need a function that can perform cross-validation for us.\n",
    "\n",
    "While `GridSearchCV` and `cross_val_score` exist, **you cannot use them in this question** ‚Äì instead, the goal here is to implement cross-validation yourself to help really understand how it works.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Note that the terminology is a little confusing, since we're using $k$-fold cross-validation to choose a $k$ for $k$-nearest neighbors regression.\n",
    "\n",
    "<b>In this question, $k$ will always refer to the number of neighbors to use in $k$-nearest neighbors regression.</b> We'll use other terminology to refer to the number of folds in cross-validation.\n",
    "    \n",
    "</div>\n",
    "\n",
    "Complete the implementation of the function `cross_validate_model`, which takes in:\n",
    "- `model`, an **un-fit** instance of an `sklearn` estimator object, like `LinearRegression()` or `KNeighborsRegressor(10)`,\n",
    "- `X_train`, a 2D array/DataFrame with $x$-values being used to train a model.\n",
    "- `y_train`, a 1D array/Series with $y$-values being used to train a model, with the same number of rows as `X_train`.\n",
    "- `cv`, a number of folds to use for cross-validation (normally, we call this the $k$ in $k$-fold cross-validation).\n",
    "\n",
    "`cross_validate_model` should implement `cv`-fold cross-validation, as described [**here in Lecture 18**](https://practicaldsc.org/resources/lectures/lec18/lec18-filled.html#Illustrating-$k$-fold-cross-validation). Specifically, it should:\n",
    "- Divide `X_train` and `y_train` into `cv` disjoint folds of equal size.\n",
    "    - `cross_validate_model` **should not** shuffle before creating these folds ‚Äì instead, it should divide the data as-is into the folds.\n",
    "    - For example, if `X_train` and `y_train` have 30 rows, and `cv = 3`, fold 0 should be rows 0-9, fold 1 should be rows 10-19, and fold 2 should be rows 20-29.\n",
    "- Train `model` `cv` times, such that:\n",
    "    - Each fold is used for validation once and for training `cv - 1` times.\n",
    "    - Each time `model` is trained, compute its **validation mean squared error** on the validation fold.\n",
    "- Return a **DataFrame** with `cv` rows and 2 columns, `'training_mse'` and `'validation_mse'`.\n",
    "    - There should be one row per fold; the index of the returned DataFrame should be `'Fold 0'`, `'Fold 1'`, and so on.\n",
    "    - If `out` is the returned DataFrame, then for example, `out.loc['Fold 4', 'training_mse']` should be the training mean squared error when fold 4 was used for validation (and the other `cv - 1` folds were used for training) and `out.loc['Fold 4', 'validation_mse']` should be the validation mean squared error when fold 4 was used for validation.\n",
    "    - The example above assumes that `cv >= 5`; note that in general, the only restriction on `cv` is that `cv >= 2`.\n",
    "    \n",
    "\n",
    "Example behavior is given below.\n",
    "\n",
    "```python\n",
    ">>> cross_validate_model(KNeighborsRegressor(2), X_train, y_train, 10)\n",
    "```\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>training_mse</th>\n",
    "      <th>validation_mse</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>Fold 0</th>\n",
    "      <td>44926.432099</td>\n",
    "      <td>281430.638889</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>Fold 1</th>\n",
    "      <td>52946.635802</td>\n",
    "      <td>99437.972222</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>Fold 2</th>\n",
    "      <td>47598.129630</td>\n",
    "      <td>119365.750000</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>Fold 3</th>\n",
    "      <td>54323.262346</td>\n",
    "      <td>115330.555556</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>Fold 4</th>\n",
    "      <td>67494.194444</td>\n",
    "      <td>77006.083333</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>Fold 5</th>\n",
    "      <td>49634.175926</td>\n",
    "      <td>281051.194444</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>Fold 6</th>\n",
    "      <td>55767.966049</td>\n",
    "      <td>50324.750000</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>Fold 7</th>\n",
    "      <td>54990.524691</td>\n",
    "      <td>373829.111111</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>Fold 8</th>\n",
    "      <td>55223.456790</td>\n",
    "      <td>73802.888889</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>Fold 9</th>\n",
    "      <td>52366.061728</td>\n",
    "      <td>97442.916667</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "For more context on the example above:\n",
    "- `X_train` and `y_train` are divided into 10 folds. `X_train` and `y_train` each have 90 rows, so each fold has 9 points.\n",
    "- When fold 0 is used for validation:\n",
    "    - Fold 0 corresponds to rows 0-8 of `X_train` and `y_train`.\n",
    "    - The rows used for training, then, are folds 1-9, i.e. rows 9-89 of `X_train` and `y_train`.\n",
    "    - A `KNeighborsRegressor(2)` instance is fit on rows 9-89 of `X_train` and `y_train`.\n",
    "    - The mean squared error of that model instance, when evaluated on rows 9-89, is `44926.432099`, so `out.loc['Fold 0', 'training_mse']` is `44926.432099`.\n",
    "    - The mean squared error of that model instance, when evaluated on rows 0-8, is `281430.638889`, so `out.loc['Fold 0', 'validation_mse']` is `281430.638889`.\n",
    "- When fold 1 is used for validation:\n",
    "    - Fold 1 corresponds to rows 9-17 of `X_train` and `y_train`.\n",
    "    - The rows used for training, then, are folds 0, 2, 3, 4, ..., 9, i.e. rows 0-8 and rows 18-89 of `X_train` and `y_train`. **A big part of the question is determining, programmatically, which rows are to be used for training!**\n",
    "    - A `KNeighborsRegressor(2)` instance is fit on rows 0-8 and 18-89 of `X_train` and `y_train`.\n",
    "    - The mean squared error of that model instance, when evaluated on rows 0-8 and 18-89, is `52946.635802`, so `out.loc['Fold 1', 'training_mse']` is `52946.635802`.\n",
    "    - The mean squared error of that model instance, when evaluated on rows 9-17, is `99437.972222`, so `out.loc['Fold 1', 'validation_mse']` is `99437.972222`.\n",
    "- And so on!\n",
    "    \n",
    "\n",
    "Some guidance:\n",
    "- Assume that the number of rows in `X_train` is divisible by `cv`, i.e. assume all folds are of the same size. Furthermore, assume that `cv >= 2`.\n",
    "- Assume that `X_train` and `y_train` have the same number of rows, but **don't** assume that they have the same index values! The `X_train` and `y_train` you produced in Question 2.1 do have the same index, but we should make your `cross_validate_model` more general-purpose. Separate data into folds based on integer positions. \n",
    "- Remember that `model` could be any un-fit `sklearn` estimator instance, not just `KNeighborsRegressor(2)`.\n",
    "- Remember that **you must implement cross-validation from scratch here ‚Äì you cannot use any pre-built implementation of it**. The animation in Lecture 18 will be helpful.\n",
    "    - If it helps you in understanding what the goal is, note that `cross_validate_model` does something very similar to the built-in function `cross_val_score` ‚Äì but again, you can't use it (we're checking!).\n",
    "    - **You can't use `sklearn`'s `mean_squared_error` either ‚Äì please implement it yourself, we'll be checking!**\n",
    "- You can use a `for`-loop ‚Äì our solution had two (more specifically, one loop and one list comprehension)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e3f177",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cross_validate_model(model, X_train, y_train, cv):\n",
    "    # Remember: Do **not** shuffle X_train or y_train here;\n",
    "    # train_test_split already did the shuffling for us!\n",
    "    ...\n",
    "    \n",
    "# Feel free to change this input to make sure your function works correctly.\n",
    "cross_validate_model(KNeighborsRegressor(2), X_train, y_train, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0551eb",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q02_02\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3cdb6e",
   "metadata": {},
   "source": [
    "### Question 2.3 [Autograded üíª] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">5 Points</div>\n",
    "\n",
    "Now, let's use your implementation of `cross_validate_model` to find the value of $k$ ‚Äì that is, the number of neighbors ‚Äì that best generalizes to unseen data.\n",
    "\n",
    "Complete the implementation of the function `plot_validation_error_vs_k`, which takes in:\n",
    "- `k_max`, a positive integer.\n",
    "- `X_train`, `y_train`, and `cv`, all of which are defined the same way as when implementing `cross_validate_model`.\n",
    "\n",
    "`plot_validation_error_vs_k` should return a `plotly` Figure object like the one below:\n",
    "\n",
    "<br>\n",
    "\n",
    "<center><img src=\"imgs/knn.png\" width=550></center>\n",
    "\n",
    "There are several steps involved here.\n",
    "- `plot_validation_error_vs_k` should call `cross_validate_model` `k_max` times.\n",
    "    - Once, `cross_validate_model` should be called with `model = KNeighborsRegressor(1)`.\n",
    "    - Then, `cross_validate_model` should be called with `model = KNeighborsRegressor(2)`.\n",
    "    - and so on, until `model = KNeighborsRegressor(k_max)`.\n",
    "    - Each time `cross_validate_model` is called, `X_train`, `y_train`, and `cv` should all be passed as-is without modification.\n",
    "- After calling `cross_validate_model` for a particular value of $k$, you should compute the **average** training MSE and **average** validation MSE for that $k$ and store it somewhere.\n",
    "- Then, create a DataFrame (likely, one that has $k$ rows and 2 columns) with the average training and validation MSE for each value of $k$, and create a `plotly` line chart with the values in that DataFrame.\n",
    "- Some properties that must be true of your `plotly` Figure:\n",
    "    - It must have exactly two lines.\n",
    "    - The two lines should have different names in the legend; one should have `'training'` somewhere in the name (in any case), and the other should have `'validation'`, and these names should correspond to the types of errors the lines are depicting.\n",
    "    - The $x$-axis and $y$-axis titles must be exactly the same as ours (including capitalization).\n",
    "    - The $x$-axis ticks should say `'k = 1'`, `'k = 2'`, and so on, as well. It doesn't matter if the tick labels are rotated on an angle or not (this is determined automatically by `plotly`, depending on what you set `k_max` to, and is not super relevant)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e122093e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_validation_error_vs_k(k_max, X_train, y_train, cv):\n",
    "    ...\n",
    "    \n",
    "# Feel free to change this input to make sure your function works correctly.\n",
    "plot_validation_error_vs_k(20, X_train, y_train, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7691f34b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q02_03\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f848c79",
   "metadata": {},
   "source": [
    "Now that you've completed `plot_validation_error_vs_k`, let's take a look at the results one more time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ebaff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_validation_error_vs_k(20, X_train, y_train, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4df706c",
   "metadata": {},
   "source": [
    "You reflected on the behavior of $k$ in $k$-nearest neighbor regression models last week, and gave an intuitive choice for a \"good\" value of $k$.\n",
    "\n",
    "Now, it's unambiguously clear what the \"best\" choice of $k$ is: $k = 4$. But, any choice in the range of $k = 3$ to $k = 11$ seems to produce roughly the same average validation mean squared error. Note that this plot looks a little different than the plots of training/validation error vs. model complexity that we saw in lecture because **here, as Number of Neighbors ($k$) increases, model complexity decreases**. $k = 1$ is the most overfit model, since it simply memorizes the $(x_i, y_i)$ pairs in the dataset. In our first lecture example, as our hyperparameter (there, polynomial degree) increased, model complexity increased, too.\n",
    "\n",
    "Nice job! You've manually implemented every single calculation that produced the results above. In the last homework, you implemented the regressor yourself, and in this homework you cross-validated it yourself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25854ff0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Question 3: In This Economy? üè°\n",
    "\n",
    "---\n",
    "\n",
    "In this question, you'll put your understanding of `sklearn` Pipeline objects and cross-validation to practical use as you aim to predict housing prices. The dataset we're using, originally compiled by Professor Dean De Cock at Truman State University **specifically for** teaching regression, contains information about houses sold in Ames, Iowa from 2006 to 2010.\n",
    "\n",
    "Run the cell below to load in a **subset of the full dataset, which we've designated as your training set**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffb26e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "houses_training = pd.read_csv('data/houses-training.csv')\n",
    "houses_training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcfbccc",
   "metadata": {},
   "source": [
    "There are 82 columns in the dataset! `'SalePrice'` is what we're aiming to predict; everything else _could_ be used as a feature. You'll notice there are some categorical features (some ordinal, some nominal) and some numeric features, and many missing values. Many of the features are self-explanatory, but some are not. Rather than trying to define each feature ourselves, we'll point you to the data description written by the curator of the dataset.\n",
    "\n",
    "<center><b>Read the data description <a href=\"https://jse.amstat.org/v19n3/decock/DataDocumentation.txt\">here</a>.</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536daabe",
   "metadata": {},
   "source": [
    "Before we build any models, as always, we should explore the data.\n",
    "\n",
    "In the cell below, draw a histogram depicting the distribution of `'SalePrice'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2ad0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb04f99f",
   "metadata": {},
   "source": [
    "In the cell below, draw a scatter plot of `'SalePrice'` vs. `'Gr Liv Area'` (which represents square footage, not including the basement)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e43322",
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ee79c4",
   "metadata": {},
   "source": [
    "Normally, we'd have you perform a train-test split. However, we've already done this for you, in that `houses_training` is just the training data for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9867d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_houses = houses_training.drop(columns=['SalePrice'])\n",
    "X_train_houses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1693a494",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_houses = houses_training['SalePrice']\n",
    "y_train_houses.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e92e61c",
   "metadata": {},
   "source": [
    "The test set's features are below. Note that there is no `'SalePrice'` column in this DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3699a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_houses = pd.read_csv('data/housing-test-X.csv')\n",
    "X_test_houses.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0732c99",
   "metadata": {},
   "source": [
    "The test set's actual `'SalePrice'` values (i.e., actual $y$-values) are **intentionally** hidden from you. You won't need them at all in Questions 3.1-3.3. In Question 3.4, you'll have the (optional) opportunity to enter a prediction competition, in which you engineer a model that minimizes testing mean squared error. If you enter, your predictions will be compared against the true `'SalePrice'` values in the test set.\n",
    "\n",
    "For now, let's just work with `X_train_houses` and `y_train_houses`.\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "   \n",
    "**A common issue last semester was that students would unknowingly use the argument `validate=False` or `validate=True` in various Pipeline-related function calls in this question, causing the Gradescope autograder to crash. Please avoid using the `validate` keyword argument here. (This will be easy to do if you _don't_ use ChatGPT to write all of your code!)**\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39e071a",
   "metadata": {},
   "source": [
    "### Question 3.1 [Autograded üíª] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">4 Points</div>\n",
    "\n",
    "To start, you'll build a `sklearn` Pipeline that does the following to predict `'SalePrice'`:\n",
    "\n",
    "- Creates a new feature that results from **adding** `'Gr Liv Area'` (non-basement square footage) and `'Total Bsmt SF'` (basement square footage). This is the total square footage of the house.\n",
    "- Creates degree-2 polynomial features from the total square footage feature defined above.\n",
    "- One hot encodes `'Neighborhood'`.\n",
    "- Fits a `LinearRegression` model.\n",
    "\n",
    "Complete the implementation of the function `create_pipe_sqft_and_neighborhood`, which takes in a DataFrame like `X_train_houses` and a Series like `y_train_houses` and returns a **fit** Pipeline that follows all of the steps above.\n",
    "\n",
    "Example behavior is given below.\n",
    "\n",
    "```python\n",
    ">>> pipe = create_pipe_sqft_and_neighborhood(X_train_houses, y_train_houses)\n",
    ">>> pipe\n",
    "```\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <img src=\"imgs/first-example-pipe.png\" width=400>\n",
    "\n",
    "```python\n",
    ">>> pipe.predict(pd.DataFrame([{\n",
    "    'Gr Liv Area': 2500,\n",
    "    'Total Bsmt SF': 1500,\n",
    "    'Neighborhood': 'CollgCr'\n",
    "}]))\n",
    "array([312269.07580775])\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "Some guidance:\n",
    "- Like in the Pipelines you created in Homework 8, all transformations should be done within the Pipeline ‚Äì you **cannot** preprocess the training data using vanilla `pandas` before creating your Pipeline!\n",
    "    - So, for instance, to create the total square footage feature, you should create a `FunctionTransformer` that takes in a DataFrame with two columns, adds those two columns, and returns a new DataFrame with a single column that contains the result. This `FunctionTransformer` should be part of a larger Pipeline whose next step is a `OneHotEncoder`.\n",
    "    - Remember, a `ColumnTransformer` ‚Äì which you can create easily using `make_column_transformer` ‚Äì is how you specify which transformations you want applied to which columns. In this particular case, you may want to make a (nested) Pipeline that does the two steps above (namely, the `FunctionTransformer` and `OneHotEncoder`), and then tell the `ColumnTransformer` that you want to use this nested Pipeline on just the two original square footage columns.\n",
    "    - If you try and preprocess the data using `pandas` before creating your final Pipeline, the example call to `pipe.predict` at the bottom of the cell below won't work.\n",
    "    - It's okay if the graphical representation of your Pipeline isn't exactly the same as ours.\n",
    "- Remember to set `include_bias=False` when creating `PolynomialFeatures` so that your model doesn't end up trying to create two intercept terms.\n",
    "- Remember to use `drop='first'` when using `OneHotEncoder` to avoid multicollinearity, and `handle_unknown='ignore'` so that your Pipeline doesn't error if we try to predict the `'SalePrice'` of a house in a `'Neighborhood'` we've never seen before.\n",
    "- You'll need to fill missing `'Total Bsmt SF'` values with 0. (There's only one house in `X_train` with this property; it likely just doesn't have a basement.) **Do this within your `FunctionTransformer` using `fillna(0)`, not by using `SimpleImputer`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d9ffa1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer, PolynomialFeatures, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def create_pipe_sqft_and_neighborhood(X_train_houses, y_train_houses):\n",
    "    ...\n",
    "\n",
    "# Feel free to change this input to make sure your function works correctly.\n",
    "# In particular, try changing X_train_houses and y_train_houses to something like\n",
    "# X_train_houses.head(20) and y_train_houses.head(20)!\n",
    "pipe = create_pipe_sqft_and_neighborhood(X_train_houses, y_train_houses)\n",
    "pipe\n",
    "# Once the above looks right, uncomment the expression below.\n",
    "# pipe.predict(pd.DataFrame([{\n",
    "#     'Gr Liv Area': 2500,\n",
    "#     'Total Bsmt SF': 1500,\n",
    "#     'Neighborhood': 'CollgCr'\n",
    "# }]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1922f8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q03_01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e053b53",
   "metadata": {},
   "source": [
    "### Question 3.2 [Autograded üíª] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">5 Points</div>\n",
    "\n",
    "Now, let's create a Pipeline that executes all of the steps that `create_pipe_sqft_and_neighborhood` does, but:\n",
    "\n",
    "1. Instead of fixing the degree of `PolynomialFeatures` to 2, try any possible degree from 1 to 5 (inclusive).\n",
    "2. Instead of using `LinearRegression`, use `Ridge`, i.e. $L_2$-regularized linear regression. Try regularization penalties $2^{-5}, 2^{-4}, ..., 2^{8}, 2^{9}$, plus $0$. (In class, we called the regularization penalty hyperparameter $\\lambda$, but `sklearn` calls it `alpha`.)\n",
    "\n",
    "The biggest difference here is that you need to use **cross-validation** to choose with polynomial degree and regularization penalty. Use `GridSearchCV` to do this; use the default number of folds. **Remember to tell `GridSearchCV` that you want the hyperparameter combination that yields the lowest mean squared error**; by default, this is not what it does!\n",
    "\n",
    "Complete the implementation of the function `create_pipe_cross_validated_degree_ridge`, which takes in a DataFrame like `X_train_houses` and a Series like `y_train_houses` and returns a **fit** Pipeline that follows all of the steps above.\n",
    "\n",
    "Example behavior is given below.\n",
    "\n",
    "```python\n",
    ">>> pipe_cv = create_pipe_cross_validated_degree_ridge(X_train_houses, y_train_houses)\n",
    ">>> pipe_cv\n",
    "```\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <img src=\"imgs/second-example-pipe.png\" width=400>\n",
    "\n",
    "```python\n",
    ">>> pipe_cv.predict(pd.DataFrame([{\n",
    "    'Gr Liv Area': 2500,\n",
    "    'Total Bsmt SF': 1500,\n",
    "    'Neighborhood': 'CollgCr'\n",
    "}]))\n",
    "array([304362.63752408])\n",
    "\n",
    "```\n",
    "\n",
    "Some guidance:\n",
    "- At some point, you'll need to create a grid of hyperparameters to pass to `GridSearchCV`. You'll need to supply this grid as a **dictionary**, mapping hyperparameter names to lists (or ranges) of values. When doing this, the hyperparameter names will be a bit more complicated than seen in lecture ‚Äì for instance, the `PolynomialFeatures` `degree` hyperparameter is a hyperparameter of a nested Pipeline, which itself is likely part of a `ColumnTransformer`, so the key for the degree will likely look something like `'columntransformer__pipeline__ ...'`.\n",
    "- If you're getting the wrong output for the example prediction above, verify that you've set the `scoring` argument of `GridSearchCV` correctly.\n",
    "- `create_pipe_cross_validated_degree_ridge` shouldn't run instantly ‚Äì it may take ~5 seconds to run. This means that `grader.check(\"q03_02\")` won't run instantly either; it may take ~20 seconds to run.\n",
    "- Once again, fill in the lone missing `'Total Bsmt SF'` value within your `FunctionTransformer` using `fillna(0)`, not by using `SimpleImputer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcccede",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "def create_pipe_cross_validated_degree_ridge(X_train_houses, y_train_houses):\n",
    "    ...\n",
    "\n",
    "# Feel free to change this input to make sure your function works correctly.\n",
    "pipe_cv = create_pipe_cross_validated_degree_ridge(X_train_houses, y_train_houses)\n",
    "pipe_cv\n",
    "# Once the above looks right, uncomment the expression below.\n",
    "# pipe_cv.predict(pd.DataFrame([{\n",
    "#     'Gr Liv Area': 2500,\n",
    "#     'Total Bsmt SF': 1500,\n",
    "#     'Neighborhood': 'CollgCr'\n",
    "# }]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d66d03",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q03_02\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf86aac4",
   "metadata": {},
   "source": [
    "### Question 3.3 [Autograded üíª] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">4 Points</div>\n",
    "\n",
    "So far, we've only used a small subset of the features in `X_train_houses`. But, there are significantly more!\n",
    "\n",
    "For our final Pipeline, you're required to use **all features in the dataset**. You'll need to handle numeric and categorical features separately; you can extract all of the numeric columns in a DataFrame using `df.select_dtypes('number')`, for example.\n",
    "\n",
    "- For **numeric features**:\n",
    "    - Very few columns have missing values. (For your own exploration, determine which columns these are.) One guess is that these values are missing when the house doesn't have one of those features, e.g. a missing `'Bsmt Half Bath'` must mean that the house doesn't have a basement half-bathroom. **So, use `SimpleImputer` to fill all of the missing numerical values with 0. Make sure to instantiate your `SimpleImputer` instance with `strategy='constant'`.**\n",
    "    - Then, one missing values are imputed, standardize all numeric features (and only numeric features!) using a `StandardScaler`.\n",
    "- For **categorical features**:\n",
    "    - There are many more missing values. **Use `SimpleImputer` to fill all of the missing values in a column with the _most frequently observed_ value in that column.**\n",
    "    - Then, one hot encode the resulting categorical columns, making sure to use the same arguments you did earlier to handle multicollinearity and unknown categories (`drop='first'` and `handle_unknown='ignore'`).\n",
    "    - Here, we are using **`SimpleImputer`** because it makes it easier to apply the imputation technique to groups of columns (one imputation strategy for all numeric columns, and one imputation strategy for all categorical columns), not individual columns like we did in 3.1 and 3.2.\n",
    "\n",
    "After you've created all of your features, fit a `Lasso` object. Use cross-validation to try different regularization penalties from $10^{0}, 10^{1}, ..., 10^{5}$, plus $0$; again, make sure `GridSearchCV` knows that you want the hyperparameter that minimizes mean squared error. Note the different range of hyperparameters as compared to before!\n",
    "\n",
    "Complete the implementation of the function `create_pipe_all_features_lasso`, which takes in a DataFrame like `X_train_houses` and a Series like `y_train_houses` and returns a **fit** Pipeline that follows all of the steps above.\n",
    "\n",
    "Example behavior is given below.\n",
    "\n",
    "```python\n",
    ">>> pipe_all = create_pipe_all_features_lasso(X_train_houses, y_train_houses)\n",
    ">>> pipe_all\n",
    "```\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <img src=\"imgs/third-example-pipe.png\" width=400>\n",
    "\n",
    "```python\n",
    ">>> pipe_all.predict(X_train_houses.head(1))\n",
    "array([174683.44773055])\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "Some guidance:\n",
    "- **Pipelines involving `Lasso` take significantly longer to `fit` than Pipelines involving `Ridge`.** This may be due to the fact that the LASSO objective function involves non-differentiable pieces that are harder to optimize. Eventually, when you call `create_pipe_all_features_lasso`, it may take ~1 minute to run.\n",
    "- To make sure that your transformations are working correctly without having to wait a minute each time you want to test them out, you may want to start by just providing a single regularization penalty hyperparameter for `GridSearchCV` to choose. Once that works without error, switch to providing the range specified above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c582c699",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "def create_pipe_all_features_lasso(X_train_houses, y_train_houses):\n",
    "    ...\n",
    "\n",
    "# Feel free to change this input to make sure your function works correctly.\n",
    "pipe_all = create_pipe_all_features_lasso(X_train_houses, y_train_houses)\n",
    "pipe_all\n",
    "# Once the above looks right, uncomment the expression below.\n",
    "# pipe_all.predict(X_train_houses.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213ad3a8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q03_03\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc31433c",
   "metadata": {},
   "source": [
    "We've now created three pipelines, all of which predict `'SalePrice'` using some combination of features in `X_train`. The Pipeline that uses **all** features has the lowest training mean squared error, by far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82585cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'pipe (3.1)': pipe, 'pipe_cv (3.2)': pipe_cv, 'pipe_all (3.3)': pipe_all}\n",
    "for model in models:\n",
    "    mse = mean_squared_error(y_train_houses, models[model].predict(X_train_houses))\n",
    "    print(f'Mean squared error for {model}: {mse:.2e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540e357c",
   "metadata": {},
   "source": [
    "But, it's still not clear which of the three Pipelines generalize best to unseen test data. While we used cross-validation to fit `pipe_cv` and `pipe_all`, we didn't directly compare them to one another when doing cross-validation, so it's _possible_ that `pipe_cv` generalizes better than `pipe_all`.\n",
    "\n",
    "Of course, we **do** have a test set that we could use to assess how well these Pipelines all generalize, but we can't give you access to it just yet.\n",
    "\n",
    "One last thing before Question 3.4: recall, LASSO (which we used in `pipe_all`) encourages **sparsity**, meaning that we should expect the coefficients of many features to end up being 0. We can see exactly which features had a coefficient of 0 in `pipe_all` here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a22736",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = pipe_all.best_estimator_[:-1].get_feature_names_out()\n",
    "coefficients = pipe_all.best_estimator_[-1].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b400365a",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = pd.Series(coefficients, index=feature_names)\n",
    "coefs[coefs == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1b4c07",
   "metadata": {},
   "source": [
    "So, LASSO was implicitly telling us **not** to use those features, if we care about building a model that generalizes well to unseen data! This feature selection process might be useful to you should you choose to complete Question 3.4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba9534a",
   "metadata": {},
   "source": [
    "### Optional: Question 3.4 [Autograded üíª] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">Extra Credit</div>\n",
    "\n",
    "**This part of the question is OPTIONAL, and just counts for extra credit!**\n",
    "\n",
    "In Questions 3.1 through 3.3, we specified exactly how you should create your Pipelines. But now, it's your job to choose features and transformations that make good, generalizable predictions.\n",
    "\n",
    "If you decide to complete Question 3.4, here's the process.\n",
    "1. Below, complete the implementation of the function `create_pipe_custom`, which takes in a DataFrame like `X_train_houses` and a Series like `y_train_houses` and returns a **fit** Pipeline, created however you'd like.\n",
    "2. Then, run the cell below so that `pipe_custom` is assigned to a a fit Pipeline.\n",
    "3. Run the three cells below this one, that starts with `# EXPORT CELL!`, to create a CSV of your Pipeline's predictions on the hidden test set.\n",
    "4. Upload the CSV created (it should be named something like `'predictions-2025-03.....csv'`) to the **Homework 9, Question 3.4 Leaderboard (Optional!)** autograder on Gradescope.\n",
    "5. Ignore the \"score\" that appears on Gradescope, since everyone receives a score of 0 ‚Äì all that matters is your ranking on the leaderboard, linked [**here**](https://www.gradescope.com/courses/930446/assignments/5994908/leaderboard). **The rankings are computed using your mean squared error on the unseen testing set; the lower the MSE, the higher your ranking.**\n",
    "6. The top 5 **good-faith** submissions on the leaderboard will receive extra credit on Homework 9 as follows:\n",
    "    - The top submission ‚Äì that is, the one with the lowest MSE ‚Äì will earn 10 points of extra credit on Homework 9. Since the homework is out of 39 points, this equates to around **25% of extra credit**.\n",
    "    - The 2nd-best submission will earn 8 extra points on Homework 9 ($\\approx$20% of extra credit).\n",
    "    - The 3rd-best submission will earn 6 extra points on Homework 9 ($\\approx$15% of extra credit).\n",
    "    - The 4th-best submission will earn 4 extra points on Homework 9 ($\\approx$10% of extra credit).\n",
    "    - The 5th-best submission will earn 2 extra points on Homework 9 ($\\approx$5% of extra credit).\n",
    "     \n",
    "Some guidance:\n",
    "- You can use _any_ regression class **in `sklearn`** to make your predictions. By **good-faith submission**, we mean a submission that doesn't somehow determine the true $y$-values in the test set and hardcodes them, and a submission that is unique, i.e. not copied from someone else (that would, of course, be an honor code violation) or from a Kaggle competition online. Before assigning extra credit, we will manually inspect your submitted notebook (which you need to submit anyways for the rest of the homework to be graded), and any submissions that don't use an `sklearn` Pipeline will not receive the extra credit.\n",
    "- Don't just guess arbitrarily which features might be useful and how to engineer them. **Do some exploratory data analysis!** Look at the relationships between various features and `'SalePrice'`. You might discover various new features you want to engineer.\n",
    "- For reference, you'll find a submission titled **Submitted by Suraj: Baseline Model from Question 3.3** on the leaderboard. This shows you the test MSE of the Pipeline that `create_pipe_all_features_lasso` achieves. Your model's MSE should be lower than this!\n",
    "- Have fun with it, and use what you've learned in this question to improve your models in the Portfolio Homework!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160e9a03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_pipe_custom(X_train_houses, y_train_houses):\n",
    "    ...\n",
    "\n",
    "# Make sure this has been run before you try and run the export cell below!\n",
    "pipe_custom = create_pipe_custom(X_train_houses, y_train_houses)\n",
    "pipe_custom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6d8e13",
   "metadata": {},
   "source": [
    "Once you've implemented `create_pipe_custom` and defined `pipe_custom` at the bottom of the cell above, run the cell below to generate your CSV of test set predictions. Upload this CSV to the Gradescope assignment titled **Homework 9, Question 3.4 Leaderboard (Optional!)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc37260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPORT CELL!\n",
    "\n",
    "import datetime\n",
    "current_time = str(datetime.datetime.now())[:19]\n",
    "\n",
    "y_pred = pipe_custom.predict(X_test_houses)\n",
    "y_pred_df = pd.DataFrame().assign(predictions=y_pred)\n",
    "y_pred_df.to_csv(f'test-predictions-{current_time}.csv', index=False)\n",
    "print(f'Saved test-predictions-{current_time}.csv; upload this to Gradescope.') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc5268b",
   "metadata": {},
   "source": [
    "## Finish Line üèÅ\n",
    "\n",
    "Congratulations! You're ready to submit Homework 9. **Remember, you need to submit Homework 9 twice (or three times, if you're participating in the optional competition for Question 3.4)**:\n",
    "\n",
    "### To submit the manually graded problem (Question 1; marked [Written ‚úèÔ∏è])\n",
    "\n",
    "- Make sure your answers **are not** in this notebook, but rather in a separate PDF.\n",
    "    - You can create this PDF either digitally, using your tablet or using [Overleaf + LaTeX](https://overleaf.com) (or some other sort of digital document), or by writing your answers on a piece of paper and scanning them in.\n",
    "- Submit this separate PDF to the **Homework 9 (Question 1; written problem)** assignment on Gradescope, and **make sure to correctly select the pages associated with each question**!\n",
    "\n",
    "### To submit the autograded problems (Questions 2-3; marked [Autograded üíª])\n",
    "\n",
    "1. Select `Kernel -> Restart & Run All` to ensure that you have executed all cells, including the test cells.\n",
    "2. Read through the notebook to make sure everything is fine and all tests passed.\n",
    "3. Run the cell below to run all tests, and make sure that they all pass.\n",
    "4. Download your notebook using `File -> Download as -> Notebook (.ipynb)`, then upload your notebook to Gradescope under \"Homework 9 (Questions 2-3; autograded problems)\". Make sure your notebook is still named `hw09.ipynb` and the name has not been changed.\n",
    "5. Stick around while the Gradescope autograder grades your work.\n",
    "6. Check that you have a confirmation email from Gradescope and save it as proof of your submission.\n",
    "\n",
    "Your Homework 9 submission time will be the **later** of your two individual submissions.\n",
    "\n",
    "### To submit to the optional prediction competition (Question 3.4)\n",
    "See the details in Question 3.4."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "otter": {
   "tests": {
    "q02_01": {
     "name": "q02_01",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> X_train.shape == (90, 1) and X_test.shape == (30, 1)\nTrue",
         "failure_message": "X_train and/or X_test have wrong shape. Make sure you provided the correct arguments to train_test_split.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> y_train.shape == (90,) and y_test.shape == (30,)\nTrue",
         "failure_message": "y_train and/or y_test have wrong shape. Make sure you provided the correct arguments to train_test_split.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> X_train.index[0] == 16\nTrue",
         "failure_message": "X_train has the wrong values. Make sure you provided the correct arguments to train_test_split.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q02_02": {
     "name": "q02_02",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> out = cross_validate_model(KNeighborsRegressor(2), X_train, y_train, 10)\n>>> column_cond = out.shape[0] == 10 and np.all(out.columns == ['training_mse', 'validation_mse'])\n>>> index_cond = np.all(out.index == ['Fold 0', 'Fold 1', 'Fold 2', 'Fold 3', 'Fold 4', 'Fold 5', 'Fold 6', 'Fold 7', 'Fold 8', 'Fold 9'])\n>>> column_cond and index_cond\nTrue",
         "failure_message": "cross_validate_model(KNeighborsRegressor(2), X_train, y_train, 10) has the wrong shape or row/column labels.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.allclose(cross_validate_model(KNeighborsRegressor(2), X_train, y_train, 10)['training_mse'].to_numpy(), np.array([44926.43209877, 52946.63580247, 47598.12962963, 54323.26234568,\n...        67494.19444444, 49634.17592593, 55767.96604938, 54990.52469136,\n...        55223.45679012, 52366.0617284 ]))\nTrue",
         "failure_message": "cross_validate_model(KNeighborsRegressor(2), X_train, y_train, 10) returns incorrect training errors.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.allclose(cross_validate_model(KNeighborsRegressor(2), X_train, y_train, 10)['validation_mse'].to_numpy(), np.array([281430.63888889,  99437.97222222, 119365.75      , 115330.55555556,\n...         77006.08333333, 281051.19444444,  50324.75      , 373829.11111111,\n...         73802.88888889,  97442.91666667]))\nTrue",
         "failure_message": "cross_validate_model(KNeighborsRegressor(2), X_train, y_train, 10) returns incorrect validation errors.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.allclose(cross_validate_model(KNeighborsRegressor(2), X_train, y_train, 2).to_numpy(), np.array([[ 86991.12777778, 124091.48888889],\n...        [ 52433.12777778, 169540.15555556]]))\nTrue",
         "failure_message": "cross_validate_model(KNeighborsRegressor(2), X_train, y_train, 2) returns incorrect values.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> from sklearn.linear_model import Ridge\n>>> np.allclose(cross_validate_model(Ridge(1000), X_train.head(50), y_train.head(50), 5)['validation_mse'].to_numpy(), np.array([169596.07353481, 152721.60454732, 201780.76668572,  67532.17032927, 490205.04732094]))\nTrue",
         "failure_message": "cross_validate_model(Ridge(1000, X_train.head(50), y_train.head(50), 5) returns incorrect values.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q02_03": {
     "name": "q02_03",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> fig = plot_validation_error_vs_k(20, X_train, y_train, 5)\n>>> \n>>> def determine_trace_order(fig):\n...     train_fig, valid_fig = 10, 10\n...     if 'training' in fig.data[0].name.lower():\n...         train_fig = 0\n...         if 'validation' in fig.data[1].name.lower():\n...             valid_fig = 1\n...     elif 'validation' in fig.data[0].name.lower():\n...         valid_fig = 0\n...         if 'training' in fig.data[1].name.lower():\n...             train_fig = 1\n...     return train_fig, valid_fig\n>>> \n>>> sum(determine_trace_order(fig)) == 1 and len(fig.data) == 2\nTrue",
         "failure_message": "Figure has wrong number of lines (should just be 2), or the lines are not named correctly in the legend. One must have 'training' in the name, and one must have 'validation' in the name.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> fig = plot_validation_error_vs_k(20, X_train, y_train, 5)\n>>> fig.layout['xaxis']['title']['text'].lower() == 'Number of Neighbors (k)'.lower() and fig.layout['yaxis']['title']['text'].lower() == 'Mean Squared Error'.lower()\nTrue",
         "failure_message": "Figure has incorrect x-axis and y-axis title names.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> fig = plot_validation_error_vs_k(20, X_train, y_train, 5)\n>>> \n>>> def determine_trace_order(fig):\n...     train_fig, valid_fig = 10, 10\n...     if 'training' in fig.data[0].name.lower():\n...         train_fig = 0\n...         if 'validation' in fig.data[1].name.lower():\n...             valid_fig = 1\n...     elif 'validation' in fig.data[0].name.lower():\n...         valid_fig = 0\n...         if 'training' in fig.data[1].name.lower():\n...             train_fig = 1\n...     return train_fig, valid_fig\n>>> \n>>> train_fig, valid_fig = determine_trace_order(fig)\n>>> \n>>> np.allclose(fig.data[train_fig]['y'], np.array([     0.        ,  53605.66388889,  78621.0845679 ,  88385.11388889,\n...        100214.17233333, 108384.05393519, 114572.27403628, 118820.24344618,\n...        124965.58631687, 128129.69688889, 134285.78078512, 137770.38809799,\n...        142542.68852728, 152179.06730442, 160592.81718519, 171506.90482856,\n...        180790.57218378, 190813.3534808 , 205984.38451062, 222539.62752083]))\nTrue",
         "failure_message": "Figure has incorrect average training MSEs.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> fig = plot_validation_error_vs_k(20, X_train, y_train, 5)\n>>> \n>>> def determine_trace_order(fig):\n...     train_fig, valid_fig = 10, 10\n...     if 'training' in fig.data[0].name.lower():\n...         train_fig = 0\n...         if 'validation' in fig.data[1].name.lower():\n...             valid_fig = 1\n...     elif 'validation' in fig.data[0].name.lower():\n...         valid_fig = 0\n...         if 'training' in fig.data[1].name.lower():\n...             train_fig = 1\n...     return train_fig, valid_fig\n>>> \n>>> train_fig, valid_fig = determine_trace_order(fig)\n>>> \n>>> np.allclose(fig.data[valid_fig]['y'], np.array([233564.38888889, 160560.18611111, 143312.03950617, 158382.74583333,\n...        161596.71911111, 160195.15154321, 161447.35079365, 159014.9234375 ,\n...        159172.84485597, 160115.67944444, 161904.81698806, 172847.2625    ,\n...        180872.20131492, 188895.29518141, 197566.22602469, 211492.31150174,\n...        225739.78539023, 242449.2867284 , 255399.14598338, 266290.63647222]))\nTrue",
         "failure_message": "Figure has incorrect average validation MSEs.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q03_01": {
     "name": "q03_01",
     "points": 4,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> houses_training = pd.read_csv('data/houses-training.csv')\n>>> X_train_houses, y_train_houses = houses_training.drop(columns=['SalePrice']), houses_training['SalePrice']\n>>> pipe = create_pipe_sqft_and_neighborhood(X_train_houses, y_train_houses)\n>>> steps = pipe.steps\n>>> 'FunctionTransformer' in str(steps[0]) and 'OneHotEncoder' in str(steps[0]) and 'PolynomialFeatures' in str(steps[0]) \nTrue",
         "failure_message": "create_pipe_sqft_and_neighborhood(X_train_houses, y_train_houses) is missing some steps. Make sure you have FunctionTransformer, OneHotEncoder, and PolynomialFeatures steps!",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> houses_training = pd.read_csv('data/houses-training.csv')\n>>> X_train_houses, y_train_houses = houses_training.drop(columns=['SalePrice']), houses_training['SalePrice']\n>>> pipe = create_pipe_sqft_and_neighborhood(X_train_houses, y_train_houses)\n>>> steps = pipe.steps\n>>> 'LinearRegression' in str(steps[1])\nTrue",
         "failure_message": "create_pipe_sqft_and_neighborhood(X_train_houses, y_train_houses) is missing a LinearRegression step at the end.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> houses_training = pd.read_csv('data/houses-training.csv')\n>>> X_train_houses, y_train_houses = houses_training.drop(columns=['SalePrice']), houses_training['SalePrice']\n>>> pipe = create_pipe_sqft_and_neighborhood(X_train_houses, y_train_houses)\n>>> np.isclose(pipe.predict(pd.DataFrame([{'Gr Liv Area': 2500, 'Total Bsmt SF': 1500, 'Neighborhood': 'CollgCr'}]))[0], 312269.07580775)\nTrue",
         "failure_message": "create_pipe_sqft_and_neighborhood(X_train_houses, y_train_houses) returns the wrong prediction for the example in the question description.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> houses_training = pd.read_csv('data/houses-training.csv')\n>>> X_train_houses, y_train_houses = houses_training.drop(columns=['SalePrice']), houses_training['SalePrice']\n>>> pipe = create_pipe_sqft_and_neighborhood(X_train_houses, y_train_houses)\n>>> pipe[:-1].transform(X_train_houses).shape == (2193, 29)\nTrue",
         "failure_message": "create_pipe_sqft_and_neighborhood(X_train_houses, y_train_houses) creates the wrong number of features (expecting 29).",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> houses_training = pd.read_csv('data/houses-training.csv')\n>>> X_train_houses, y_train_houses = houses_training.drop(columns=['SalePrice']), houses_training['SalePrice']\n>>> pipe = create_pipe_sqft_and_neighborhood(X_train_houses, y_train_houses)\n>>> np.isclose(pipe.predict(pd.DataFrame([{'Gr Liv Area': 1000, 'Total Bsmt SF': 2500, 'Neighborhood': 'Ann Arbor'}]))[0], 259485.13875211187)\nTrue",
         "failure_message": "create_pipe_sqft_and_neighborhood(X_train_houses, y_train_houses) returns the wrong prediction for an example neighborhood that was not in the training set.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q03_02": {
     "name": "q03_02",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> houses_training = pd.read_csv('data/houses-training.csv')\n>>> X_train_houses, y_train_houses = houses_training.drop(columns=['SalePrice']), houses_training['SalePrice']\n>>> pipe_cv = create_pipe_cross_validated_degree_ridge(X_train_houses, y_train_houses)\n>>> steps = pipe_cv.best_estimator_.steps\n>>> 'Ridge' in str(steps[1])\nTrue",
         "failure_message": "create_pipe_cross_validated_degree_ridge(X_train_houses, y_train_houses)'s best_estimator_ is missing a Ridge step at the end.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> houses_training = pd.read_csv('data/houses-training.csv')\n>>> X_train_houses, y_train_houses = houses_training.drop(columns=['SalePrice']), houses_training['SalePrice']\n>>> pipe_cv = create_pipe_cross_validated_degree_ridge(X_train_houses, y_train_houses)\n>>> np.isclose(pipe_cv.predict(pd.DataFrame([{'Gr Liv Area': 2500, 'Total Bsmt SF': 1500, 'Neighborhood': 'CollgCr'}]))[0], 304362.63752408)\nTrue",
         "failure_message": "create_pipe_cross_validated_degree_ridge(X_train_houses, y_train_houses) returns the wrong prediction for the example in the question description.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> houses_training = pd.read_csv('data/houses-training.csv')\n>>> X_train_houses, y_train_houses = houses_training.drop(columns=['SalePrice']), houses_training['SalePrice']\n>>> pipe_cv = create_pipe_cross_validated_degree_ridge(X_train_houses, y_train_houses)\n>>> len(pipe_cv.cv_results_['params']) == 80\nTrue",
         "failure_message": "create_pipe_cross_validated_degree_ridge(X_train_houses, y_train_houses) tests the wrong number of hyperparameter combinations.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> houses_training = pd.read_csv('data/houses-training.csv')\n>>> X_train_houses, y_train_houses = houses_training.drop(columns=['SalePrice']), houses_training['SalePrice']\n>>> pipe_cv = create_pipe_cross_validated_degree_ridge(X_train_houses, y_train_houses)\n>>> np.isclose(pipe_cv.predict(pd.DataFrame([{'Gr Liv Area': 2198, 'Total Bsmt SF': 3000, 'Neighborhood': 'Sawyer'}]))[0], 366274.4234519357)\nTrue",
         "failure_message": "create_pipe_cross_validated_degree_ridge(X_train_houses, y_train_houses) returns the wrong prediction for an arbitrary input.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> houses_training = pd.read_csv('data/houses-training.csv')\n>>> X_train_houses, y_train_houses = houses_training.drop(columns=['SalePrice']), houses_training['SalePrice']\n>>> pipe_cv_sample = create_pipe_cross_validated_degree_ridge(X_train_houses.tail(25), y_train_houses.tail(25))\n>>> np.isclose(pipe_cv_sample.predict(pd.DataFrame([{'Gr Liv Area': 2500, 'Total Bsmt SF': 1500, 'Neighborhood': 'CollgCr'}]))[0], 273815.4075387019)\nTrue",
         "failure_message": "create_pipe_cross_validated_degree_ridge(X_train_houses.tail(25), y_train_houses.tail(25)) returns the wrong prediction for the example in the question description.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> from sklearn.metrics import mean_squared_error\n>>> houses_training = pd.read_csv('data/houses-training.csv')\n>>> X_train_houses, y_train_houses = houses_training.drop(columns=['SalePrice']), houses_training['SalePrice']\n>>> pipe_cv_sample = create_pipe_cross_validated_degree_ridge(X_train_houses.tail(25), y_train_houses.tail(25))\n>>> np.isclose(mean_squared_error(y_train_houses.tail(25), pipe_cv_sample.predict(X_train_houses.tail(25))), 448728114.5642506)\nTrue",
         "failure_message": "create_pipe_sqft_and_neighborhood(X_train_houses.tail(25), y_train_houses.tail(25)) has the wrong training mean squared error.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q03_03": {
     "name": "q03_03",
     "points": 4,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> houses_training = pd.read_csv('data/houses-training.csv')\n>>> X_train_houses, y_train_houses = houses_training.drop(columns=['SalePrice']), houses_training['SalePrice']\n>>> pipe_all = create_pipe_all_features_lasso(X_train_houses, y_train_houses)\n>>> steps = pipe_all.best_estimator_.steps\n>>> 'Lasso' in str(steps[1]) and pipe_all.best_estimator_[:-1].transform(X_train_houses).shape == (2193, 252)\nTrue",
         "failure_message": "create_pipe_all_features_lasso(X_train_houses, y_train_houses)'s best_estimator_ is missing a Lasso step at the end and/or creates the wrong number of features (expecting 252).",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> houses_training = pd.read_csv('data/houses-training.csv')\n>>> X_train_houses, y_train_houses = houses_training.drop(columns=['SalePrice']), houses_training['SalePrice']\n>>> pipe_all = create_pipe_all_features_lasso(X_train_houses, y_train_houses)\n>>> np.isclose(pipe_all.predict(X_train_houses.head(1))[0], 174683.44773055363)\nTrue",
         "failure_message": "create_pipe_all_features_lasso(X_train_houses, y_train_houses) returns the wrong prediction for the example in the question description.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> houses_training = pd.read_csv('data/houses-training.csv')\n>>> X_train_houses, y_train_houses = houses_training.drop(columns=['SalePrice']), houses_training['SalePrice']\n>>> pipe_all = create_pipe_all_features_lasso(X_train_houses, y_train_houses)\n>>> list(pipe_all.best_params_.values())[0] == 10.0 and len(pipe_all.cv_results_['params']) == 7\nTrue",
         "failure_message": "create_pipe_all_features_lasso(X_train_houses, y_train_houses) finds the wrong optimal hyperparameters and/or tests the wrong number of hyperparameter combinations.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> houses_training = pd.read_csv('data/houses-training.csv')\n>>> X_train_houses, y_train_houses = houses_training.drop(columns=['SalePrice']), houses_training['SalePrice']\n>>> pipe_all = create_pipe_all_features_lasso(X_train_houses, y_train_houses)\n>>> np.isclose(pipe_all.predict(X_train_houses.iloc[[23]])[0], 38465.22064756334)\nTrue",
         "failure_message": "create_pipe_all_features_lasso(X_train_houses, y_train_houses) returns the wrong prediction for an arbitrary input.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
