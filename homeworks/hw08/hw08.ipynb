{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca86aa58",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"hw08.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b888ed6",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" markdown=\"1\">\n",
    "\n",
    "#### Homework 8\n",
    "\n",
    "# Feature Engineering and Pipelines\n",
    "\n",
    "### EECS 398: Practical Data Science, Winter 2025\n",
    "\n",
    "#### Due Wednesday, March 26th at 11:59PM (one day later than usual)\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a2c499",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "Welcome to Homework 8! In this homework, you'll learn how to create new features for model building using both `pandas` and `sklearn`, as well as how to expand on this by building `sklearn` modeling Pipelines. The most relevant lectures are Lectures 16 and 17.\n",
    "\n",
    "You are given **eight** slip days throughout the semester to extend deadlines. See the [Syllabus](https://practicaldsc.org/syllabus) for more details. With the exception of using slip days, late work will not be accepted unless you have made special arrangements with your instructor.\n",
    "\n",
    "To access this notebook, you'll need to clone our [public GitHub repository](https://github.com/practicaldsc/wn25/). The [Environment Setup](https://practicaldsc.org/env-setup) page on the course website walks you through the necessary steps.\n",
    "<div class=\"alert alert-warning\" markdown=\"1\">\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "This homework features a mix of autograded programming questions and manually-graded questions.\n",
    "    \n",
    "- Questions 1.4, 3, and 4 are **manually graded**, like in Homework 7, and say **[Written ‚úèÔ∏è]** in the title. For these questions, **do not write your answers in this notebook**! Instead, like in Homework 7, write **all** of your answers to the questions in this homework in a separate PDF. You can create this PDF either digitally, using your tablet or using [Overleaf + LaTeX](https://overleaf.com) (or some other sort of digital document), or by writing your answers on a piece of paper and scanning them in. Submit this separate PDF to the **Homework 8 (Questions 1.4, 3-4; written problems)** assignment on Gradescope, and **make sure to correctly select the pages associated with each question**!\n",
    "\n",
    "- Questions 1.1-1.3 and 2 are **fully autograded**, and say **[Autograded üíª]** in the title. For these questions, all you need to is write your code in this notebook, run the local `grader.check` tests, and submit to the **Homework 8 (Questions 1.1-1.3, 2; autograder problems)** assignment on Gradescope to have your code graded by the hidden autograder. This is the same workflow you followed in earlier homeworks.\n",
    "\n",
    "Your Homework 8 submission time will be the **later** of your two individual submissions.\n",
    "</div>\n",
    "</div>\n",
    "\n",
    "**Make sure to show your work for all written questions! Answers without work shown may not receive full credit.**\n",
    "\n",
    "This homework is worth a total of **46 points**, 23 of which are manually graded and 23 of which come from the autograder. The number of points each question is worth is listed at the start of each question. **All questions in the assignment are independent, so feel free to move around if you get stuck**, but keep in mind that you'll need to submit this homework twice ‚Äì one submission for your written problems, and one submission for your autograded problems. Tip: if you're using Jupyter Lab, you can see a Table of Contents for the notebook by going to View > Table of Contents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d959cd71",
   "metadata": {},
   "source": [
    "To get started, run the cell below, plus the cell at the top of the notebook that imports and initializes `otter`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e003d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "\n",
    "# Preferred styles\n",
    "pio.templates[\"pds\"] = go.layout.Template(\n",
    "    layout=dict(\n",
    "        margin=dict(l=30, r=30, t=30, b=30),\n",
    "        autosize=True,\n",
    "        width=600,\n",
    "        height=400,\n",
    "        xaxis=dict(showgrid=True),\n",
    "        yaxis=dict(showgrid=True),\n",
    "        title=dict(x=0.5, xanchor=\"center\"),\n",
    "    )\n",
    ")\n",
    "pio.templates.default = \"simple_white+pds\"\n",
    "\n",
    "# Use plotly as default plotting engine\n",
    "pd.options.plotting.backend = \"plotly\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c59a901",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Question 1: Play Ball ‚öæÔ∏è\n",
    "\n",
    "---\n",
    "\n",
    "In this question, you'll get a feel for the process of creating new features from existing ones and how to _think_ about model generalizability, an idea we'll see more in Lectures 18 onwards.\n",
    "\n",
    "As we discussed in Lecture 16, a numerical-to-numerical transformation results from taking the values in some numerical column $x_1, x_2, ..., x_n$ and applying some function $f$ to each value, to produce a new set of numbers $f(x_1), f(x_2), ..., f(x_n)$. These **transformed** values, $f(x_1), f(x_2), ..., f(x_n)$, can then either be used as a feature, or as the target ($y$) variable.\n",
    "\n",
    "A common goal of applying a numerical-to-numerical transformation is to modify the data from a complicated, non-linear relationship into a **linear** relationship. Linear relationships are easy to understand and are well-described using linear models.\n",
    "\n",
    "However, non-linear growth is common in real-world datasets. Sometimes this growth is by a **fixed power** and sometimes it is **exponential**. The transformation functions, $f$, that turn these types of growth linear are **root** and **log** transformations respectively. (Generally, it is more difficult to determine which transformation is appropriate for a given dataset, though the [Tukey-Mosteller bulge diagram](https://freakonometrics.hypotheses.org/files/2014/06/Selection_005.png) from Lecture 16 is useful.)\n",
    "\n",
    "Let's start by looking at some examples of transformations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddb6666",
   "metadata": {},
   "source": [
    "### Example 1\n",
    "\n",
    "Run the cell below to generate a scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8654e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# By setting a seed, we guarantee that we will see the same results each time we run this cell.\n",
    "np.random.seed(23)\n",
    "\n",
    "# Generates a random scatter plot\n",
    "x = np.arange(1, 101) + np.random.normal(0, 0.5, 100)\n",
    "y = 2 * ((x + np.random.normal(0, 1, 100)) ** 2) + np.abs(x) * np.random.normal(0, 30, 100)\n",
    "df_1 = pd.DataFrame().assign(x=x, y=y)\n",
    "\n",
    "px.scatter(df_1, x='x', y='y', trendline=\"ols\", trendline_color_override=\"#ff7f0e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e0c15c",
   "metadata": {},
   "source": [
    "It doesn't appear to be the case that `'x'` and `'y'` are linearly associated here, and they aren't ‚Äì there is a **quadratic** relationship between them. \n",
    "\n",
    "One way we may be able to notice this is a **residual plot**, where we visualize the residuals (or errors), $e_i = y_i - H^*(x_i)$, as defined in Question 1. Note that if we were to create a **residual plot** based on the data above, there would be a pattern ‚Äì the residuals for smaller `'x'` would mostly be positive, and the residuals for larger `'x'` would mostly be negative. Patterns in a residual plot imply that the relationship between the two variables is non-linear.\n",
    "\n",
    "Let's take a look at the residual plot, using a helper function defined below. This function fits a `LinearRegression` model to `'x'` and `'y'`, adds a `'residuals'` column to the `df`, and plots that against the predictions `'pred'`. Note that it's equally valid to plot the residuals against `'x'`: to do that, change `x = 'pred'` to `x = x` in the call to `px.scatter` below. You'll see the trend is the same, but the x-axis will have different numbers. That's because `'pred'` is just a linear transformation of `'x'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7df4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to use this function directly to help you answer Question 1.\n",
    "def create_residual_plot(df, x, y):\n",
    "    df = df.copy()\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    model = LinearRegression()\n",
    "    model.fit(df[[x]], df[y])\n",
    "    df['pred'] = model.predict(df[[x]])\n",
    "    df[f'{y} residuals'] = df[y] - model.predict(df[[x]])\n",
    "    return px.scatter(df, x='pred', y=f'{y} residuals', trendline='ols', trendline_color_override='red')\n",
    "\n",
    "create_residual_plot(df_1, 'x', 'y')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ea757e",
   "metadata": {},
   "source": [
    "To linearize the relationship, we can take the square root of each `'y'` value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5831b911",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1['root y'] = np.sqrt(df_1['y'])\n",
    "\n",
    "px.scatter(df_1, x='x', y='root y', trendline=\"ols\", trendline_color_override=\"#ff7f0e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be69f65",
   "metadata": {},
   "source": [
    "That looks much better!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61dc8b3",
   "metadata": {},
   "source": [
    "### Example 2\n",
    "\n",
    "Run the cell below to generate another scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c92e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# By setting a seed, we guarantee that we will see the same results each time we run this cell\n",
    "np.random.seed(32)\n",
    "\n",
    "# Generates a different random scatter plot\n",
    "x = np.linspace(2, 5, 100)\n",
    "y = 10 * (np.e ** x) + np.abs(x) * np.random.normal(0, 5, 100) + np.random.normal(0, 30, 100)\n",
    "df_2 = pd.DataFrame().assign(x=x, y=y)\n",
    "\n",
    "px.scatter(df_2, x='x', y='y', trendline=\"ols\", trendline_color_override=\"#ff7f0e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328e4e4e",
   "metadata": {},
   "source": [
    "Again, the relationship between `'x'` and `'y'` is not quite linear. Let's try the square root transformation we tried in Example 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f3a25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2['root y'] = np.sqrt(df_2['y'])\n",
    "\n",
    "px.scatter(df_2, x='x', y='root y', trendline=\"ols\", trendline_color_override=\"#ff7f0e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c906d0d",
   "metadata": {},
   "source": [
    "Hmm... the relationship certainly looks _more_ linear than before, but still not quite linear. Let's look at the residual plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caaa999d",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_residual_plot(df_2, 'x', 'root y')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15096782",
   "metadata": {},
   "source": [
    "There is clearly a pattern in the residual plot. Let's instead try another transformation for the `'y'` values ‚Äì $\\log$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ea783e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2['log y'] = np.log(df_2['y'])\n",
    "\n",
    "px.scatter(df_2, x='x', y='log y', trendline=\"ols\", trendline_color_override=\"#ff7f0e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6383011e",
   "metadata": {},
   "source": [
    "That looks much better! We can verify that the residual plot has no \"patterns\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2135a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_residual_plot(df_2, 'x', 'log y')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f07493a",
   "metadata": {},
   "source": [
    "Note ‚Äì there is still evidence of **heteroscedasticity**, or \"uneven spread\", in this scatter plot, but the relationship is as close to linear as we'll get."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4360df",
   "metadata": {},
   "source": [
    "Now that we've learned how to perform transformations with example datasets, it's your job to apply these ideas to a real dataset. Below, we load in a dataset that describes the [number of home runs in the MLB per year](https://www.mlb.com/glossary/standard-stats/home-run). The relationship between the two variables, `'Year'` and `'Homeruns'`, is not linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa8a811",
   "metadata": {},
   "outputs": [],
   "source": [
    "homeruns = pd.read_csv('data/homeruns.csv')\n",
    "homeruns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2455e1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "homeruns.plot(kind='scatter', x='Year', y='Homeruns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b570be",
   "metadata": {},
   "source": [
    "**Throughout this entire question**, suppose we're modeling `'Homeruns'` as a function of `'Year'`, i.e. `'Homeruns'` is the $y$ variable and `'Year'` is the $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030872e2",
   "metadata": {},
   "source": [
    "### Question 1.1 [Autograded üíª] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">3 Points</div>\n",
    "\n",
    "**Your first job is to determine what the appropriate transformation to apply to the `'Homeruns'` column is, in order to linearize the relationship.** Specifically, try out the transformations below, and then draw and examine residual plots to identify which numerical-to-numerical transformation is best.\n",
    "\n",
    "While you'll have to write a bunch of code, this is a multiple-choice question. Assign `best_transformation` to either 1, 2, 3, or 4, with the value corresponding to one of the following choices:\n",
    "\n",
    "1. Square root transformation.\n",
    "2. Log transformation.\n",
    "3. Both work the same.\n",
    "4. Neither gives a transformation revealing a linear relationship.\n",
    "\n",
    "If you find that both residual plots have some sort of pattern, choose the residual plot in which the vertical spread is constant. There is one clearly correct answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0b9159",
   "metadata": {
    "tags": [
     "to-py"
    ]
   },
   "outputs": [],
   "source": [
    "best_transformation = ...\n",
    "best_transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2de8f3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q01_01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0759155d",
   "metadata": {},
   "source": [
    "### Question 1.2 [Autograded üíª] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">5 Points</div>\n",
    "\n",
    "Recall, our goal in this question is to model `'Homeruns'` as a function of `'Year'`. In the previous part, we had you apply a numerical-to-numerical transformation to `'Homeruns'`, which is the $y$ variable.\n",
    "\n",
    "In this part, you'll be required to engineer new quantitative features **of your own choosing**, all based on transformations of the $x$ variable, `'Year'`.\n",
    "\n",
    "Complete the implementation of the function `fit_model_and_return_predictions`, which takes in:\n",
    "- `X`, a DataFrame with a single column of `'Year'` values from `homeruns`, and\n",
    "- `y`, an array or Series with a sequence of `'Homerun'` values from `homeruns`.\n",
    "\n",
    "`fit_model_and_return_predictions` should:\n",
    "- Create new numerical features by applying various transformations to the values in `X['Year']` (look at Question 5 in Homework 7 for inspiration),\n",
    "- Fit a `sklearn` LinearRegression object using your custom design matrix as the `X` argument and our passed-in `y` as the `y` argument, and\n",
    "- **Return an array of predictions** that result from calling the `predict` method on the fit model, using your custom design matrix as the `X` argument.\n",
    "\n",
    "For example, suppose our `fit_model_and_return_predictions` function creates polynomial features of degrees 2 through 10, and adds no other new features. Example behavior of `fit_model_and_return_predictions` may then be as follows:\n",
    "\n",
    "```python\n",
    ">>> fit_model_and_return_predictions(homeruns[['Year']], homeruns['Homeruns'])[:5]\n",
    "array([165.07808666, 300.52105073, 174.28363771, 288.87689757, 395.065479  ])\n",
    "```\n",
    "\n",
    "A plot of the predictions returned by `fit_model_and_return_predictions` might then look like:\n",
    "\n",
    "<center><img src=\"imgs/fit-model.png\" width=500></center>\n",
    "\n",
    "Is this a \"good\" model? Sure, it has a low training MSE, but it's not likely to generalize well to unseen $x$-values ‚Äì in this case, future `'Year'`.\n",
    "\n",
    "**You can create your features however you'd like!** Don't just use our example of using polynomial features of degrees 2 to 10. Try, intuitively, to come up with a fit hypothesis function that _you think_ is likely to generalize well to future `'Year'`s for whom we don't know the number of `'Homeruns'`. We will formalize how to develop models that generalize well in the coming lectures.\n",
    "\n",
    "All we can autograde in this question are your resulting predictions ‚Äì practically, we have no way of knowing how you come up with them. Other than what's described above, here are the only added requirements of your function:\n",
    "\n",
    "- It should be able to take in a **subset** of the rows in `homeruns`, and should do all calculations (feature creation, fitting, predicting) using that subset. So, this should work too:\n",
    "    ```python\n",
    "        >>> fit_model_and_return_predictions(homeruns.head()[['Year']], homeruns.head()['Homeruns'])\n",
    "        \n",
    "    ```\n",
    "    Note that in `fit_model_and_return_predictions`, the `X` data used to fit the model is always the same as the data used to make predictions. In future examples in this class, this is not necessarily how model building will work ‚Äì after all, we typically build models using historical data and use them to make predictions about future data ‚Äì but this is how we'll use and test `fit_model_and_return_predictions`.\n",
    "\n",
    "- The array that `fit_model_and_return_predictions` returns should be **deterministic**. That is, if `fit_model_and_return_predictions` is called twice with the exact same inputs `X` and `y`, the output should not change.\n",
    "- The mean squared error of the predictions, when called on `X=homeruns[['Year']]` and `y=homeruns['Homeruns']`, should be **between 100,000 and 200,000**. Yes, it's possible to achieve a mean squared error of less than 100,000, but such a model is likely **overfitting** significantly to the data. (In fact, in Homework 7, you learned how to build models with 0 MSE, using Lagrange Interpolation! **Don't do that here ‚Äì try and build more general-purpose models.**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a97bbee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def fit_model_and_return_predictions(X, y):\n",
    "    X = X.copy()\n",
    "    # Below, create your features and design matrix,\n",
    "    # instantiate a LinearRegression object,\n",
    "    # fit it, and then call model.predict on it.\n",
    "    ...\n",
    "\n",
    "# Feel free to change this input to make sure your function works correctly.\n",
    "preds = fit_model_and_return_predictions(homeruns[['Year']], homeruns['Homeruns'])\n",
    "\n",
    "# Uncomment the code below to see a graph of your\n",
    "# fit hypothesis function's predictions.\n",
    "# fig = homeruns.plot(kind='scatter', x='Year', y='Homeruns')\n",
    "# fig.add_trace(go.Scatter(\n",
    "#     x=homeruns['Year'],\n",
    "#     y=preds,\n",
    "#     mode='lines',\n",
    "#     line=dict(width=4),\n",
    "#     name='Fit Model'\n",
    "# ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c3e069",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q01_02\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbf567c",
   "metadata": {},
   "source": [
    "### Question 1.3 [Autograded üíª] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">5 Points</div>\n",
    "\n",
    "Above, you had to manually create features that resulted in a hypothesis function that fit the data well (but not too well). You may wonder, is there a way to do this automatically?\n",
    "\n",
    "One _kind-of_ solution is to use **nearest neighbors regression**. In nearest neighbors regression, to evaluate the hypothesis function $H^*$ on the (scalar) input $x_\\text{new}$:\n",
    "\n",
    "1. First, choose a value of $k$. Sometimes, this is called **$k$-nearest neighbors, or $k$-NN regression**.\n",
    "1. Then:\n",
    "    1. Find the $k$ points in the original dataset whose $x$-values are closest to $x_\\text{new}$ in terms of absolute value (note that since we're essentially dealing with just a single $x$ feature, using squared distance would also work the same way).\n",
    "    1. Return the mean of the $y$-values corresponding to the $k$ points found in the step above.\n",
    "\n",
    "For example, suppose our original dataset is:\n",
    "\n",
    "| x | y |\n",
    "| --- | --- |\n",
    "| 10 | 5 |\n",
    "| 11 | 17 |\n",
    "| 12 | 26 |\n",
    "| 19 | -5 |\n",
    "| 25 | 3 |\n",
    "\n",
    "Suppose we choose $k = 3$, and suppose we want to predict the $y$-value for $x_\\text{new} = 20$. Then:\n",
    "- The $k = 3$ points with the closest $x$-values are $(19, -5)$, $(25, 3)$, and $(12, 26)$.\n",
    "- The mean of the $y$-values of the three points above is $\\frac{-5 + 3 + 26}{3} = 8$.\n",
    "- So, we predict a $y$-value of 8 for input $x_\\text{new} = 20$.\n",
    "\n",
    "This is a regression technique, because it allows us to predict real-valued outputs. However, it is different from linear regression in that it is **non-parametric** ‚Äì there are no **parameters** $w_0^*, w_1^*, ...$ that we're learning from the data in order to make our predictions. Another way of thinking about the idea of a parametric model is that parametric methods make assumptions about the shape of the data and/or its underlying probability distribution; linear regression assumes that the underlying data looks linear (among other things), while $k$-NN regression doesn't assume anything about the shape of the data.\n",
    "\n",
    "\n",
    "We can choose $k$ to be whatever we want it to be, but some values of $k$ are \"better\" in some sense than others. We'll explore this idea in Question 1.4, when we tie things back into the `homeruns` dataset.\n",
    "\n",
    "**Your job is to** complete the implementation of the function `create_knn_regressor`, which takes in:\n",
    "- `x`, a 1D array/Series of $x$-values, e.g. `homeruns['Year']`,\n",
    "- `y`, a 1D array/Series of $y$-values, e.g. `homeruns['Homeruns']`, and\n",
    "- `k`, a positive integer corresponding to the value of $k$ (where `k <= len(x)`).\n",
    "\n",
    "`create_knn_regressor` should return a **function** that can take in a single number `x_new` and return the predicted $y$-value for the input `x_new`, according to the process outlined above.\n",
    "\n",
    "Example behavior is given below.\n",
    "\n",
    "```python\n",
    ">> regressor = create_knn_regressor(x=np.array([10, 11, 12, 19, 25]),\n",
    "                                    y=np.array([5, 17, 26, -5, 3]),\n",
    "                                    k=3)\n",
    ">>> regressor(20)\n",
    "8.0\n",
    "```\n",
    "\n",
    "Some guidance: \n",
    "- The bulk of the work in this question is in understanding how nearest neighbor regression works. Our implementation is very short (5 lines total).\n",
    "- **You're not allowed to use `sklearn` here**, but don't forget to use what you know about `pandas` DataFrames! You shouldn't use a `for`-loop.\n",
    "- Don't worry about cases in which there are ties in distance (e.g. if $k = 3$ but there are 4 points that are all equidistant from $x_\\text{new}$ such that they are all the closest); our tests are written in a way that will not penalize your handling of this situation if it's different from ours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d8af4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_knn_regressor(x, y, k):\n",
    "    ...\n",
    "\n",
    "# Feel free to change these inputs to make sure your function works correctly.\n",
    "# It's a good idea to test out create_knn_regressor on the homeruns dataset!\n",
    "regressor = create_knn_regressor(x=np.array([10, 11, 12, 19, 25]),\n",
    "                                 y=np.array([5, 17, 26, -5, 3]),\n",
    "                                 k=3)\n",
    "regressor(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82f58c4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q01_03\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1b52ed",
   "metadata": {},
   "source": [
    "Once you've implemented `create_knn_regressor`, run the cell below to see an **interactive** widget that will allow you to choose different values of $k$ and see the resulting $k$-NN regressor plotted on top of the `homeruns` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6e887e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "def plot_given_k(k):\n",
    "    x = homeruns['Year']\n",
    "    y = homeruns['Homeruns']\n",
    "    regressor = create_knn_regressor(x, y, k)\n",
    "    preds = [regressor(xi) for xi in x]\n",
    "\n",
    "    fig = px.scatter(x=x, y=y).update_layout(xaxis_title='Year', yaxis_title='Homeruns', title=f'Fit kNN Model with k={k}')\n",
    "\n",
    "    return fig.add_trace(go.Scatter(\n",
    "        x=x,\n",
    "        y=preds,\n",
    "        mode='lines',\n",
    "        line=dict(width=4),\n",
    "        name='Fit Model'\n",
    "    ))\n",
    "\n",
    "widgets.interact(plot_given_k, k=widgets.IntSlider(min=1, max=140, step=1, value=5));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568bcc31",
   "metadata": {},
   "source": [
    "Try different values of $k$ ‚Äì what do you notice?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0f0486",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 1.4 [Written ‚úèÔ∏è] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">3 Points</div>\n",
    "\n",
    "Play around with the interactive cell above. Then, comment on the following points **in your PDF writeup, along with your answers to the rest of the written problems in this homework (that is, _not_ in this notebook)**:\n",
    "1. When $k = 1$, what does the resulting fit model look like, and how does it relate to models we've seen in earlier lectures/homeworks?\n",
    "2. When $k = 140$, what does the resulting fit model look like, and how does it relate to models we've seen in earlier lectures/homeworks?\n",
    "3. Which value of $k$ do you _feel_ best captures the trend in the data, and why? (Just give a one sentence intuitive answer ‚Äì no calculations needed.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100479fd",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## Question 2: March Madness üèÄ\n",
    "\n",
    "---\n",
    "\n",
    "Michigan's men's basketball team is back in the NCAA Tournament! Our first game, on Thursday, March 20th, is against Suraj's old team, UC San Diego. (By the time you're reading this, we may already know the result!)\n",
    "\n",
    "In this question, we'll continue with our theme of using sports data. This time, we'll use a dataset that has one row each for all 364 Division 1 men's basketball team this season, taken from [Sports Reference](https://www.sports-reference.com/cbb/seasons/men/2025-school-stats.html). Run the cell below to load in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eda8726",
   "metadata": {},
   "outputs": [],
   "source": [
    "teams = pd.read_csv('data/ncaa-2025.csv')\n",
    "teams.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f196c6b3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "There are several pieces of information for each `'School'`, based on their performance in the 2024-25 season leading up to the NCAA Tournament, i.e. **not** including the NCAA Tournament."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d9f737",
   "metadata": {},
   "outputs": [],
   "source": [
    "teams.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed70aaa",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We won't use most of these features, and will explain the features we do end up using.\n",
    "\n",
    "First, we'll say that we're not going to try and make a perfect bracket, or predict who is going to win any particular March Madness game ‚Äì that's far too difficult to do. There's a reason that [nobody has ever correctly predicted the results of all 63 games in the NCAA Tournament](https://www.ncaa.com/news/basketball-men/bracketiq/2023-03-16/perfect-ncaa-bracket-absurd-odds-march-madness-dream).\n",
    "\n",
    "Let's start simpler, by looking at the relationship between the **total** number of points each team scored in the regular season, `'Points For'`, and the total number of points their opponents scored against them, `'Points Against'`. We'll color each school by whether or not they `'Qualified'` for the NCAA Tournament."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe85b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(teams, x='Points For', y='Points Against', hover_name='School', color='Qualified', \n",
    "                 color_discrete_map={True: '#D81B60', False: '#1E88E5'})\n",
    "\n",
    "fig.update_layout(width=800, title='Points Against vs. Points For for All 364 D1 Teams',\n",
    "                  legend={'title': 'Qualified for NCAA Tournament'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa8c902",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "If you hover over a point in the plot above, you'll see the name of the corresponding school. For fun, take a look at the NCAA's [Official Rankings](https://www.cbssports.com/college-basketball/news/march-madness-2025-committee-reveals-official-ncaa-tournament-bracket-seed-list-from-1-68/) for all 68 teams that qualified for the tournament. Where do the top teams on the NCAA's list appear in the plot above?\n",
    "\n",
    "You'll notice that teams that qualified for the tournament appear in the bottom right quadrant of the graph. Typically, to qualify for the tournament, a team has to be pretty good, and good teams score lots of points. There are also not-so-good teams that automatically qualified for the tournament; see if you can spot them in the graph above.\n",
    "\n",
    "It's important to note that there are 364 teams in the dataset, but each team only played ~35 games leading up to the tournament. So, each individual team only played a small subset of other teams. Each team mostly played teams in its own \"conference\". Michigan, for example, is in the Big Ten Conference, and mostly played other Big Ten teams.\n",
    "\n",
    "Now that we're somewhat familiar with the dataset, let's get started. In Question 1, you only used `sklearn` to train your model, once you had already created your features. In this question, we will have you create various `sklearn` Pipelines that implement the end-to-end modeling process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5939d406",
   "metadata": {},
   "source": [
    "### Question 2.1 [Autograded üíª] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">2 Points</div>\n",
    "\n",
    "Let's start by creating a linear regression model that uses a team's `'Points For'` and `'Points Against'` to predict `'W-L%'`, the percentage of games that the team won leading up to the tournament. Specifically, let's fit the model:\n",
    "\n",
    "$$\\text{pred. W-L%}_i = w_0 + w_1 \\cdot \\text{Points For}_i + w_2 \\cdot \\text{Points Against}_i$$\n",
    "\n",
    "Complete the implementation of the function `create_model_points_for_against`, which takes in a DataFrame like `teams` and returns an **already fit** `LinearRegression` object that implements the hypothesis function above. Example behavior is given below.\n",
    "\n",
    "```python\n",
    ">>> model = create_model_points_for_against(teams)\n",
    "\n",
    ">>> model.coef_\n",
    "array([ 0.0007842 , -0.00077308])\n",
    "\n",
    ">>> model.predict([[2400, 2200]])[0]\n",
    "0.6289662049554058\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dd8c71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_model_points_for_against(teams):\n",
    "    # Make sure not to fit the model with all of the columns in `teams`,\n",
    "    # just the two that are relevant.\n",
    "    ...\n",
    "    \n",
    "# Feel free to change this input to make sure your function works correctly.\n",
    "# Remember that your function should work on subsets of the teams DataFrame as well.\n",
    "model = create_model_points_for_against(teams)\n",
    "\n",
    "# Note that to predict W-L%, I only need to pass in two values!\n",
    "model.predict([[2400, 2200]])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f84ca1c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q02_01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8014266b",
   "metadata": {},
   "source": [
    "Let's visualize your fit model. Run the cell below to see your model's predictions in <b><span style=\"color:orange\">orange</span></b>, along with the original dataset in <b><span style=\"color:blue\">blue</span></b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093b2aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thanks, Claude, for helping us generate this visualization code!\n",
    "model = create_model_points_for_against(teams)\n",
    "\n",
    "x_range = np.linspace(teams['Points For'].min(), teams['Points For'].max(), 20)\n",
    "y_range = np.linspace(teams['Points Against'].min(), teams['Points Against'].max(), 20)\n",
    "x_grid, y_grid = np.meshgrid(x_range, y_range)\n",
    "\n",
    "grid_points = np.column_stack([x_grid.flatten(), y_grid.flatten()])\n",
    "z_pred = model.predict(grid_points)\n",
    "z_grid = z_pred.reshape(x_grid.shape)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=teams['Points For'],\n",
    "    y=teams['Points Against'],\n",
    "    z=teams['W-L%'],\n",
    "    mode='markers',\n",
    "    name='Actual Values'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Surface(\n",
    "    x=x_grid,\n",
    "    y=y_grid,\n",
    "    z=z_grid,\n",
    "    name='Predictions',\n",
    "    showscale=False,\n",
    "    colorscale='oranges'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    scene=dict(\n",
    "        xaxis_title='Points For',\n",
    "        yaxis_title='Points Against',\n",
    "        zaxis_title='Win-Loss Percentage'\n",
    "    ),\n",
    "    title='Actual vs. Predicted Win-Loss Percentage',\n",
    "    width=900,\n",
    "    height=500\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7355bed",
   "metadata": {},
   "source": [
    "It seems like our model is doing a decent job at modeling win-loss percentage. Let's peek at our optimal model parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f9e797",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.intercept_, model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c315c46",
   "metadata": {},
   "source": [
    "If you did this correctly, you should see that our model looks like:\n",
    "\n",
    "$$\\text{pred. W-L%}_i \\approx 0.447660 + 0.000784 \\cdot \\text{Points For}_i - 0.000773 \\cdot \\text{Points Against}_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848e7a9f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "It appears that the coefficients on $\\text{Points For}$ and $\\text{Points Against}$ are _almost_ cancelling each other out! This could imply that we could achieve _almost_ as good performance by looking at just the **difference** between a team's $\\text{Points For}$ and $\\text{Points Against}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba901b21",
   "metadata": {},
   "source": [
    "### Question 2.2 [Autograded üíª] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">3 Points</div>\n",
    "\n",
    "Recall from Lecture 16 that standardizing a model's features **does not** change its performance; rather, it makes the model's coefficients more directly comparable to one another, since standardizing brings features to the same scale. Here, standardizing is _truly_ not necessary since both the `'Points For'` and `'Points Against'` columns are already roughly on the same scale (both features are in the 1800-3000 range, roughly speaking).\n",
    "\n",
    "But, while it won't help with our model's performance, we'll have you standardize our model's features here, to practice creating a Pipeline. Specifically, you'll build an `sklearn` Pipeline that does the following to predict `'W-L%'`:\n",
    "\n",
    "- Standardizes `'Points For'` and `'Points Against'`.\n",
    "- Fits a `LinearRegression` model.\n",
    "\n",
    "Complete the implementation of the function `create_model_points_for_against_standardized`, which takes in a DataFrame like `teams` and returns a fit Pipeline that follows all of the steps above. Example behavior is given below.\n",
    "\n",
    "\n",
    "```python\n",
    ">>> model = create_model_points_for_against_standardized(teams)\n",
    ">>> model\n",
    "```\n",
    "\n",
    "<div style=\"text-align: left;\">\n",
    "  <img src=\"imgs/base-pipe.png\" width=\"200\">\n",
    "</div>\n",
    "\n",
    "```python\n",
    ">>> model[-1].coef_\n",
    "array([ 0.16508223, -0.12354681]) # Different from before!\n",
    "\n",
    ">>> model.predict([[2400, 2200]])[0]\n",
    "0.6289662049554058 # Identical to before!\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dcb565",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def create_model_points_for_against_standardized(teams):\n",
    "    ...\n",
    "    \n",
    "# Feel free to change this input to make sure your function works correctly.\n",
    "# Remember that your function should work on subsets of the teams DataFrame as well.\n",
    "model = create_model_points_for_against_standardized(teams)\n",
    "model.predict([[2400, 2200]])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc84de83",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q02_02\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1390d2",
   "metadata": {},
   "source": [
    "Above, you should have noticed that both the original model and the standardized Pipeline model give the same predicted win-loss percentage for a team that scored 2400 points and had 2200 points scored against them. Again, standardizing _does not_ change a model's predictions. In the rest of this cell, we'll refer to our two models so far as the same one model.\n",
    "\n",
    "How well is our model so far performing? It's useful to compute some performance metrics that we can refer back to later on. Once you finish Question 2.2, run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec18b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell, and don't edit it.\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def model_performances(model, X, y):\n",
    "    rmse_100 = 100 * np.sqrt(mean_squared_error(y, model.predict(X)))\n",
    "    r2 = model.score(X, y)\n",
    "    return pd.Series({'100 * RMSE': rmse_100, 'R^2': r2})\n",
    "\n",
    "model = create_model_points_for_against_standardized(teams)\n",
    "\n",
    "perf = pd.DataFrame(columns=['100 * RMSE', 'R^2'])\n",
    "perf.loc['Points For + Points Against'] = model_performances(\n",
    "    model, teams[['Points For', 'Points Against']], teams['W-L%']\n",
    ")\n",
    "perf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3415ecaa",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We've computed two metrics above:\n",
    "- **100 * RMSE**: This is the square root of our model's mean squared error, multiplied by 100. Since our model predicts win percentages ‚Äì or more precisely, win **proportions** ‚Äì the square root of its mean squared error can be interpreted, **roughly**, as the average difference between a team's actual win proportion and our prediction of its win proportion. (Remember that a model's mean absolute error is _different_ from the square root of its mean squared error, though abstractly, these are both similar measurements of the model's quality.) If we multiply the model's root mean squared error by 100, we get, roughly, the average number of **percentage points** our predictions were wrong by. Here, it seems that a typical predicted win percentage was off by 6.43 percentage points.\n",
    "- **R^2**: This metric, computed by calling `model.score` on any fit regression model, is called the **multiple $R^2$** coefficient (among [other things](https://en.wikipedia.org/wiki/Coefficient_of_determination)). It is a measure of the quality of a model's predictions, or more precisely, a measure of what proportion of the $y$-variable (`'W-L%'`)'s variance our model captured. It ranges between 0 and 1, where 0 means we captured none of the $y$-variable's variance (<span style=\"color:orange\"><b>bad</b></span>) and 1 means we captured all of the $y$-variables variance (<span style=\"color:blue\"><b>good</b></span>). There are a few equivalent ways of computing it, assuming we're dealing with a linear model with an intercept term:\n",
    "\n",
    "    1. $R^2 = \\frac{\\text{variance}(\\text{predicted } y \\text{ values})}{\\text{variance}(\\text{actual } y \\text{ values})}$\n",
    "    1. $R^2 = \\left[ r(\\text{actual } y \\text { values}, \\text{predicted } y \\text { values}) \\right]^2$, where $r$ denotes the correlation coefficient from Lecture 12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6599dd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same value as above!\n",
    "np.var(model.predict(teams[['Points For', 'Points Against']])) / np.var(teams['W-L%'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799e04fc",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's keep these metrics in mind as we build more sophisticated models to predict win-loss percentage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624dc353",
   "metadata": {},
   "source": [
    "### Question 2.3 [Autograded üíª] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">5 Points</div>\n",
    "\n",
    "In the basketball world, two common \"advanced stats\" that analysts use to rank teams are **offensive efficiency** and **defensive efficiency**. We define them below, **using variable names that correspond to column names in `'teams'`**.\n",
    "\n",
    "$$\\text{Offensive Efficiency}_i = 100 \\cdot \\frac{\\text{Points For}_i}{0.96 \\cdot \\text{FGA}_i + \\text{TOV}_i + 0.44 \\cdot \\text{FTA}_i - \\text{ORB}_i}$$\n",
    "\n",
    "$$\\text{Defensive Efficiency}_i = 100 \\cdot \\frac{\\text{Points Against}_i}{0.96 \\cdot \\text{FGA}_i + \\text{TOV}_i + 0.44 \\cdot \\text{FTA}_i - \\text{ORB}_i}$$\n",
    "\n",
    "Large offensive efficiency values mean a team is good at scoring points. Small defensive efficiency values mean a team is good at preventing their opponents from scoring points. Perhaps there's an argument to be made that we can make better predictions if we use offensive and defensive efficiency, rather than just the number of points a team scored and had scored against them. Let's try it out!\n",
    "\n",
    "Your job here is to build an `sklearn` Pipeline that does the following to predict `'W-L%'`:\n",
    "\n",
    "- Takes the existing features in the `teams` DataFrame and creates two new features, one for offensive efficiency and one for defensive efficiency.\n",
    "- One hot encodes the `'Qualified'` column, with `drop='first'`.\n",
    "- Fits a `LinearRegression` model.\n",
    "\n",
    "Our final hypothesis function will then look like:\n",
    "\n",
    "$$\\text{pred. W-L%}_i = w_0 + w_1 \\cdot \\text{Offensive Efficiency}_i + w_2 \\cdot \\text{Defensive Efficiency}_i + w_3 \\cdot (\\text{Qualified}_i == \\text{True})$$\n",
    "\n",
    "<center><small><small>The last feature could also be $(\\text{Qualified}_i == \\text{False})$; <code>sklearn</code> will decide.</small></small></center>\n",
    "\n",
    "Complete the implementation of the function `create_model_advanced`, which takes in a DataFrame like `teams` and returns a fit Pipeline that follows all of the steps above. Example behavior is given below.\n",
    "\n",
    "```python\n",
    ">>> model = create_model_advanced(teams)\n",
    ">>> model\n",
    "```\n",
    "\n",
    "<img src=\"imgs/pipe-complex.png\" width=500>\n",
    "\n",
    "```python\n",
    "# Three coefficients: \n",
    "# - one for offensive efficiency.\n",
    "# - one for defensive efficiency.\n",
    "# - one for the one hot encoded 'Qualified' column.\n",
    ">>> model[-1].coef_\n",
    "array([ 0.01484763, -0.0168983 ,  0.03888132])\n",
    "\n",
    ">>> model.predict(pd.DataFrame([{\n",
    "    'Points For': 2400,\n",
    "    'Points Against': 2200,\n",
    "    'FGA': 1998,\n",
    "    'TOV': 500,\n",
    "    'FTA': 700,\n",
    "    'ORB': 300,\n",
    "    'Qualified': False\n",
    "}]))[0]\n",
    "0.6343109351729046\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "Some guidance:\n",
    "- All transformations should be done within the Pipeline ‚Äì you **cannot** preprocess the training data using vanilla `pandas` before creating your Pipeline!\n",
    "    - Specifically, you're **not** supposed to make an `'Offensive Efficiency'` column directly within `teams` before fitting a model. If you do that, your Pipeline won't behave like our example above. Your Pipeline needs to be able to take in **original, raw data** (without `'Offensive Efficiency'` values) and use them for prediction.\n",
    "    - So, for instance, to create a column of offensive efficiency values **within** your Pipeline, you should create a `FunctionTransformer`! \n",
    "        - That `FunctionTransformer` will take in a function, say `f`, as input.\n",
    "        - `f` itself will take in a DataFrame like `teams`, and return a **DataFrame with just a single column** of offensive efficiency values. (This is something we mentioned in [Lecture 17](https://practicaldsc.org/resources/lectures/lec17/lec17-annotated.pdf#page=18).)\n",
    "        - Then, `FunctionTransformer(f)` will be given to `make_column_transformer`, along with a list of column names that are needed for `f` to work (including `'Points For'`, `'FGA'`, etc.).\n",
    "    - You'll make a **separate** `FunctionTransformer` to create defensive efficiency values.\n",
    "    - Remember, a `ColumnTransformer` ‚Äì which you can create easily using `make_column_transformer` ‚Äì is how you specify which transformations you want applied to which columns. \n",
    "    - The tests assume that you add your offensive efficiency transformer to your `ColumnTransformer` **before** your defensive efficiency transformer.\n",
    "    - It's okay if the graphical representation of your Pipeline isn't exactly the same as ours.\n",
    "- Remember to use `drop='first'` when using `OneHotEncoder` to avoid multicollinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1050c248",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "\n",
    "def create_model_advanced(teams):\n",
    "    # Create your transformers here.\n",
    "    ...\n",
    "    \n",
    "    # Make your Pipeline here.\n",
    "    model = ...\n",
    "    \n",
    "    # Don't change the line below.\n",
    "    # We're ensuring that your model is only fit using the columns that are actually needed,\n",
    "    # so that when we call model.predict, we only need to specify these values as inputs.\n",
    "    feature_cols = ['Points For', 'Points Against', 'FGA', 'TOV', 'FTA', 'ORB', 'Qualified']\n",
    "    return model.fit(teams[feature_cols], teams['W-L%'])\n",
    "    \n",
    "# Feel free to change this input to make sure your function works correctly.\n",
    "# Remember that your function should work on subsets of the teams DataFrame as well.\n",
    "model = create_model_advanced(teams)\n",
    "model.predict(pd.DataFrame([{\n",
    "    'Points For': 2400,\n",
    "    'Points Against': 2200,\n",
    "    'FGA': 1998,\n",
    "    'TOV': 500,\n",
    "    'FTA': 700,\n",
    "    'ORB': 300,\n",
    "    'Qualified': False\n",
    "}]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec0296a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q02_03\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac6009c",
   "metadata": {},
   "source": [
    "Nice! Let's see how our shiny new model compares to our original model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0321624",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['Points For', 'Points Against', 'FGA', 'TOV', 'FTA', 'ORB', 'Qualified']\n",
    "\n",
    "model = create_model_advanced(teams)\n",
    "\n",
    "perf.loc['With OffEff, DefEff, and Qualifying Status'] = model_performances(\n",
    "    model,\n",
    "    teams[feature_cols],\n",
    "    teams['W-L%']\n",
    ")\n",
    "perf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556a21ff",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "You should notice that the predictions aren't significantly better! This is a good life lesson: engineering more sophisticated features _can_ lead to better model performance, but that isn't guaranteed.\n",
    "\n",
    "To wrap up, let's use your model to look at how the offensive and defensive efficiencies of the teams in our dataset are related. If you've implemented `create_model_advanced` correctly, you should see a matrix with 3 columns below. You'll know that your columns are in the right order if the top-left value is `103.42113452`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01abc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed = model[0].transform(teams[feature_cols])\n",
    "transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5124e418",
   "metadata": {},
   "source": [
    "If that looks good, run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997a833a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(teams, x='Points For', y='Points Against', hover_name='School', color='Qualified', \n",
    "                 )\n",
    "fig.update_layout(width=800)\n",
    "\n",
    "fig = px.scatter(x=transformed[:, 0], \n",
    "                 y=transformed[:, 1], \n",
    "                 hover_name=teams['School'], \n",
    "                 color=teams['Qualified'],\n",
    "                 color_discrete_map={True: '#D81B60', False: '#1E88E5'})\n",
    "\n",
    "fig.update_layout(width=800, title='Defensive Efficiency vs. Offensive Efficiency For for All 364 D1 Teams',\n",
    "                  xaxis_title='Offensive Efficiency',\n",
    "                  yaxis_title='Defensive Efficiency',\n",
    "                  legend={'title': 'Qualified for NCAA Tournament'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5ab032",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Can you find Michigan „ÄΩÔ∏è? If you did everything correctly, Michigan should appear around (115, 105).\n",
    "\n",
    "Best of luck to your bracket!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007584b2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Question 3: Sums of Residuals ü§î\n",
    "\n",
    "---\n",
    "\n",
    "In this problem, we will prove that the sum of the residuals of a fit regression model is 0.\n",
    "\n",
    "We define the $i$th **residual** to be the difference between the actual and predicted values for individual $i$ in our dataset, when the predictions are made using a regression model whose coefficients $w_0^*$ and $w_1^*$ (or, for multiple linear regression models, $w_0^*$, $w_1^*$, $w_2^*$, ..., $w_d^*$) are all optimal.\n",
    "\n",
    "In other words, the $i$th residual $e_i$ is: $$e_i = y_i - H^*(\\vec x_i)$$\n",
    "\n",
    "We use the letter $e$ for residuals because residuals are also known as errors.\n",
    "\n",
    "We'll get to the proof soon, but first, a warmup."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953eeca4",
   "metadata": {
    "tags": []
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 3.1 [Written ‚úèÔ∏è] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">2 Points</div>\n",
    "Suppose $\\vec{1} \\in \\mathbb{R}^n$ is a vector containing the value 1 for each element, i.e. $\\vec{1} = \\begin{bmatrix} 1 \\\\ 1 \\\\ ... \\\\ 1 \\end{bmatrix}$.\n",
    "\n",
    "For any other vector $\\vec{b} = \\begin{bmatrix} b_1 \\\\ b_2 \\\\ ... \\\\ b_n \\end{bmatrix}$, what is the value of $\\vec{1}^T \\vec{b}$, i.e. what is the dot product of $\\vec{1}$ and $\\vec{b}$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d433c0",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 3.2 [Written ‚úèÔ∏è] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">3 Points</div>\n",
    "Back to the main problem at hand.\n",
    "\n",
    "Consider the typical multiple regression scenario where our hypothesis function has an intercept term:\n",
    "$$H(\\vec{x}_i) = w_0 + w_1 x_i^{(1)} + w_2 x_i^{(2)} + ... + w_d x_i^{(d)}$$\n",
    "\n",
    "Note that another way of writing the $i$th residual, $e_i = y_i - H^*(\\vec x_i)$, is:\n",
    "\n",
    "$$e_i = (\\vec{y} - X \\vec{w}^*)_i$$\n",
    "\n",
    "Here, $X$ is a $n \\times (d + 1)$ design matrix, $\\vec{y} \\in \\mathbb{R}^n$ is an observation vector, and $\\vec{w} \\in \\mathbb{R}^{(d+1)}$ is the parameter vector. We'll use $\\vec{w}^*$ to denote the optimal parameter vector, or the one that satisfies the normal equations. $(\\vec{y} - X \\vec{w}^*)_i$ is referring to element $i$ of the vector $\\vec{y} - X \\vec{w}^*$.\n",
    "\n",
    "Using facts about $\\vec{w}^*$ we learned in Lectures 14 and 15, prove that for multiple linear regression models with an intercept term, the sum of the residuals is 0. That is, prove that:$$\\sum_{i = 1}^n e_i = 0$$\n",
    "\n",
    "*Hint: Refer to the derivation of $\\vec w^*$ in Lecture 14. How did we define $X$? Your proof should not be very long.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbc2af2",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 3.3 [Written ‚úèÔ∏è]  <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">3 Points</div>\n",
    "Now suppose our hypothesis function does not have an intercept term, but is otherwise linear with multiple features: $$H(\\vec x_i) = w_1 x_i^{(1)} + w_2 x_i^{(2)} + ... + w_d x_i^{(d)}$$\n",
    "\n",
    "- Is it still guaranteed that $\\displaystyle\\sum_{i = 1}^n e_i = 0$? Why or why not?\n",
    "- Is it still possible that $\\displaystyle\\sum_{i = 1}^n e_i = 0$? If you believe the answer is yes, come up with a simple example where a linear hypothesis function without an intercept has residuals that sum to 0. If you believe the answer is no, state why not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae53f1bc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## Question 4: Real Estate üè°\n",
    "\n",
    "---\n",
    "\n",
    "You are given a dataset containing information on recently sold houses in Ann Arbor, including:\n",
    "\n",
    "- square footage\n",
    "- number of bedrooms\n",
    "- number of bathrooms\n",
    "- year the house was built\n",
    "- asking price, or how much the house was originally listed for, before negotiations\n",
    "- sale price, or how much the house actually sold for, after negotiations\n",
    "\n",
    "The table below shows the first few rows of the data set. Note that since you don't have the full dataset, you cannot answer the questions that follow based on calculations; you must answer conceptually.\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th>House</th>\n",
    "      <th>Square Feet</th>\n",
    "      <th>Bedrooms</th>\n",
    "      <th>Bathrooms</th>\n",
    "      <th>Year</th>\n",
    "      <th>Asking Price</th>\n",
    "      <th>Sale Price</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>1</td>\n",
    "      <td>1247</td>\n",
    "      <td>3</td>\n",
    "      <td>3</td>\n",
    "      <td>2005</td>\n",
    "      <td>500,000</td>\n",
    "      <td>494,000</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>2</td>\n",
    "      <td>1670</td>\n",
    "      <td>3</td>\n",
    "      <td>2</td>\n",
    "      <td>1927</td>\n",
    "      <td>1,000,000</td>\n",
    "      <td>985,000</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>3</td>\n",
    "      <td>716</td>\n",
    "      <td>1</td>\n",
    "      <td>1</td>\n",
    "      <td>1993</td>\n",
    "      <td>335,000</td>\n",
    "      <td>333,850</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>4</td>\n",
    "      <td>1600</td>\n",
    "      <td>4</td>\n",
    "      <td>2</td>\n",
    "      <td>1962</td>\n",
    "      <td>830,000</td>\n",
    "      <td>815,000</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>5</td>\n",
    "      <td>2635</td>\n",
    "      <td>4</td>\n",
    "      <td>3</td>\n",
    "      <td>1993</td>\n",
    "      <td>1,250,000</td>\n",
    "      <td>1,250,000</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>&#8943;</td> <!-- ellipsis -->\n",
    "      <td>&#8943;</td>\n",
    "      <td>&#8943;</td>\n",
    "      <td>&#8943;</td>\n",
    "      <td>&#8943;</td>\n",
    "      <td>&#8943;</td>\n",
    "      <td>&#8943;</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dec674a",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 4.1 [Written ‚úèÔ∏è] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">3 Points</div>\n",
    "First, suppose we fit a multiple linear regression model to predict the sale price of a house given all five of the other variables.  Which feature would you expect to have the largest magnitude weight? Why? (Remember that the weight of a feature is the value of $w^*$ for that feature.)\n",
    "\n",
    "Then, suppose we standardize each variable separately. (Recall, to standardize a column $x_1, x_2, ..., x_n$, we replace each value $x_i$ with $\\frac{x_i - \\bar{x}}{\\sigma_x}$.) Suppose we fit another multiple linear regression model to predict the sale price of a house given all five of the other standardized variables. Now, which feature would you expect to have the largest magnitude weight? Why?\n",
    "\n",
    "Some guidance: There _could_ be multiple answers to one of the parts; if that's the case, you only need to list and justify one possible answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9815756a",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 4.2 [Written ‚úèÔ∏è] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">3 Points</div>\n",
    "\n",
    "Suppose we fit a multiple linear regression model to predict the sale price of a house given all five of the other variables in their original, unstandardized form. Suppose the weight for the Year feature is $\\alpha$.\n",
    "\n",
    "Now, suppose we replace Year with a new feature, Age, which is 0 if the house was built in 2025, 1 if the house was built in 2024, 2 if the house was built in 2023, and so on. If we fit a new multiple linear regression model on all five variables, but using Age instead of Year, what will the weight for the Age feature be, in terms of $\\alpha$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b48195",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 4.3 [Written ‚úèÔ∏è] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">3 Points</div>\n",
    "\n",
    "Now, suppose we fit a multiple linear regression model to predict the sale price of a house given all five of the other features, plus a new sixth feature named $\\text{Rooms}$, which is the total number of bedrooms and bathrooms in the house. Will our new regression model with an added sixth feature make better predictions than the models we fit in Questions 2.1 or 2.2?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43a612a",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 4.4 [Written ‚úèÔ∏è] <div style=\"display:inline-block; vertical-align: middle; padding:7px 7px; font-size:10px; font-weight:light; color:white; background-color:#e84c4a; border-radius:7px; text-align:left;\">3 Points</div>\n",
    "\n",
    "Now, suppose we fit two multiple linear regression models to predict the sale price of a house.\n",
    "\n",
    "The first uses the features $\\text{Square Feet}$ and $\\text{Bathrooms}$:\n",
    "\n",
    "$$H_\\gamma(\\vec x_i) = \\gamma_0 + \\gamma_1 \\cdot \\text{Square Feet}_i +\\gamma_2 \\cdot \\text{Bathrooms}_i$$\n",
    "\n",
    "The second model uses the  features $\\text{Square Feet}$ and $\\text{Bathrooms}$ and a new seventh feature named $\\text{Length of Street Name}$, which is the number of letters in the name of the street that the house is on:\n",
    "\n",
    "$$H_\\lambda(\\vec x_i) = \\lambda_0 + \\lambda_1 \\cdot \\text{Square Feet}_i +\\lambda_2 \\cdot \\text{Bathrooms}_i + \\lambda_3 \\cdot \\text{Length of Street Name}_i$$\n",
    "\n",
    "Let $\\text{TMSE}$ refer to the \"training\" mean squared error, that is, the mean squared error of a hypothesis function **on the same dataset we used to fit it**. (Through Lecture 16, we just referred to this idea as MSE.)\n",
    "\n",
    "Argue why $\\text{TMSE}(H_\\lambda) \\leq \\text{TMSE}(H_\\gamma)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84716ac2",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## Finish Line üèÅ\n",
    "\n",
    "Congratulations! You're ready to submit Homework 8. **Remember, you need to submit Homework 8 twice**:\n",
    "\n",
    "### To submit the manually graded problems (Questions 1.4, 3-4; marked [Written ‚úèÔ∏è])\n",
    "\n",
    "- Make sure your answers **are not** in this notebook, but rather in a separate PDF.\n",
    "    - You can create this PDF either digitally, using your tablet or using [Overleaf + LaTeX](https://overleaf.com) (or some other sort of digital document), or by writing your answers on a piece of paper and scanning them in.\n",
    "- Submit this separate PDF to the **Homework 8 (Questions 1.4, 3-4; written problems)** assignment on Gradescope, and **make sure to correctly select the pages associated with each question**!\n",
    "\n",
    "### To submit the autograded problems (Questions 1.1-1.3, 2; marked [Autograded üíª])\n",
    "\n",
    "1. Select `Kernel -> Restart & Run All` to ensure that you have executed all cells, including the test cells.\n",
    "2. Read through the notebook to make sure everything is fine and all tests passed.\n",
    "3. Run the cell below to run all tests, and make sure that they all pass.\n",
    "4. Download your notebook using `File -> Download as -> Notebook (.ipynb)`, then upload your notebook to Gradescope under \"Homework 8 (Questions 1.1-1.3, 2; autograded problems)\".\n",
    "5. Stick around while the Gradescope autograder grades your work.\n",
    "6. Check that you have a confirmation email from Gradescope and save it as proof of your submission.\n",
    "\n",
    "Your Homework 8 submission time will be the **later** of your two individual submissions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "otter": {
   "tests": {
    "q01_01": {
     "name": "q01_01",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> best_transformation in [1, 2, 3, 4]\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q01_02": {
     "name": "q01_02",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> callable(fit_model_and_return_predictions)\nTrue",
         "failure_message": "fit_model_and_return_predictions is not a function!",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out = fit_model_and_return_predictions(homeruns[['Year']], homeruns['Homeruns'])\n>>> isinstance(out, np.ndarray) and out.shape[0] == 120\nTrue",
         "failure_message": "Output of fit_model_and_return_predictions has wrong shape (expecting length 120).",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out = fit_model_and_return_predictions(homeruns[['Year']].sample(55), homeruns['Homeruns'].sample(55))\n>>> out.shape[0] == 55\nTrue",
         "failure_message": "Output of fit_model_and_return_predictions has wrong shape (expecting length 55).",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> out = fit_model_and_return_predictions(homeruns[['Year']], homeruns['Homeruns'])\n>>> out2 = fit_model_and_return_predictions(homeruns[['Year']], homeruns['Homeruns'])\n>>> np.allclose(out, out2)\nTrue",
         "failure_message": "Output of fit_model_and_return_predictions is non-deterministic, i.e. not the same on each function call.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q01_03": {
     "name": "q01_03",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> regressor = create_knn_regressor(x=np.array([10, 11, 12, 19, 25]), y=np.array([5, 17, 26, -5, 3]), k=3)\n>>> np.isclose(regressor(20), 8) and np.isclose(regressor(10), 16)\nTrue",
         "failure_message": "Incorrect outputs for input x, y, and k in the problem description.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> regressor = create_knn_regressor(x=np.array([10, 11, 12, 19, 25]), y=np.array([5, 17, 26, -5, 3]), k=5)\n>>> np.isclose(regressor(100), 9.2)\nTrue",
         "failure_message": "Incorrect outputs for the same x and y as in the problem description, with k=5. Should always return 9.2 since there are only 5 points.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> regressor = create_knn_regressor(x=np.array([10, 11, 12, 19, 25]), y=np.array([5, 17, 26, -5, 3]), k=1)\n>>> np.allclose([regressor(i) for i in range(10, 26)], [5.0, 17.0, 26.0, 26.0, 26.0, 26.0, -5.0, -5.0, -5.0, -5.0, -5.0, -5.0, -5.0, 3.0, 3.0, 3.0])\nTrue",
         "failure_message": "Incorrect outputs for the same x and y as in the problem description, with k=1.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q02_01": {
     "name": "q02_01",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> model = create_model_points_for_against(teams)\n>>> np.allclose(model.coef_, np.array([ 0.0007842 , -0.00077308]))\nTrue",
         "failure_message": "Incorrect model coefficients, when trained on the full dataset.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> model = create_model_points_for_against(teams)\n>>> np.isclose(model.intercept_, 0.4476604590703024)\nTrue",
         "failure_message": "Incorrect model intercept, when trained on the full dataset.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> model = create_model_points_for_against(teams)\n>>> np.isclose(model.predict([[2400, 2200]])[0], 0.6289662)\nTrue",
         "failure_message": "Incorrect prediction for points for=2400 and points against=2200, when trained on the full dataset.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> model = create_model_points_for_against(teams)\n>>> np.isclose(model.predict(pd.DataFrame([{'Points For': 2400, 'Points Against': 2200}]))[0], 0.6289662)\nTrue",
         "failure_message": "Incorrect prediction for points for=2400 and points against=2200, when trained on the full dataset, using named labels.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q02_02": {
     "name": "q02_02",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> model = create_model_points_for_against_standardized(teams)\n>>> len(model) == 2 and str(type(model[0])) == \"<class 'sklearn.preprocessing._data.StandardScaler'>\"\nTrue",
         "failure_message": "Pipeline should have 2 steps, the first of which is a StandardScaler instance.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> model = create_model_points_for_against_standardized(teams)\n>>> np.allclose(model[-1].coef_, np.array([ 0.16508223, -0.12354681]))\nTrue",
         "failure_message": "Incorrect model coefficients, when trained on the full dataset.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> model = create_model_points_for_against_standardized(teams)\n>>> np.isclose(model[-1].intercept_, 0.5191758241758242)\nTrue",
         "failure_message": "Incorrect model intercept, when trained on the full dataset.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> model = create_model_points_for_against_standardized(teams)\n>>> np.isclose(model.predict([[2400, 2200]])[0], 0.6289662)\nTrue",
         "failure_message": "Incorrect prediction for points for=2400 and points against=2200, when trained on the full dataset.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> model = create_model_points_for_against_standardized(teams)\n>>> np.isclose(model.predict(pd.DataFrame([{'Points For': 2400, 'Points Against': 2200}]))[0], 0.6289662)\nTrue",
         "failure_message": "Incorrect prediction for points for=2400 and points against=2200, when trained on the full dataset, using named labels.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q02_03": {
     "name": "q02_03",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> model = create_model_advanced(teams)\n>>> len(model) == 2\nTrue",
         "failure_message": "Pipeline should have 2 steps.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> model = create_model_advanced(teams)\n>>> is_ct = str(type(model[0])) == \"<class 'sklearn.compose._column_transformer.ColumnTransformer'>\"\n>>> is_ct and str(model[0]).count('FunctionTransformer') == 2 and str(model[0]).count('OneHotEncoder') == 1\nTrue",
         "failure_message": "First step of Pipeline should be ColumnTransformer with 2 FunctionTransformers, 1 OneHotEncoder.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> model = create_model_advanced(teams)\n>>> np.allclose(model[-1].coef_, np.array([ 0.01484763, -0.0168983 ,  0.03888132]))\nTrue",
         "failure_message": "Incorrect model coefficients, when trained on the full dataset.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> feature_cols = ['Points For', 'Points Against', 'FGA', 'TOV', 'FTA', 'ORB', 'Qualified']\n>>> michigan = teams[teams['School'] == 'Michigan'].loc[:, feature_cols]\n>>> model = create_model_advanced(teams)\n>>> np.isclose(model.predict(michigan)[0], 0.6754727385426412)\nTrue",
         "failure_message": "Incorrect prediction for Michigan, when trained on the full dataset.",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> model = create_model_advanced(teams)\n>>> np.isclose(model.predict(pd.DataFrame([{'Points For': 2400, 'Points Against': 2200, 'FGA': 1998, 'TOV': 500, 'FTA': 700, 'ORB': 300, 'Qualified': False}]))[0], 0.6343109351729046)\nTrue",
         "failure_message": "Incorrect prediction for input from example, when trained on the full dataset.",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
