{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec69f86",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from lec_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3143de48",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-info\" markdown=\"1\">\n",
    "\n",
    "#### Discussion 13\n",
    "\n",
    "# Clustering\n",
    "\n",
    "### EECS 398: Practical Data Science, Winter 2025\n",
    "\n",
    "<small><a style=\"text-decoration: none\" href=\"https://practicaldsc.org\">practicaldsc.org</a> ‚Ä¢ <a style=\"text-decoration: none\" href=\"https://github.com/practicaldsc/wn25\">github.com/practicaldsc/wn25</a> ‚Ä¢ üì£ See latest announcements [**here on Ed**](https://edstem.org/us/courses/69737/discussion/5943734) </small>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504aee40",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Agenda üìÜ\n",
    "\n",
    "- Unsupervised learning.\n",
    "- Minimizing inertia.\n",
    "- $k$-means clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beffa4f8-5dd1-45db-8086-d78842678dba",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Unsupervised learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bb8851-2450-40e7-8fab-5b02d6a4debb",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Suppose you're given a dataset where each point has several features $X$, but no labels $y$.\n",
    "\n",
    "<center><img src='imgs/clusters.png' width=400></img></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c9eb11-837d-4031-9147-b77fba62629d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Labels are an essential ingredient to the supervised algorithms we've learned about like linear regression, which learns a hypothesis function to predict a target $y$ given features $X$.<br>So we can't run supervised learning. What can we do?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd26775",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- One idea: Find groups of points in our dataset which are similar to one another.<br> These groups are called **clusters**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55919de-2be8-4662-b707-4c41988207a7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Minimizing inertia\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4472eff8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- There are several ways to define clusters.<br>\n",
    "One way is to define a set of $k$ **centroids**, or cluster centers. Each point belongs to the centroid it is closest to.\n",
    "\n",
    "<center><img src='imgs/clusters.png' width=400></img></center>\n",
    "\n",
    "<center><small>Here, our optimal centroids might lie at $(3, 8), (9.5, 9.5), (9, 4)$.<br>Once we've put users into clusters, we can make better recommendations based on the preferences of other users in the same cluster.</small></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15fa672",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- How do we place our centroids **optimally**?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36d9727-8862-46e5-914c-b917327f575e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Inertia** is an **objective function** we can use to measure how well a dataset was clustered. It's calculated by measuring the ($L_2$) distance between each data point and its closest centroid, squaring this distance, and summing this value across all points.\n",
    "$$I(\\vec \\mu_1, \\vec \\mu_2, ..., \\vec \\mu_k) = \\text{total squared distance} \\\\ \\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\: \\text{of each point } \\vec x_i \\\\ \\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\: \\text{ to its closest centroid } \\vec \\mu_j$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e73e43a-a30c-4af4-abe0-de4d7e7aad3c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We want to find the centroids $\\vec \\mu_1, \\vec \\mu_2, ..., \\vec \\mu_k$ that minimize inertia, but there are $k^n$ possible assignments of points to clusters. It would be computationally infeasible to try them all.<br><small>Instead, we'll use an iterative algorithm to (try to) find the centroid locations that minimize inertia!</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae415964-58f7-46ae-b15c-4ffaf4e28c44",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### $k$-means clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e358155a-d097-487f-a116-c7f845f0cd38",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- $k$-means is one of the most popular clustering algorithms, and is designed to minimize inertia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618c717a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- $k$-means finds the best centroids by initializing $k$ centroids randomly, and then alternating between:\n",
    "    1. Assigning each point to the nearest centroid.\n",
    "    2. Moving each centroid to the center of its group. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7a353e-1ed3-4f62-91a5-d094bb2a4fab",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Let's try a couple runs of $k$-means clustering [**here**](https://www.naftaliharris.com/blog/visualizing-k-means-clustering).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfac177-ab80-4435-a3e0-8917436d3011",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Attendance üôã\n",
    "\n",
    "<center><img src='imgs/disc13.png' width=\"500\"></img></center> \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e09ae71",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <a href='https://study.practicaldsc.org/disc13/index.html'>Worksheet</a> üìù\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "livereveal": {
   "scroll": true
  },
  "rise": {
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
